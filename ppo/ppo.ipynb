{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829e2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from gymnasium import spaces\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d30cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/martina/codi2/4year/tfg\")  # add parent folder of general.py\n",
    "\n",
    "from general import prepare, Glioblastoma, Glioblastoma2, testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42037536",
   "metadata": {},
   "source": [
    "# PPO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ecac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAwarePPOActorCritic(nn.Module):\n",
    "    def __init__(self, env, learning_rate=3e-4, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.n_outputs = env.action_space.n\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # CNN for patch processing\n",
    "        input_channels = 1\n",
    "        patch_shape = env.observation_space['patch'].shape  # (60, 60)\n",
    "        \n",
    "        self.patch_features = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        # Calculate flattened patch features size\n",
    "        with torch.no_grad():\n",
    "            dummy_patch = torch.zeros(1, input_channels, *patch_shape)\n",
    "            patch_features_out = self.patch_features(dummy_patch)\n",
    "            patch_flatten = patch_features_out.view(1, -1).size(1)\n",
    "        \n",
    "        # Position embedding\n",
    "        position_size = env.observation_space['position'].shape[0]  # 2\n",
    "        self.position_embedding = nn.Sequential(\n",
    "            nn.Linear(position_size, 16),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        \n",
    "        # Combined features\n",
    "        combined_features_size = patch_flatten + 32\n",
    "        \n",
    "        # Actor and Critic\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(combined_features_size, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(128, self.n_outputs),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(combined_features_size, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        if self.device == 'cuda':\n",
    "            self.to(self.device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, dict):\n",
    "            # Single observation - convert to batch of size 1\n",
    "            patch = x['patch']\n",
    "            position = x['position']\n",
    "            \n",
    "            if isinstance(patch, np.ndarray):\n",
    "                if patch.ndim == 2:\n",
    "                    patch = patch[np.newaxis, np.newaxis, :, :]  # (1, 1, 60, 60)\n",
    "                patch = torch.FloatTensor(patch).to(self.device)\n",
    "            \n",
    "            if isinstance(position, np.ndarray):\n",
    "                position = torch.FloatTensor(position).to(self.device).unsqueeze(0)  # Add batch dim\n",
    "            \n",
    "        elif isinstance(x, list):\n",
    "            # Batch of observations\n",
    "            patch_batch = []\n",
    "            position_batch = []\n",
    "            \n",
    "            for obs in x:\n",
    "                patch_batch.append(obs['patch'])\n",
    "                position_batch.append(obs['position'])\n",
    "            \n",
    "            patch_array = np.array(patch_batch)\n",
    "            if patch_array.ndim == 3:\n",
    "                patch_array = patch_array[:, np.newaxis, :, :]\n",
    "            \n",
    "            patch = torch.FloatTensor(patch_array).to(self.device)\n",
    "            position = torch.FloatTensor(np.array(position_batch)).to(self.device)\n",
    "        \n",
    "        # Process through networks (both paths now have batch dimension)\n",
    "        patch_features = self.patch_features(patch)\n",
    "        patch_flat = patch_features.view(patch.size(0), -1)\n",
    "        position_embedded = self.position_embedding(position)\n",
    "        combined = torch.cat([patch_flat, position_embedded], dim=-1)\n",
    "        \n",
    "        action_probs = self.actor(combined)\n",
    "        state_values = self.critic(combined)\n",
    "        \n",
    "        return action_probs, state_values\n",
    "\n",
    "\n",
    "\n",
    "# Fixed environment with global awareness\n",
    "class GlobalAwareGlioblastoma(Glioblastoma):\n",
    "    def __init__(self, image_path, mask_path, grid_size=4, tumor_threshold=0.0001, rewards=[1.0, -2.0, -0.5], action_space=spaces.Discrete(3), render_mode=\"human\"):\n",
    "        super().__init__(image_path, mask_path, grid_size, tumor_threshold, rewards, action_space, render_mode)\n",
    "        \n",
    "        self.image = np.load(image_path).astype(np.float32)\n",
    "        self.mask = np.load(mask_path).astype(np.uint8)\n",
    "        \n",
    "        img_min, img_max = self.image.min(), self.image.max()\n",
    "        if img_max > 1.0:\n",
    "            self.image = (self.image - img_min) / (img_max - img_min + 1e-8)\n",
    "\n",
    "        self.grid_size = grid_size\n",
    "        self.block_size = self.image.shape[0] // grid_size\n",
    "        \n",
    "        self.action_space = action_space\n",
    "        self.tumor_threshold = tumor_threshold\n",
    "        self.rewards = rewards\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # Dict observation space with position info\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'patch': spaces.Box(low=0, high=1, shape=(self.block_size, self.block_size), dtype=np.float32),\n",
    "            'position': spaces.Box(low=0, high=grid_size-1, shape=(2,), dtype=np.int32)\n",
    "        })\n",
    "\n",
    "        self.agent_pos = [0, 0]\n",
    "        self.current_step = 0\n",
    "        self.max_steps = 20\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.agent_pos = [0, 0]\n",
    "        self.current_step = 0\n",
    "        obs = self._get_obs()\n",
    "        info = {}\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        prev_pos = self.agent_pos.copy()\n",
    "        \n",
    "        # Movement logic (same as before)\n",
    "        if self.action_space.n == 3:\n",
    "            if action == 1 and self.agent_pos[0] < self.grid_size - 1:\n",
    "                self.agent_pos[0] += 1\n",
    "            elif action == 2 and self.agent_pos[1] < self.grid_size - 1:\n",
    "                self.agent_pos[1] += 1\n",
    "        elif self.action_space.n == 5:\n",
    "            if action == 1 and self.agent_pos[0] < self.grid_size - 1:\n",
    "                self.agent_pos[0] += 1\n",
    "            elif action == 2 and self.agent_pos[1] < self.grid_size - 1:\n",
    "                self.agent_pos[1] += 1\n",
    "            elif action == 3 and self.agent_pos[0] > 0:\n",
    "                self.agent_pos[0] -= 1\n",
    "            elif action == 4 and self.agent_pos[1] > 0:\n",
    "                self.agent_pos[1] -= 1\n",
    "        \n",
    "        reward = self._get_reward(action, prev_pos)\n",
    "        obs = self._get_obs()\n",
    "        terminated = self.current_step >= self.max_steps\n",
    "        truncated = False\n",
    "        info = {}\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        r0 = self.agent_pos[0] * self.block_size\n",
    "        c0 = self.agent_pos[1] * self.block_size\n",
    "        patch = self.image[r0:r0+self.block_size, c0:c0+self.block_size].astype(np.float32)\n",
    "        \n",
    "        return {\n",
    "            'patch': patch,\n",
    "            'position': np.array(self.agent_pos, dtype=np.int32)\n",
    "        }\n",
    "\n",
    "    def _get_reward(self, action, prev_pos):\n",
    "        r0 = self.agent_pos[0] * self.block_size\n",
    "        c0 = self.agent_pos[1] * self.block_size\n",
    "        patch_mask = self.mask[r0:r0+self.block_size, c0:c0+self.block_size]\n",
    "        \n",
    "        tumor_count_curr = np.sum(np.isin(patch_mask, [1, 4]))\n",
    "        total = self.block_size * self.block_size\n",
    "        inside = (tumor_count_curr / total) >= self.tumor_threshold\n",
    "        \n",
    "        if inside:\n",
    "            return self.rewards[0]\n",
    "        else:\n",
    "            if action == 0 or prev_pos == self.agent_pos:\n",
    "                return self.rewards[1]\n",
    "            else:\n",
    "                return self.rewards[2]\n",
    "\n",
    "    def render(self, show=True):\n",
    "        if self.render_mode != \"human\": # would be rgb_array or ansi\n",
    "            return  # Only render in human mode\n",
    "\n",
    "        # Create RGB visualization image\n",
    "        # not necessary since it's grayscale, but i want to draw the mask and position\n",
    "        vis_img = np.stack([self.image] * 3, axis=-1).astype(np.float32)\n",
    "\n",
    "        # Overlay tumor mask in red [..., 0] \n",
    "        tumor_overlay = np.zeros_like(vis_img) # do all blank but here we have 3 channels, mask is 2D\n",
    "        tumor_overlay[..., 0] = (self.mask > 0).astype(float) # red channel. set to float to avoid issues when blending in vis_img\n",
    "\n",
    "        # transparency overlay (crec que es el mateix valor que tinc a l'altra notebook)\n",
    "        alpha = 0.4\n",
    "        vis_img = (1 - alpha) * vis_img + alpha * tumor_overlay\n",
    "\n",
    "        if show:\n",
    "            # Plotting\n",
    "            fig, ax = plt.subplots(figsize=(3, 3))\n",
    "            ax.imshow(vis_img, cmap='gray', origin='upper')\n",
    "\n",
    "            # Draw grid lines\n",
    "            # alpha for transparency again\n",
    "            for i in range(1, self.grid_size):\n",
    "                ax.axhline(i * self.block_size, color='white', lw=1, alpha=0.5)\n",
    "                ax.axvline(i * self.block_size, color='white', lw=1, alpha=0.5)\n",
    "\n",
    "            # Draw agent position\n",
    "            r0 = self.agent_pos[0] * self.block_size\n",
    "            c0 = self.agent_pos[1] * self.block_size\n",
    "            rect = patches.Rectangle(\n",
    "                (c0, r0), # (x,y) bottom left corner\n",
    "                self.block_size, # width\n",
    "                self.block_size, # height\n",
    "                linewidth=2,\n",
    "                edgecolor='yellow',\n",
    "                facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            ax.set_title(f\"Agent at {self.agent_pos} | Step {self.current_step}/{self.max_steps}\")\n",
    "            ax.axis('off')\n",
    "            plt.show()\n",
    "            return None\n",
    "        else: #just return without showing but draw the agent position\n",
    "            rgb_array = (vis_img * 255).astype(np.uint8)\n",
    "        \n",
    "            # Draw grid lines directly on the array\n",
    "            for i in range(1, self.grid_size):\n",
    "                # Horizontal line\n",
    "                y = i * self.block_size\n",
    "                rgb_array[y-1:y+1, :] = [255, 255, 255]  # White line\n",
    "                \n",
    "                # Vertical line  \n",
    "                x = i * self.block_size\n",
    "                rgb_array[:, x-1:x+1] = [255, 255, 255]  # White line\n",
    "            \n",
    "            # Draw agent position as a yellow rectangle\n",
    "            r0 = self.agent_pos[0] * self.block_size\n",
    "            c0 = self.agent_pos[1] * self.block_size\n",
    "            \n",
    "            # Draw rectangle borders (yellow)\n",
    "            rgb_array[r0:r0+2, c0:c0+self.block_size] = [255, 255, 0]  # Top border\n",
    "            rgb_array[r0+self.block_size-2:r0+self.block_size, c0:c0+self.block_size] = [255, 255, 0]  # Bottom border\n",
    "            rgb_array[r0:r0+self.block_size, c0:c0+2] = [255, 255, 0]  # Left border\n",
    "            rgb_array[r0:r0+self.block_size, c0+self.block_size-2:c0+self.block_size] = [255, 255, 0]  # Right border\n",
    "            \n",
    "            # Add step counter text to the image\n",
    "            from PIL import Image, ImageDraw, ImageFont\n",
    "            pil_img = Image.fromarray(rgb_array)\n",
    "            draw = ImageDraw.Draw(pil_img)\n",
    "            \n",
    "            # Use default font (you can also load a specific font)\n",
    "            try:\n",
    "                font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "            except:\n",
    "                font = ImageFont.load_default()\n",
    "            \n",
    "            # Draw step counter in top-left corner\n",
    "            step_text = f\"Step: {self.current_step}/{self.max_steps}\"\n",
    "            draw.text((5, 5), step_text, fill=(255, 255, 0), font=font)  # Yellow text\n",
    "            \n",
    "            # Convert back to numpy array\n",
    "            rgb_array = np.array(pil_img)\n",
    "            return rgb_array\n",
    "        \n",
    "    def current_patch_overlap_with_lesion(self):\n",
    "        row, col = self.agent_pos\n",
    "        patch_h = self.block_size\n",
    "        patch_w = self.block_size\n",
    "        \n",
    "        y0 = row * patch_h\n",
    "        y1 = y0 + patch_h\n",
    "        x0 = col * patch_w\n",
    "        x1 = x0 + patch_w\n",
    "        patch_mask = self.mask[y0:y1, x0:x1]\n",
    "        overlap = np.sum(patch_mask > 0)\n",
    "        return overlap\n",
    "\n",
    "\n",
    "class PPOAgent:\n",
    "    def __init__(self, env_config, model, train_pairs, env_class,\n",
    "                 gamma=0.99, gae_lambda=0.95,\n",
    "                 clip_epsilon=0.2, ppo_epochs=4, batch_size=64,\n",
    "                 save_name=\"PPO_Agent\"):\n",
    "        \n",
    "        self.env_config = env_config\n",
    "        self.env_class = env_class\n",
    "        self.model = model\n",
    "        self.device = model.device\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.gae_lambda = gae_lambda\n",
    "        self.clip_epsilon = clip_epsilon\n",
    "        self.ppo_epochs = ppo_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.save_name = save_name\n",
    "        \n",
    "        self.training_rewards = []\n",
    "        self.mean_training_rewards = []\n",
    "        self.actor_losses = []\n",
    "        self.critic_losses = []\n",
    "        self.entropies = []\n",
    "        \n",
    "        self.train_pairs = train_pairs\n",
    "\n",
    "\n",
    "# Also need to fix the PPOAgent to handle dict observations\n",
    "class GlobalAwarePPOAgent(PPOAgent):\n",
    "    def __init__(self, env_config, model, train_pairs, env_class,\n",
    "                 gamma=0.99, gae_lambda=0.95,\n",
    "                 clip_epsilon=0.2, ppo_epochs=4, batch_size=64,\n",
    "                 save_name=\"GlobalAware_PPO\"):\n",
    "        \n",
    "        self.env_config = env_config\n",
    "        self.env_class = env_class\n",
    "        self.model = model\n",
    "        self.device = model.device\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.gae_lambda = gae_lambda\n",
    "        self.clip_epsilon = clip_epsilon\n",
    "        self.ppo_epochs = ppo_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.save_name = save_name\n",
    "        \n",
    "        self.training_rewards = []\n",
    "        self.mean_training_rewards = []\n",
    "        self.actor_losses = []\n",
    "        self.critic_losses = []\n",
    "        self.entropies = []\n",
    "        \n",
    "        self.train_pairs = train_pairs\n",
    "        \n",
    "    def compute_gae(self, rewards, values, dones, next_value):\n",
    "        gae = 0\n",
    "        returns = []\n",
    "        advantages = []\n",
    "        \n",
    "        values = values + [next_value]\n",
    "        \n",
    "        for step in reversed(range(len(rewards))):\n",
    "            delta = rewards[step] + self.gamma * values[step + 1] * (1 - dones[step]) - values[step]\n",
    "            gae = delta + self.gamma * self.gae_lambda * (1 - dones[step]) * gae\n",
    "            advantages.insert(0, gae)\n",
    "            returns.insert(0, gae + values[step])\n",
    "            \n",
    "        return returns, advantages\n",
    "    \n",
    "    def collect_trajectories(self, num_steps=2048):\n",
    "        all_states = []\n",
    "        all_actions = []\n",
    "        all_rewards = []\n",
    "        all_dones = []\n",
    "        all_values = []\n",
    "        all_log_probs = []\n",
    "        \n",
    "        img_path, mask_path = random.choice(self.train_pairs)\n",
    "        env = self.env_class(img_path, mask_path, **self.env_config)\n",
    "        state, _ = env.reset()\n",
    "        \n",
    "        episode_reward = 0\n",
    "        episode_rewards = []\n",
    "        \n",
    "        for step in range(num_steps):\n",
    "            with torch.no_grad():\n",
    "                action_probs, value = self.model(state)\n",
    "                dist = Categorical(action_probs)\n",
    "                action = dist.sample()\n",
    "                log_prob = dist.log_prob(action)\n",
    "                value = value.squeeze()\n",
    "            \n",
    "            next_state, reward, terminated, truncated, _ = env.step(action.item())\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            # Store the state dict properly\n",
    "            all_states.append({\n",
    "                'patch': state['patch'].copy(),\n",
    "                'position': state['position'].copy()\n",
    "            })\n",
    "            all_actions.append(action.item())\n",
    "            all_rewards.append(reward)\n",
    "            all_dones.append(done)\n",
    "            all_values.append(value.item())\n",
    "            all_log_probs.append(log_prob.item())\n",
    "            \n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                episode_rewards.append(episode_reward)\n",
    "                img_path, mask_path = random.choice(self.train_pairs)\n",
    "                env = self.env_class(img_path, mask_path, **self.env_config)\n",
    "                state, _ = env.reset()\n",
    "                episode_reward = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, next_value = self.model(state)\n",
    "            next_value = next_value.squeeze().item()\n",
    "        \n",
    "        return (all_states, all_actions, all_rewards, all_dones, \n",
    "                all_values, all_log_probs, next_value, episode_rewards)\n",
    "    \n",
    "    def update(self, states, actions, returns, advantages, old_log_probs):\n",
    "        # Prepare batch data\n",
    "        patch_batch = []\n",
    "        position_batch = []\n",
    "        \n",
    "        for state in states:\n",
    "            patch_batch.append(state['patch'])\n",
    "            position_batch.append(state['position'])\n",
    "        \n",
    "        # Convert to tensors\n",
    "        patch_array = np.array(patch_batch)\n",
    "        if patch_array.ndim == 3:\n",
    "            patch_array = patch_array[:, np.newaxis, :, :]\n",
    "        \n",
    "        batch_data = {\n",
    "            'patch': torch.FloatTensor(patch_array).to(self.device),\n",
    "            'position': torch.FloatTensor(np.array(position_batch)).to(self.device)\n",
    "        }\n",
    "        \n",
    "        actions_tensor = torch.LongTensor(actions).to(self.device)\n",
    "        returns_tensor = torch.FloatTensor(returns).to(self.device)\n",
    "        advantages_tensor = torch.FloatTensor(advantages).to(self.device)\n",
    "        old_log_probs_tensor = torch.FloatTensor(old_log_probs).to(self.device)\n",
    "        \n",
    "        # Normalize advantages\n",
    "        advantages_tensor = (advantages_tensor - advantages_tensor.mean()) / (advantages_tensor.std() + 1e-8)\n",
    "        \n",
    "        batch_size = len(states)\n",
    "        indices = np.arange(batch_size)\n",
    "        \n",
    "        for _ in range(self.ppo_epochs):\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "            for start in range(0, batch_size, self.batch_size):\n",
    "                end = start + self.batch_size\n",
    "                batch_indices = indices[start:end]\n",
    "                \n",
    "                batch_states = {\n",
    "                    'patch': batch_data['patch'][batch_indices],\n",
    "                    'position': batch_data['position'][batch_indices]\n",
    "                }\n",
    "                batch_actions = actions_tensor[batch_indices]\n",
    "                batch_returns = returns_tensor[batch_indices]\n",
    "                batch_advantages = advantages_tensor[batch_indices]\n",
    "                batch_old_log_probs = old_log_probs_tensor[batch_indices]\n",
    "                \n",
    "                # Get current policy and value\n",
    "                action_probs, values = self.model(batch_states)\n",
    "                dist = Categorical(action_probs)\n",
    "                new_log_probs = dist.log_prob(batch_actions)\n",
    "                entropy = dist.entropy().mean()\n",
    "                \n",
    "                values = values.squeeze()\n",
    "                \n",
    "                # Calculate ratios\n",
    "                ratios = torch.exp(new_log_probs - batch_old_log_probs)\n",
    "                \n",
    "                # Policy loss\n",
    "                surr1 = ratios * batch_advantages\n",
    "                surr2 = torch.clamp(ratios, 1 - self.clip_epsilon, 1 + self.clip_epsilon) * batch_advantages\n",
    "                policy_loss = -torch.min(surr1, surr2).mean()\n",
    "                \n",
    "                # Value loss\n",
    "                value_loss = 0.5 * (values - batch_returns).pow(2).mean()\n",
    "                \n",
    "                # Total loss\n",
    "                loss = policy_loss + 0.5 * value_loss - 0.01 * entropy\n",
    "                \n",
    "                # Backpropagate\n",
    "                self.model.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)\n",
    "                self.model.optimizer.step()\n",
    "                \n",
    "                self.actor_losses.append(policy_loss.item())\n",
    "                self.critic_losses.append(value_loss.item())\n",
    "                self.entropies.append(entropy.item())\n",
    "    \n",
    "    def train(self, max_episodes=1000, num_steps=512):\n",
    "        print(\"Starting Global-Aware PPO training...\")\n",
    "        \n",
    "        episode = 0\n",
    "        best_mean_reward = -float('inf')\n",
    "        \n",
    "        while episode < max_episodes:\n",
    "            (states, actions, rewards, dones, values, \n",
    "             old_log_probs, next_value, episode_rewards) = self.collect_trajectories(num_steps)\n",
    "            \n",
    "            if not states:\n",
    "                continue\n",
    "            \n",
    "            returns, advantages = self.compute_gae(rewards, values, dones, next_value)\n",
    "            self.update(states, actions, returns, advantages, old_log_probs)\n",
    "            \n",
    "            self.training_rewards.extend(episode_rewards)\n",
    "            \n",
    "            if len(self.training_rewards) >= 100:\n",
    "                mean_reward = np.mean(self.training_rewards[-100:])\n",
    "            else:\n",
    "                mean_reward = np.mean(self.training_rewards)\n",
    "                \n",
    "            self.mean_training_rewards.append(mean_reward)\n",
    "            \n",
    "            if episode_rewards:\n",
    "                avg_episode_reward = np.mean(episode_rewards)\n",
    "                print(f\"Episode {episode} | \"\n",
    "                      f\"Avg Reward: {avg_episode_reward:.2f} | \"\n",
    "                      f\"Mean Reward (100): {mean_reward:.2f} | \"\n",
    "                      f\"Actor Loss: {np.mean(self.actor_losses[-10:] or [0]):.4f}\")\n",
    "                \n",
    "                # save in wandb\n",
    "                wandb.log({\n",
    "                    \"episode\": episode,\n",
    "                    \"avg_episode_reward\": avg_episode_reward,\n",
    "                    \"mean_reward_100\": mean_reward,\n",
    "                    \"actor_loss\": np.mean(self.actor_losses[-10:] or [0]),\n",
    "                    \"critic_loss\": np.mean(self.critic_losses[-10:] or [0]),\n",
    "                    \"entropy\": np.mean(self.entropies[-10:] or [0])\n",
    "                })\n",
    "            \n",
    "            episode += len(episode_rewards)\n",
    "            \n",
    "            if mean_reward > best_mean_reward:\n",
    "                best_mean_reward = mean_reward\n",
    "                torch.save(self.model.state_dict(), f\"{self.save_name}_best.pth\")\n",
    "                print(\"New best model saved!\")\n",
    "            \n",
    "            if episode % 100 == 0:\n",
    "                torch.save(self.model.state_dict(), f\"{self.save_name}_checkpoint.pth\")\n",
    "        \n",
    "        torch.save(self.model.state_dict(), f\"{self.save_name}_final.pth\")\n",
    "        print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f706c9",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9fa236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Categorical\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def testing(agent, test_pairs, agent_type, num_episodes=None, env_config=None, save_gifs=True, gif_folder=\"TEST_GIFS\"):\n",
    "\n",
    "    if num_episodes is None:\n",
    "        num_episodes = len(test_pairs)\n",
    "    \n",
    "    # Create GIF folder if needed\n",
    "    if save_gifs and not os.path.exists(gif_folder):\n",
    "        os.makedirs(gif_folder)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    if agent_type.lower() == \"dqn\":\n",
    "        agent.dnnetwork.eval()\n",
    "    elif agent_type.lower() == \"ppo\":\n",
    "        agent.model.eval()\n",
    "    \n",
    "    results = {\n",
    "        'success_rate': [],\n",
    "        'final_position_accuracy': [],\n",
    "        'average_reward': [],\n",
    "        'steps_to_find_tumor': [],\n",
    "        'total_tumor_reward': [],\n",
    "        'tumor_sizes_pixels': [],\n",
    "        'tumor_sizes_percentage': [],\n",
    "        'episode_details': []\n",
    "    }\n",
    "    \n",
    "    grid_size = env_config.get('grid_size', 4)\n",
    "    rewards = env_config.get('rewards', [5.0, -1.0, -0.2])\n",
    "    action_space = env_config.get('action_space', None)\n",
    "    \n",
    "    for i in range(min(num_episodes, len(test_pairs))):\n",
    "        img_path, mask_path = test_pairs[i]\n",
    "        \n",
    "        # Create environment\n",
    "        if hasattr(agent, 'env_class'):\n",
    "            env = agent.env_class(img_path, mask_path, grid_size=grid_size, rewards=rewards, action_space=action_space)\n",
    "        else:\n",
    "            env = Glioblastoma(img_path, mask_path, grid_size=grid_size, rewards=rewards, action_space=action_space)\n",
    "        \n",
    "        state, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        found_tumor = False\n",
    "        tumor_positions_visited = set()\n",
    "        steps_to_find = env.max_steps\n",
    "        tumor_rewards = 0\n",
    "        \n",
    "        # For action distribution tracking\n",
    "        action_counts = np.zeros(env.action_space.n)\n",
    "        \n",
    "        # For GIF creation\n",
    "        frames = []\n",
    "        \n",
    "        # Get tumor size information for this episode\n",
    "        tumor_size_pixels = count_tumor_pixels(env)\n",
    "        total_pixels = env.image.shape[0] * env.image.shape[1]\n",
    "        tumor_size_percentage = (tumor_size_pixels / total_pixels) * 100\n",
    "        \n",
    "        results['tumor_sizes_pixels'].append(tumor_size_pixels)\n",
    "        results['tumor_sizes_percentage'].append(tumor_size_percentage)\n",
    "        \n",
    "        for step in range(env.max_steps):\n",
    "            with torch.no_grad():\n",
    "                if agent_type.lower() == \"dqn\":\n",
    "                    action = agent.dnnetwork.get_action(state, epsilon=0.00)\n",
    "                    action_idx = action\n",
    "                elif agent_type.lower() == \"ppo\":\n",
    "                    action_probs, _ = agent.model(state)\n",
    "                    dist = Categorical(action_probs)\n",
    "                    action = dist.sample()\n",
    "                    action_idx = action.item()\n",
    "            \n",
    "            action_counts[action_idx] += 1\n",
    "            \n",
    "            next_state, reward, terminated, truncated, _ = env.step(action_idx)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Track tumor-related metrics\n",
    "            current_overlap = env.current_patch_overlap_with_lesion()\n",
    "            if current_overlap > 0:\n",
    "                tumor_positions_visited.add(tuple(env.agent_pos))\n",
    "                if not found_tumor:\n",
    "                    found_tumor = True\n",
    "                    steps_to_find = step + 1\n",
    "                \n",
    "                # Count positive rewards (when on tumor)\n",
    "                if reward > 0:\n",
    "                    tumor_rewards += 1\n",
    "            \n",
    "            # Capture frame for GIF\n",
    "            if save_gifs:\n",
    "                frame = env.render(show=False)\n",
    "                if frame is not None:\n",
    "                    frames.append(frame)\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        \n",
    "        # Save GIF\n",
    "        gif_path = None\n",
    "        if save_gifs and frames:\n",
    "            gif_path = os.path.join(gif_folder, f\"episode_{i}_{os.path.basename(img_path).split('.')[0]}.gif\")\n",
    "            # Convert frames to PIL Images and save as GIF\n",
    "            pil_frames = [Image.fromarray(frame) for frame in frames]\n",
    "            pil_frames[0].save(\n",
    "                gif_path,\n",
    "                save_all=True,\n",
    "                append_images=pil_frames[1:],\n",
    "                duration=500,  # milliseconds per frame\n",
    "                loop=0\n",
    "            )\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Saved GIF for episode {i} at {gif_path}\")\n",
    "        \n",
    "        # Calculate metrics for this episode\n",
    "        final_overlap = env.current_patch_overlap_with_lesion()\n",
    "        \n",
    "        # Success: ended on tumor region\n",
    "        success = final_overlap > 0\n",
    "        results['success_rate'].append(success)\n",
    "        \n",
    "        # Final position accuracy\n",
    "        results['final_position_accuracy'].append(final_overlap > 0)\n",
    "        \n",
    "        # Average reward\n",
    "        results['average_reward'].append(total_reward)\n",
    "        \n",
    "        # Steps to find tumor\n",
    "        results['steps_to_find_tumor'].append(steps_to_find)\n",
    "                \n",
    "        # Total positive rewards from tumor\n",
    "        results['total_tumor_reward'].append(tumor_rewards)\n",
    "        \n",
    "        # Store detailed episode information\n",
    "        episode_detail = {\n",
    "            'image_path': img_path,\n",
    "            'success': success,\n",
    "            'final_on_tumor': final_overlap > 0,\n",
    "            'total_reward': total_reward,\n",
    "            'steps_to_find_tumor': steps_to_find,\n",
    "            'tumor_rewards': tumor_rewards,\n",
    "            'tumor_size_pixels': tumor_size_pixels,\n",
    "            'tumor_size_percentage': tumor_size_percentage,\n",
    "            'action_distribution': action_counts / np.sum(action_counts),  # Normalized\n",
    "            'action_counts_raw': action_counts,  # Keep raw counts for aggregation\n",
    "            'gif_path': gif_path\n",
    "        }\n",
    "        results['episode_details'].append(episode_detail)\n",
    "    \n",
    "    # Calculate separate action distributions\n",
    "    successful_episodes = [ep for ep in results['episode_details'] if ep['final_on_tumor']]\n",
    "    unsuccessful_episodes = [ep for ep in results['episode_details'] if not ep['final_on_tumor']]\n",
    "    \n",
    "    action_dist_success = calculate_separate_action_distribution(successful_episodes)\n",
    "    action_dist_failure = calculate_separate_action_distribution(unsuccessful_episodes)\n",
    "    \n",
    "    # Calculate overall metrics with new tumor size statistics\n",
    "    overall_results = {\n",
    "        'success_rate': np.mean(results['success_rate']),\n",
    "        'average_reward': np.mean(results['average_reward']),\n",
    "        'avg_steps_to_find_tumor': np.mean(results['steps_to_find_tumor']),\n",
    "        'avg_tumor_rewards': np.mean(results['total_tumor_reward']),\n",
    "        'biggest_tumor_pixels': np.max(results['tumor_sizes_pixels']),\n",
    "        'smallest_tumor_pixels': np.min(results['tumor_sizes_pixels']),\n",
    "        'biggest_tumor_percentage': np.max(results['tumor_sizes_percentage']),\n",
    "        'smallest_tumor_percentage': np.min(results['tumor_sizes_percentage']),\n",
    "        'avg_tumor_size_pixels': np.mean(results['tumor_sizes_pixels']),\n",
    "        'avg_tumor_size_percentage': np.mean(results['tumor_sizes_percentage']),\n",
    "        'action_distribution': calculate_overall_action_distribution(results['episode_details']),\n",
    "        'action_distribution_success': action_dist_success,\n",
    "        'action_distribution_failure': action_dist_failure,\n",
    "        'episode_details': results['episode_details']\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"TEST RESULTS ({agent_type.upper()} Agent)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Success Rate: {overall_results['success_rate']*100:.2f}%\")\n",
    "    print(f\"Average Episode Reward: {overall_results['average_reward']:.2f}\")\n",
    "    print(f\"Average Steps to Find Tumor: {overall_results['avg_steps_to_find_tumor']:.2f}\")\n",
    "    print(f\"Average Tumor Rewards per Episode: {overall_results['avg_tumor_rewards']:.2f}\")\n",
    "    print(f\"Tumor Size Statistics:\")\n",
    "    print(f\"  Biggest Tumor: {overall_results['biggest_tumor_pixels']:.0f} pixels ({overall_results['biggest_tumor_percentage']:.2f}%)\")\n",
    "    print(f\"  Smallest Tumor: {overall_results['smallest_tumor_pixels']:.0f} pixels ({overall_results['smallest_tumor_percentage']:.2f}%)\")\n",
    "    print(f\"  Average Tumor: {overall_results['avg_tumor_size_pixels']:.0f} pixels ({overall_results['avg_tumor_size_percentage']:.2f}%)\")\n",
    "    print(f\"Overall Action Distribution: {overall_results['action_distribution']}\")\n",
    "    print(f\"  Successful Episodes: {overall_results['action_distribution_success']}\")\n",
    "    print(f\"  Unsuccessful Episodes: {overall_results['action_distribution_failure']}\")\n",
    "    \n",
    "    # Print individual episode results\n",
    "    print(f\"\\nDetailed Results for {len(results['episode_details'])} episodes:\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, detail in enumerate(results['episode_details']):\n",
    "        print(f\"Episode {i}: {os.path.basename(detail['image_path'])}\")\n",
    "        print(f\"  Success: {detail['success']}, Final on Tumor: {detail['final_on_tumor']}\")\n",
    "        print(f\"  Total Reward: {detail['total_reward']:.2f}, Steps to Find: {detail['steps_to_find_tumor']}\")\n",
    "        print(f\"  Tumor Size: {detail['tumor_size_pixels']} pixels ({detail['tumor_size_percentage']:.2f}%)\")\n",
    "        print(f\"  Action Distribution: {detail['action_distribution']}\")\n",
    "        if detail['gif_path']:\n",
    "            print(f\"  GIF saved: {detail['gif_path']}\")\n",
    "        print()\n",
    "    \n",
    "    return overall_results\n",
    "\n",
    "\n",
    "def count_tumor_pixels(env):\n",
    "    \"\"\"Count total number of tumor pixels in the mask\"\"\"\n",
    "    if hasattr(env, 'mask'):\n",
    "        return np.sum(env.mask > 0)\n",
    "    elif hasattr(env, 'original_mask'):\n",
    "        return np.sum(env.original_mask > 0)\n",
    "    else:\n",
    "        # Fallback: try to access the mask through available attributes\n",
    "        try:\n",
    "            mask = env.lesion_mask if hasattr(env, 'lesion_mask') else None\n",
    "            if mask is not None:\n",
    "                return np.sum(mask > 0)\n",
    "        except:\n",
    "            pass\n",
    "    return 0\n",
    "\n",
    "def calculate_overall_action_distribution(episode_details):\n",
    "    \"\"\"Calculate overall action distribution across all episodes\"\"\"\n",
    "    total_actions = np.zeros_like(episode_details[0]['action_distribution'])\n",
    "    \n",
    "    for detail in episode_details:\n",
    "        # Multiply by steps to get actual count, then normalize\n",
    "        action_dist = detail['action_distribution']\n",
    "        # Since action_distribution is already normalized per episode, we'll average them\n",
    "        total_actions += action_dist\n",
    "    \n",
    "    # Normalize to get overall distribution\n",
    "    overall_dist = total_actions / len(episode_details)\n",
    "    return overall_dist\n",
    "\n",
    "def calculate_separate_action_distribution(episode_list):\n",
    "    \"\"\"Calculate action distribution for a specific list of episodes\"\"\"\n",
    "    if len(episode_list) == 0:\n",
    "        return np.array([])  # Return empty array if no episodes\n",
    "    \n",
    "    total_actions = np.zeros_like(episode_list[0]['action_distribution'])\n",
    "    \n",
    "    for episode in episode_list:\n",
    "        total_actions += episode['action_distribution']\n",
    "    \n",
    "    # Normalize to get distribution\n",
    "    distribution = total_actions / len(episode_list)\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f4243",
   "metadata": {},
   "source": [
    "# TRIALS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e434091a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 30 pairs out of 30 listed in CSV.\n"
     ]
    }
   ],
   "source": [
    "train_pairs = prepare()\n",
    "\n",
    "sucess = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d0b779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmartinacarrettab\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/martina/codi2/4year/tfg/ppo/wandb/run-20251113_234726-rg02qdqe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/rg02qdqe' target=\"_blank\">PPO_batch64_rewards[5.0, -1.0, -0.2]_3actions</a></strong> to <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/rg02qdqe' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/rg02qdqe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Global-Aware PPO training...\n",
      "Episode 0 | Avg Reward: -3.95 | Mean Reward (100): -3.95 | Actor Loss: -0.0228\n",
      "New best model saved!\n",
      "Episode 25 | Avg Reward: -4.96 | Mean Reward (100): -4.46 | Actor Loss: -0.0212\n",
      "Episode 50 | Avg Reward: -8.46 | Mean Reward (100): -5.79 | Actor Loss: -0.0046\n",
      "Episode 75 | Avg Reward: -5.17 | Mean Reward (100): -5.64 | Actor Loss: -0.0123\n",
      "Episode 100 | Avg Reward: 0.05 | Mean Reward (100): -4.64 | Actor Loss: -0.0079\n",
      "Episode 125 | Avg Reward: 1.07 | Mean Reward (100): -3.13 | Actor Loss: 0.0156\n",
      "New best model saved!\n",
      "Episode 150 | Avg Reward: 1.68 | Mean Reward (100): -0.59 | Actor Loss: -0.0068\n",
      "New best model saved!\n",
      "Episode 175 | Avg Reward: 3.01 | Mean Reward (100): 1.45 | Actor Loss: -0.0035\n",
      "New best model saved!\n",
      "Episode 200 | Avg Reward: 2.56 | Mean Reward (100): 2.08 | Actor Loss: -0.0331\n",
      "New best model saved!\n",
      "Episode 225 | Avg Reward: 14.27 | Mean Reward (100): 5.38 | Actor Loss: -0.0056\n",
      "New best model saved!\n",
      "Episode 250 | Avg Reward: 8.58 | Mean Reward (100): 7.10 | Actor Loss: 0.0326\n",
      "New best model saved!\n",
      "Episode 275 | Avg Reward: 14.19 | Mean Reward (100): 9.90 | Actor Loss: 0.0236\n",
      "New best model saved!\n",
      "Episode 300 | Avg Reward: 37.46 | Mean Reward (100): 18.62 | Actor Loss: -0.0070\n",
      "New best model saved!\n",
      "Episode 325 | Avg Reward: -1.86 | Mean Reward (100): 14.59 | Actor Loss: 0.0254\n",
      "Episode 350 | Avg Reward: 8.35 | Mean Reward (100): 14.54 | Actor Loss: 0.0077\n",
      "Episode 375 | Avg Reward: 23.79 | Mean Reward (100): 16.94 | Actor Loss: -0.0024\n",
      "Episode 400 | Avg Reward: 32.80 | Mean Reward (100): 15.77 | Actor Loss: 0.0166\n",
      "Episode 425 | Avg Reward: 15.98 | Mean Reward (100): 20.23 | Actor Loss: -0.0227\n",
      "New best model saved!\n",
      "Episode 450 | Avg Reward: 23.84 | Mean Reward (100): 24.10 | Actor Loss: -0.0124\n",
      "New best model saved!\n",
      "Episode 475 | Avg Reward: 29.81 | Mean Reward (100): 25.61 | Actor Loss: 0.0186\n",
      "New best model saved!\n",
      "Episode 500 | Avg Reward: 6.54 | Mean Reward (100): 19.04 | Actor Loss: -0.0074\n",
      "Episode 525 | Avg Reward: 22.61 | Mean Reward (100): 20.70 | Actor Loss: -0.0166\n",
      "Episode 550 | Avg Reward: 10.40 | Mean Reward (100): 17.34 | Actor Loss: -0.0095\n",
      "Episode 575 | Avg Reward: 19.02 | Mean Reward (100): 14.64 | Actor Loss: 0.0057\n",
      "Episode 600 | Avg Reward: 28.54 | Mean Reward (100): 20.14 | Actor Loss: 0.0216\n",
      "Episode 625 | Avg Reward: 32.64 | Mean Reward (100): 22.65 | Actor Loss: -0.0249\n",
      "Episode 650 | Avg Reward: 30.78 | Mean Reward (100): 27.75 | Actor Loss: 0.0073\n",
      "New best model saved!\n",
      "Episode 675 | Avg Reward: 29.38 | Mean Reward (100): 30.34 | Actor Loss: -0.0263\n",
      "New best model saved!\n",
      "Episode 700 | Avg Reward: 20.16 | Mean Reward (100): 28.24 | Actor Loss: 0.0030\n",
      "Episode 725 | Avg Reward: 12.86 | Mean Reward (100): 23.30 | Actor Loss: -0.0124\n",
      "Episode 750 | Avg Reward: 29.54 | Mean Reward (100): 22.98 | Actor Loss: 0.0110\n",
      "Episode 775 | Avg Reward: 42.19 | Mean Reward (100): 26.19 | Actor Loss: -0.0128\n",
      "Episode 800 | Avg Reward: 40.90 | Mean Reward (100): 31.37 | Actor Loss: -0.0161\n",
      "New best model saved!\n",
      "Episode 825 | Avg Reward: 14.22 | Mean Reward (100): 31.71 | Actor Loss: -0.0185\n",
      "New best model saved!\n",
      "Episode 850 | Avg Reward: 39.68 | Mean Reward (100): 34.25 | Actor Loss: -0.0184\n",
      "New best model saved!\n",
      "Episode 875 | Avg Reward: 22.62 | Mean Reward (100): 29.36 | Actor Loss: 0.0201\n",
      "Episode 900 | Avg Reward: 14.58 | Mean Reward (100): 22.78 | Actor Loss: -0.0048\n",
      "Episode 925 | Avg Reward: 30.61 | Mean Reward (100): 26.87 | Actor Loss: -0.0160\n",
      "Episode 950 | Avg Reward: 2.08 | Mean Reward (100): 17.47 | Actor Loss: 0.0198\n",
      "Episode 975 | Avg Reward: 44.30 | Mean Reward (100): 22.89 | Actor Loss: 0.0365\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▂▂▄▃▄▆▄▄▁▄█▇▄▇▅▄▆▂▃▆▄▃▃▅▆▂▅▂▅▃▅▃▃▂▂▆▄▃▆█</td></tr><tr><td>avg_episode_reward</td><td>▂▁▁▁▂▂▂▃▂▄▃▄▇▂▃▅▆▄▅▆▃▅▄▅▆▆▆▆▅▄▆██▄▇▅▄▆▂█</td></tr><tr><td>critic_loss</td><td>▂▁▁▁▂▂▂▂▂▅▅▄▆▃▃▆▅▅▆▆▄▅▅▅▅▇▇▆▆▆▇██▆█▆▆▆▃▆</td></tr><tr><td>entropy</td><td>████▇▇▇▇▆▅▄▄▄▄▃▂▂▃▂▃▃▂▃▂▂▂▁▁▂▂▂▁▁▁▁▂▃▂▃▂</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>mean_reward_100</td><td>▁▁▁▁▁▁▂▂▂▃▃▄▅▅▅▅▅▆▆▆▅▆▅▅▆▆▇▇▇▆▆▇▇██▇▆▇▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>0.03654</td></tr><tr><td>avg_episode_reward</td><td>44.304</td></tr><tr><td>critic_loss</td><td>179.40695</td></tr><tr><td>entropy</td><td>0.37175</td></tr><tr><td>episode</td><td>975</td></tr><tr><td>mean_reward_100</td><td>22.892</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">PPO_batch64_rewards[5.0, -1.0, -0.2]_3actions</strong> at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/rg02qdqe' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/rg02qdqe</a><br> View project at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251113_234726-rg02qdqe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -1.0, -0.2], \n",
    "    'action_space': gym.spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "LR = 3e-4\n",
    "MAX_EPISODES = 1000\n",
    "NUM_STEPS = 512  # Start with smaller rollout for testing\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "env = GlobalAwareGlioblastoma(*train_pairs[0], **CURRENT_CONFIG)\n",
    "model = GlobalAwarePPOActorCritic(env, learning_rate=LR, device='cpu')\n",
    "agent = GlobalAwarePPOAgent(\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    model=model,\n",
    "    train_pairs=train_pairs,\n",
    "    env_class=GlobalAwareGlioblastoma,  # Use the new environment class\n",
    "    gamma=0.99,\n",
    "    clip_epsilon=0.2,\n",
    "    ppo_epochs=4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "\n",
    "wandb.init(project=\"TFG_Glioblastoma_PPO\", \n",
    "           name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\",\n",
    "           config={\n",
    "               \"learning_rate\": LR,\n",
    "               \"max_episodes\": MAX_EPISODES,\n",
    "               \"num_steps\": NUM_STEPS,\n",
    "               \"batch_size\": BATCH_SIZE,\n",
    "               \"configuration\": CURRENT_CONFIG\n",
    "           })\n",
    "\n",
    "# Start training\n",
    "agent.train(max_episodes=MAX_EPISODES, num_steps=NUM_STEPS)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e01bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 100 pairs out of 100 listed in CSV.\n",
      "Saved GIF for episode 0 at GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_0_002_58.gif\n",
      "Saved GIF for episode 10 at GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_10_013_86.gif\n",
      "Saved GIF for episode 20 at GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_20_024_49.gif\n",
      "Saved GIF for episode 30 at GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_30_038_84.gif\n",
      "Saved GIF for episode 40 at GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_40_052_98.gif\n",
      "Saved GIF for episode 50 at GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_50_104_74.gif\n",
      "Saved GIF for episode 60 at GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_60_176_99.gif\n",
      "Saved GIF for episode 70 at GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_70_204_52.gif\n",
      "Saved GIF for episode 80 at GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_80_260_62.gif\n",
      "Saved GIF for episode 90 at GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_90_300_107.gif\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS (PPO Agent)\n",
      "============================================================\n",
      "Success Rate: 43.00%\n",
      "Average Episode Reward: 28.52\n",
      "Average Steps to Find Tumor: 8.57\n",
      "Average Tumor Rewards per Episode: 7.69\n",
      "Tumor Size Statistics:\n",
      "  Biggest Tumor: 4910 pixels (8.52%)\n",
      "  Smallest Tumor: 296 pixels (0.51%)\n",
      "  Average Tumor: 1873 pixels (3.25%)\n",
      "Overall Action Distribution: [0.6835 0.131  0.1855]\n",
      "  Successful Episodes: [0.84534884 0.08837209 0.06627907]\n",
      "  Unsuccessful Episodes: [0.56140351 0.16315789 0.2754386 ]\n",
      "\n",
      "Detailed Results for 100 episodes:\n",
      "--------------------------------------------------------------------------------\n",
      "Episode 0: 002_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2049 pixels (3.56%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_0_002_58.gif\n",
      "\n",
      "Episode 1: 004_87.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 2727 pixels (4.73%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_1_004_87.gif\n",
      "\n",
      "Episode 2: 005_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 15\n",
      "  Tumor Size: 768 pixels (1.33%)\n",
      "  Action Distribution: [0.55 0.15 0.3 ]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_2_005_94.gif\n",
      "\n",
      "Episode 3: 006_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2834 pixels (4.92%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_3_006_83.gif\n",
      "\n",
      "Episode 4: 007_54.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1299 pixels (2.26%)\n",
      "  Action Distribution: [0.7  0.15 0.15]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_4_007_54.gif\n",
      "\n",
      "Episode 5: 008_41.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 2\n",
      "  Tumor Size: 1243 pixels (2.16%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_5_008_41.gif\n",
      "\n",
      "Episode 6: 009_65.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 41.60, Steps to Find: 2\n",
      "  Tumor Size: 4172 pixels (7.24%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_6_009_65.gif\n",
      "\n",
      "Episode 7: 010_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 1327 pixels (2.30%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_7_010_89.gif\n",
      "\n",
      "Episode 8: 011_103.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 831 pixels (1.44%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_8_011_103.gif\n",
      "\n",
      "Episode 9: 012_69.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -11.60, Steps to Find: 20\n",
      "  Tumor Size: 1365 pixels (2.37%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_9_012_69.gif\n",
      "\n",
      "Episode 10: 013_86.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -0.40, Steps to Find: 2\n",
      "  Tumor Size: 1536 pixels (2.67%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_10_013_86.gif\n",
      "\n",
      "Episode 11: 014_46.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.00, Steps to Find: 2\n",
      "  Tumor Size: 2035 pixels (3.53%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_11_014_46.gif\n",
      "\n",
      "Episode 12: 015_71.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 29.60, Steps to Find: 13\n",
      "  Tumor Size: 2195 pixels (3.81%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_12_015_71.gif\n",
      "\n",
      "Episode 13: 016_95.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 2\n",
      "  Tumor Size: 2999 pixels (5.21%)\n",
      "  Action Distribution: [0.  0.4 0.6]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_13_016_95.gif\n",
      "\n",
      "Episode 14: 017_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 2255 pixels (3.91%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_14_017_68.gif\n",
      "\n",
      "Episode 15: 018_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 35.60, Steps to Find: 2\n",
      "  Tumor Size: 1676 pixels (2.91%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_15_018_84.gif\n",
      "\n",
      "Episode 16: 019_52.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 12.40, Steps to Find: 16\n",
      "  Tumor Size: 1280 pixels (2.22%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_16_019_52.gif\n",
      "\n",
      "Episode 17: 021_96.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 2\n",
      "  Tumor Size: 867 pixels (1.51%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_17_021_96.gif\n",
      "\n",
      "Episode 18: 022_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1566 pixels (2.72%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_18_022_89.gif\n",
      "\n",
      "Episode 19: 023_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1119 pixels (1.94%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_19_023_98.gif\n",
      "\n",
      "Episode 20: 024_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 11\n",
      "  Tumor Size: 1338 pixels (2.32%)\n",
      "  Action Distribution: [0.35 0.2  0.45]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_20_024_49.gif\n",
      "\n",
      "Episode 21: 026_43.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 663 pixels (1.15%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_21_026_43.gif\n",
      "\n",
      "Episode 22: 028_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 6\n",
      "  Tumor Size: 799 pixels (1.39%)\n",
      "  Action Distribution: [0.05 0.25 0.7 ]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_22_028_56.gif\n",
      "\n",
      "Episode 23: 030_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 1979 pixels (3.44%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_23_030_99.gif\n",
      "\n",
      "Episode 24: 030_115.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 2\n",
      "  Tumor Size: 611 pixels (1.06%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_24_030_115.gif\n",
      "\n",
      "Episode 25: 032_134.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 554 pixels (0.96%)\n",
      "  Action Distribution: [0.   0.45 0.55]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_25_032_134.gif\n",
      "\n",
      "Episode 26: 033_86.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.20, Steps to Find: 1\n",
      "  Tumor Size: 2788 pixels (4.84%)\n",
      "  Action Distribution: [0.2  0.15 0.65]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_26_033_86.gif\n",
      "\n",
      "Episode 27: 034_113.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 2141 pixels (3.72%)\n",
      "  Action Distribution: [0.  0.5 0.5]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_27_034_113.gif\n",
      "\n",
      "Episode 28: 035_40.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 837 pixels (1.45%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_28_035_40.gif\n",
      "\n",
      "Episode 29: 036_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 72.40, Steps to Find: 6\n",
      "  Tumor Size: 795 pixels (1.38%)\n",
      "  Action Distribution: [0.55 0.1  0.35]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_29_036_83.gif\n",
      "\n",
      "Episode 30: 038_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1720 pixels (2.99%)\n",
      "  Action Distribution: [0.  0.2 0.8]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_30_038_84.gif\n",
      "\n",
      "Episode 31: 040_46.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 3375 pixels (5.86%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_31_040_46.gif\n",
      "\n",
      "Episode 32: 043_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 2\n",
      "  Tumor Size: 1217 pixels (2.11%)\n",
      "  Action Distribution: [0.   0.35 0.65]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_32_043_48.gif\n",
      "\n",
      "Episode 33: 045_57.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 473 pixels (0.82%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_33_045_57.gif\n",
      "\n",
      "Episode 34: 045_82.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 56.00, Steps to Find: 5\n",
      "  Tumor Size: 2259 pixels (3.92%)\n",
      "  Action Distribution: [0.6 0.2 0.2]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_34_045_82.gif\n",
      "\n",
      "Episode 35: 046_44.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 5\n",
      "  Tumor Size: 1147 pixels (1.99%)\n",
      "  Action Distribution: [0.35 0.15 0.5 ]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_35_046_44.gif\n",
      "\n",
      "Episode 36: 048_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 3\n",
      "  Tumor Size: 1308 pixels (2.27%)\n",
      "  Action Distribution: [0.1 0.4 0.5]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_36_048_49.gif\n",
      "\n",
      "Episode 37: 049_81.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 60.40, Steps to Find: 6\n",
      "  Tumor Size: 1649 pixels (2.86%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_37_049_81.gif\n",
      "\n",
      "Episode 38: 050_60.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 20.00, Steps to Find: 2\n",
      "  Tumor Size: 2312 pixels (4.01%)\n",
      "  Action Distribution: [0.6  0.15 0.25]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_38_050_60.gif\n",
      "\n",
      "Episode 39: 051_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 36.40, Steps to Find: 2\n",
      "  Tumor Size: 3155 pixels (5.48%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_39_051_94.gif\n",
      "\n",
      "Episode 40: 052_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.00, Steps to Find: 4\n",
      "  Tumor Size: 1228 pixels (2.13%)\n",
      "  Action Distribution: [0.  0.4 0.6]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_40_052_98.gif\n",
      "\n",
      "Episode 41: 053_85.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2915 pixels (5.06%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_41_053_85.gif\n",
      "\n",
      "Episode 42: 054_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 54.40, Steps to Find: 2\n",
      "  Tumor Size: 2098 pixels (3.64%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_42_054_61.gif\n",
      "\n",
      "Episode 43: 055_61.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 84.40, Steps to Find: 3\n",
      "  Tumor Size: 2578 pixels (4.48%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_43_055_61.gif\n",
      "\n",
      "Episode 44: 057_124.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 5\n",
      "  Tumor Size: 1433 pixels (2.49%)\n",
      "  Action Distribution: [0.05 0.35 0.6 ]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_44_057_124.gif\n",
      "\n",
      "Episode 45: 058_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1231 pixels (2.14%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_45_058_84.gif\n",
      "\n",
      "Episode 46: 059_67.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.00, Steps to Find: 9\n",
      "  Tumor Size: 730 pixels (1.27%)\n",
      "  Action Distribution: [0.3  0.25 0.45]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_46_059_67.gif\n",
      "\n",
      "Episode 47: 066_116.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 674 pixels (1.17%)\n",
      "  Action Distribution: [0.45 0.25 0.3 ]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_47_066_116.gif\n",
      "\n",
      "Episode 48: 090_73.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.80, Steps to Find: 12\n",
      "  Tumor Size: 1051 pixels (1.82%)\n",
      "  Action Distribution: [0.4 0.1 0.5]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_48_090_73.gif\n",
      "\n",
      "Episode 49: 092_94.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1658 pixels (2.88%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_49_092_94.gif\n",
      "\n",
      "Episode 50: 104_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 3423 pixels (5.94%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_50_104_74.gif\n",
      "\n",
      "Episode 51: 116_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 8.00, Steps to Find: 2\n",
      "  Tumor Size: 1855 pixels (3.22%)\n",
      "  Action Distribution: [0.3  0.25 0.45]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_51_116_58.gif\n",
      "\n",
      "Episode 52: 119_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1148 pixels (1.99%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_52_119_53.gif\n",
      "\n",
      "Episode 53: 130_39.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.80, Steps to Find: 2\n",
      "  Tumor Size: 742 pixels (1.29%)\n",
      "  Action Distribution: [0.7 0.2 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_53_130_39.gif\n",
      "\n",
      "Episode 54: 147_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 2935 pixels (5.10%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_54_147_83.gif\n",
      "\n",
      "Episode 55: 154_87.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1443 pixels (2.51%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_55_154_87.gif\n",
      "\n",
      "Episode 56: 155_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1005 pixels (1.74%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_56_155_48.gif\n",
      "\n",
      "Episode 57: 160_82.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2528 pixels (4.39%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_57_160_82.gif\n",
      "\n",
      "Episode 58: 163_101.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 3132 pixels (5.44%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_58_163_101.gif\n",
      "\n",
      "Episode 59: 171_69.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1076 pixels (1.87%)\n",
      "  Action Distribution: [0.05 0.15 0.8 ]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_59_171_69.gif\n",
      "\n",
      "Episode 60: 176_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 2223 pixels (3.86%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_60_176_99.gif\n",
      "\n",
      "Episode 61: 177_57.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 823 pixels (1.43%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_61_177_57.gif\n",
      "\n",
      "Episode 62: 178_85.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 4\n",
      "  Tumor Size: 2286 pixels (3.97%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_62_178_85.gif\n",
      "\n",
      "Episode 63: 179_70.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1958 pixels (3.40%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_63_179_70.gif\n",
      "\n",
      "Episode 64: 180_50.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2855 pixels (4.96%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_64_180_50.gif\n",
      "\n",
      "Episode 65: 180_72.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 2771 pixels (4.81%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_65_180_72.gif\n",
      "\n",
      "Episode 66: 184_36.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -0.40, Steps to Find: 2\n",
      "  Tumor Size: 296 pixels (0.51%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_66_184_36.gif\n",
      "\n",
      "Episode 67: 188_62.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 1754 pixels (3.05%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_67_188_62.gif\n",
      "\n",
      "Episode 68: 190_81.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 6.40, Steps to Find: 17\n",
      "  Tumor Size: 987 pixels (1.71%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_68_190_81.gif\n",
      "\n",
      "Episode 69: 200_45.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 1239 pixels (2.15%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_69_200_45.gif\n",
      "\n",
      "Episode 70: 204_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 6.40, Steps to Find: 2\n",
      "  Tumor Size: 893 pixels (1.55%)\n",
      "  Action Distribution: [0.75 0.1  0.15]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_70_204_52.gif\n",
      "\n",
      "Episode 71: 226_66.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2037 pixels (3.54%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_71_226_66.gif\n",
      "\n",
      "Episode 72: 227_60.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.00, Steps to Find: 20\n",
      "  Tumor Size: 1494 pixels (2.59%)\n",
      "  Action Distribution: [0.  0.1 0.9]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_72_227_60.gif\n",
      "\n",
      "Episode 73: 231_90.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 77.60, Steps to Find: 2\n",
      "  Tumor Size: 3297 pixels (5.72%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_73_231_90.gif\n",
      "\n",
      "Episode 74: 236_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.00, Steps to Find: 20\n",
      "  Tumor Size: 2498 pixels (4.34%)\n",
      "  Action Distribution: [0.65 0.1  0.25]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_74_236_58.gif\n",
      "\n",
      "Episode 75: 237_41.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 840 pixels (1.46%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_75_237_41.gif\n",
      "\n",
      "Episode 76: 240_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2725 pixels (4.73%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_76_240_52.gif\n",
      "\n",
      "Episode 77: 245_35.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1257 pixels (2.18%)\n",
      "  Action Distribution: [0.65 0.15 0.2 ]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_77_245_35.gif\n",
      "\n",
      "Episode 78: 250_45.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -11.60, Steps to Find: 3\n",
      "  Tumor Size: 1616 pixels (2.81%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_78_250_45.gif\n",
      "\n",
      "Episode 79: 255_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 3030 pixels (5.26%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_79_255_56.gif\n",
      "\n",
      "Episode 80: 260_62.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1653 pixels (2.87%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_80_260_62.gif\n",
      "\n",
      "Episode 81: 266_105.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 56.00, Steps to Find: 3\n",
      "  Tumor Size: 1725 pixels (2.99%)\n",
      "  Action Distribution: [0.55 0.15 0.3 ]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_81_266_105.gif\n",
      "\n",
      "Episode 82: 274_90.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 4092 pixels (7.10%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_82_274_90.gif\n",
      "\n",
      "Episode 83: 276_102.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 2\n",
      "  Tumor Size: 1831 pixels (3.18%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_83_276_102.gif\n",
      "\n",
      "Episode 84: 280_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 905 pixels (1.57%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_84_280_96.gif\n",
      "\n",
      "Episode 85: 282_53.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 1994 pixels (3.46%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_85_282_53.gif\n",
      "\n",
      "Episode 86: 284_88.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 22.80, Steps to Find: 1\n",
      "  Tumor Size: 4461 pixels (7.74%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_86_284_88.gif\n",
      "\n",
      "Episode 87: 287_97.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1807 pixels (3.14%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_87_287_97.gif\n",
      "\n",
      "Episode 88: 289_74.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 3435 pixels (5.96%)\n",
      "  Action Distribution: [0.   0.25 0.75]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_88_289_74.gif\n",
      "\n",
      "Episode 89: 299_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2607 pixels (4.53%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_89_299_97.gif\n",
      "\n",
      "Episode 90: 300_107.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -12.40, Steps to Find: 2\n",
      "  Tumor Size: 2216 pixels (3.85%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_90_300_107.gif\n",
      "\n",
      "Episode 91: 308_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 4910 pixels (8.52%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_91_308_88.gif\n",
      "\n",
      "Episode 92: 314_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 932 pixels (1.62%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_92_314_91.gif\n",
      "\n",
      "Episode 93: 326_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1227 pixels (2.13%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_93_326_68.gif\n",
      "\n",
      "Episode 94: 333_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 3974 pixels (6.90%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_94_333_91.gif\n",
      "\n",
      "Episode 95: 350_77.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 0.40, Steps to Find: 3\n",
      "  Tumor Size: 1879 pixels (3.26%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_95_350_77.gif\n",
      "\n",
      "Episode 96: 356_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 5\n",
      "  Tumor Size: 532 pixels (0.92%)\n",
      "  Action Distribution: [0.   0.35 0.65]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_96_356_97.gif\n",
      "\n",
      "Episode 97: 360_103.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 3331 pixels (5.78%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_97_360_103.gif\n",
      "\n",
      "Episode 98: 363_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 872 pixels (1.51%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_98_363_48.gif\n",
      "\n",
      "Episode 99: 365_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.00, Steps to Find: 2\n",
      "  Tumor Size: 3872 pixels (6.72%)\n",
      "  Action Distribution: [0.75 0.1  0.15]\n",
      "  GIF saved: GIFs_batch64_rewards[5.0, -1.0, -0.2]_3actions/episode_99_365_83.gif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_results = testing(\n",
    "    agent=agent,\n",
    "    test_pairs=prepare(mode=\"test\"),\n",
    "    agent_type=\"ppo\",\n",
    "    num_episodes=100,\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    save_gifs=True,\n",
    "    gif_folder=f\"GIFs_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "sucess[f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"] = overall_results['success_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "065bb6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/martina/codi2/4year/tfg/ppo/wandb/run-20251113_235154-rs6lpyng</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/rs6lpyng' target=\"_blank\">PPO_batch32_rewards[5.0, -1.0, -0.2]_3actions</a></strong> to <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/rs6lpyng' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/rs6lpyng</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Global-Aware PPO training...\n",
      "Episode 0 | Avg Reward: -4.82 | Mean Reward (100): -4.82 | Actor Loss: -0.0617\n",
      "New best model saved!\n",
      "Episode 25 | Avg Reward: -1.55 | Mean Reward (100): -3.18 | Actor Loss: 0.0289\n",
      "New best model saved!\n",
      "Episode 50 | Avg Reward: -5.09 | Mean Reward (100): -3.82 | Actor Loss: -0.0207\n",
      "Episode 75 | Avg Reward: -8.98 | Mean Reward (100): -5.11 | Actor Loss: 0.0223\n",
      "Episode 100 | Avg Reward: -8.11 | Mean Reward (100): -5.93 | Actor Loss: 0.0050\n",
      "Episode 125 | Avg Reward: -6.16 | Mean Reward (100): -7.08 | Actor Loss: 0.0579\n",
      "Episode 150 | Avg Reward: -6.43 | Mean Reward (100): -7.42 | Actor Loss: 0.0434\n",
      "Episode 175 | Avg Reward: 5.73 | Mean Reward (100): -3.74 | Actor Loss: -0.1008\n",
      "Episode 200 | Avg Reward: 15.76 | Mean Reward (100): 2.22 | Actor Loss: 0.0072\n",
      "New best model saved!\n",
      "Episode 225 | Avg Reward: 35.76 | Mean Reward (100): 12.70 | Actor Loss: -0.0476\n",
      "New best model saved!\n",
      "Episode 250 | Avg Reward: 17.25 | Mean Reward (100): 18.62 | Actor Loss: 0.0317\n",
      "New best model saved!\n",
      "Episode 275 | Avg Reward: 17.20 | Mean Reward (100): 21.49 | Actor Loss: -0.0107\n",
      "New best model saved!\n",
      "Episode 300 | Avg Reward: 31.73 | Mean Reward (100): 25.48 | Actor Loss: -0.0454\n",
      "New best model saved!\n",
      "Episode 325 | Avg Reward: 18.43 | Mean Reward (100): 21.15 | Actor Loss: 0.0055\n",
      "Episode 350 | Avg Reward: 22.18 | Mean Reward (100): 22.38 | Actor Loss: -0.0167\n",
      "Episode 375 | Avg Reward: 28.77 | Mean Reward (100): 25.28 | Actor Loss: -0.0456\n",
      "Episode 400 | Avg Reward: 23.84 | Mean Reward (100): 23.30 | Actor Loss: 0.0068\n",
      "Episode 425 | Avg Reward: 4.22 | Mean Reward (100): 19.75 | Actor Loss: -0.0942\n",
      "Episode 450 | Avg Reward: 31.50 | Mean Reward (100): 22.08 | Actor Loss: 0.0109\n",
      "Episode 475 | Avg Reward: 30.46 | Mean Reward (100): 22.51 | Actor Loss: 0.0341\n",
      "Episode 500 | Avg Reward: 30.90 | Mean Reward (100): 24.27 | Actor Loss: -0.0068\n",
      "Episode 525 | Avg Reward: 25.54 | Mean Reward (100): 29.60 | Actor Loss: -0.0386\n",
      "New best model saved!\n",
      "Episode 550 | Avg Reward: 39.04 | Mean Reward (100): 31.48 | Actor Loss: -0.0046\n",
      "New best model saved!\n",
      "Episode 575 | Avg Reward: 19.58 | Mean Reward (100): 28.76 | Actor Loss: 0.0166\n",
      "Episode 600 | Avg Reward: 32.19 | Mean Reward (100): 29.09 | Actor Loss: -0.0159\n",
      "Episode 625 | Avg Reward: 36.67 | Mean Reward (100): 31.87 | Actor Loss: -0.0300\n",
      "New best model saved!\n",
      "Episode 650 | Avg Reward: 32.03 | Mean Reward (100): 30.12 | Actor Loss: -0.0047\n",
      "Episode 675 | Avg Reward: 28.35 | Mean Reward (100): 32.31 | Actor Loss: -0.0027\n",
      "New best model saved!\n",
      "Episode 700 | Avg Reward: 43.20 | Mean Reward (100): 35.06 | Actor Loss: 0.0013\n",
      "New best model saved!\n",
      "Episode 725 | Avg Reward: 29.58 | Mean Reward (100): 33.29 | Actor Loss: 0.0346\n",
      "Episode 750 | Avg Reward: 42.24 | Mean Reward (100): 35.84 | Actor Loss: -0.0164\n",
      "New best model saved!\n",
      "Episode 775 | Avg Reward: 40.61 | Mean Reward (100): 38.91 | Actor Loss: -0.0567\n",
      "New best model saved!\n",
      "Episode 800 | Avg Reward: 61.78 | Mean Reward (100): 43.55 | Actor Loss: -0.0544\n",
      "New best model saved!\n",
      "Episode 825 | Avg Reward: 56.85 | Mean Reward (100): 50.37 | Actor Loss: 0.0070\n",
      "New best model saved!\n",
      "Episode 850 | Avg Reward: 30.27 | Mean Reward (100): 47.38 | Actor Loss: 0.0414\n",
      "Episode 875 | Avg Reward: 32.90 | Mean Reward (100): 45.45 | Actor Loss: -0.0155\n",
      "Episode 900 | Avg Reward: 26.37 | Mean Reward (100): 36.60 | Actor Loss: 0.0230\n",
      "Episode 925 | Avg Reward: 62.10 | Mean Reward (100): 37.91 | Actor Loss: 0.0051\n",
      "Episode 950 | Avg Reward: 43.20 | Mean Reward (100): 41.14 | Actor Loss: -0.0399\n",
      "Episode 975 | Avg Reward: 60.03 | Mean Reward (100): 47.92 | Actor Loss: 0.0168\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▃▇▅▆▆█▇▁▆▃▇▅▃▆▅▃▆▁▆▇▅▄▅▆▅▄▅▅▆▇▅▃▃▆▇▅▆▆▄▆</td></tr><tr><td>avg_episode_reward</td><td>▁▂▁▁▁▁▁▂▃▅▄▄▅▄▄▅▄▂▅▅▅▄▆▄▅▅▅▅▆▅▆▆█▇▅▅▄█▆█</td></tr><tr><td>critic_loss</td><td>▂▂▁▁▁▁▁▂▄▆▄▅▇▅▆▇▇▃▆▇▅▆▆▅▇▆▇▆▇▆▇▇██▇█▇▇▆▇</td></tr><tr><td>entropy</td><td>███████▇▆▄▃▃▃▂▁▂▂▄▃▃▂▂▂▃▃▃▃▃▂▃▂▂▁▁▂▂▂▂▂▁</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>mean_reward_100</td><td>▁▂▁▁▁▁▁▁▂▃▄▅▅▄▅▅▅▄▅▅▅▅▆▅▅▆▆▆▆▆▆▇▇██▇▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>0.0168</td></tr><tr><td>avg_episode_reward</td><td>60.032</td></tr><tr><td>critic_loss</td><td>210.38103</td></tr><tr><td>entropy</td><td>0.1874</td></tr><tr><td>episode</td><td>975</td></tr><tr><td>mean_reward_100</td><td>47.924</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">PPO_batch32_rewards[5.0, -1.0, -0.2]_3actions</strong> at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/rs6lpyng' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/rs6lpyng</a><br> View project at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251113_235154-rs6lpyng/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -1.0, -0.2], \n",
    "    'action_space': gym.spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "LR = 3e-4\n",
    "MAX_EPISODES = 1000\n",
    "NUM_STEPS = 512  # Start with smaller rollout for testing\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "env = GlobalAwareGlioblastoma(*train_pairs[0], **CURRENT_CONFIG)\n",
    "model = GlobalAwarePPOActorCritic(env, learning_rate=LR, device='cpu')\n",
    "agent = GlobalAwarePPOAgent(\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    model=model,\n",
    "    train_pairs=train_pairs,\n",
    "    env_class=GlobalAwareGlioblastoma,  # Use the new environment class\n",
    "    gamma=0.99,\n",
    "    clip_epsilon=0.2,\n",
    "    ppo_epochs=4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "\n",
    "wandb.init(project=\"TFG_Glioblastoma_PPO\",\n",
    "           name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\",\n",
    "           config={\n",
    "               \"learning_rate\": LR,\n",
    "               \"max_episodes\": MAX_EPISODES,\n",
    "               \"num_steps\": NUM_STEPS,\n",
    "               \"batch_size\": BATCH_SIZE,\n",
    "               \"configuration\": CURRENT_CONFIG\n",
    "           })\n",
    "\n",
    "# Start training\n",
    "agent.train(max_episodes=MAX_EPISODES, num_steps=NUM_STEPS)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89335955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 100 pairs out of 100 listed in CSV.\n",
      "Saved GIF for episode 0 at GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_0_002_58.gif\n",
      "Saved GIF for episode 10 at GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_10_013_86.gif\n",
      "Saved GIF for episode 20 at GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_20_024_49.gif\n",
      "Saved GIF for episode 30 at GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_30_038_84.gif\n",
      "Saved GIF for episode 40 at GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_40_052_98.gif\n",
      "Saved GIF for episode 50 at GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_50_104_74.gif\n",
      "Saved GIF for episode 60 at GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_60_176_99.gif\n",
      "Saved GIF for episode 70 at GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_70_204_52.gif\n",
      "Saved GIF for episode 80 at GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_80_260_62.gif\n",
      "Saved GIF for episode 90 at GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_90_300_107.gif\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS (PPO Agent)\n",
      "============================================================\n",
      "Success Rate: 46.00%\n",
      "Average Episode Reward: 28.33\n",
      "Average Steps to Find Tumor: 7.70\n",
      "Average Tumor Rewards per Episode: 7.66\n",
      "Tumor Size Statistics:\n",
      "  Biggest Tumor: 4910 pixels (8.52%)\n",
      "  Smallest Tumor: 296 pixels (0.51%)\n",
      "  Average Tumor: 1873 pixels (3.25%)\n",
      "Overall Action Distribution: [0.713 0.167 0.12 ]\n",
      "  Successful Episodes: [0.83478261 0.08586957 0.07934783]\n",
      "  Unsuccessful Episodes: [0.60925926 0.23611111 0.15462963]\n",
      "\n",
      "Detailed Results for 100 episodes:\n",
      "--------------------------------------------------------------------------------\n",
      "Episode 0: 002_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2049 pixels (3.56%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_0_002_58.gif\n",
      "\n",
      "Episode 1: 004_87.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 72.40, Steps to Find: 6\n",
      "  Tumor Size: 2727 pixels (4.73%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_1_004_87.gif\n",
      "\n",
      "Episode 2: 005_94.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 36.40, Steps to Find: 12\n",
      "  Tumor Size: 768 pixels (1.33%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_2_005_94.gif\n",
      "\n",
      "Episode 3: 006_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 71.60, Steps to Find: 3\n",
      "  Tumor Size: 2834 pixels (4.92%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_3_006_83.gif\n",
      "\n",
      "Episode 4: 007_54.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 5\n",
      "  Tumor Size: 1299 pixels (2.26%)\n",
      "  Action Distribution: [0.1  0.75 0.15]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_4_007_54.gif\n",
      "\n",
      "Episode 5: 008_41.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -11.60, Steps to Find: 2\n",
      "  Tumor Size: 1243 pixels (2.16%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_5_008_41.gif\n",
      "\n",
      "Episode 6: 009_65.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -11.60, Steps to Find: 2\n",
      "  Tumor Size: 4172 pixels (7.24%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_6_009_65.gif\n",
      "\n",
      "Episode 7: 010_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 4\n",
      "  Tumor Size: 1327 pixels (2.30%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_7_010_89.gif\n",
      "\n",
      "Episode 8: 011_103.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 66.40, Steps to Find: 7\n",
      "  Tumor Size: 831 pixels (1.44%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_8_011_103.gif\n",
      "\n",
      "Episode 9: 012_69.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 47.60, Steps to Find: 10\n",
      "  Tumor Size: 1365 pixels (2.37%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_9_012_69.gif\n",
      "\n",
      "Episode 10: 013_86.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 2\n",
      "  Tumor Size: 1536 pixels (2.67%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_10_013_86.gif\n",
      "\n",
      "Episode 11: 014_46.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 2035 pixels (3.53%)\n",
      "  Action Distribution: [0.1 0.4 0.5]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_11_014_46.gif\n",
      "\n",
      "Episode 12: 015_71.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 41.60, Steps to Find: 11\n",
      "  Tumor Size: 2195 pixels (3.81%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_12_015_71.gif\n",
      "\n",
      "Episode 13: 016_95.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 2\n",
      "  Tumor Size: 2999 pixels (5.21%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_13_016_95.gif\n",
      "\n",
      "Episode 14: 017_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 2255 pixels (3.91%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_14_017_68.gif\n",
      "\n",
      "Episode 15: 018_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -16.80, Steps to Find: 2\n",
      "  Tumor Size: 1676 pixels (2.91%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_15_018_84.gif\n",
      "\n",
      "Episode 16: 019_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1280 pixels (2.22%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_16_019_52.gif\n",
      "\n",
      "Episode 17: 021_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 867 pixels (1.51%)\n",
      "  Action Distribution: [0.15 0.65 0.2 ]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_17_021_96.gif\n",
      "\n",
      "Episode 18: 022_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1566 pixels (2.72%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_18_022_89.gif\n",
      "\n",
      "Episode 19: 023_98.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 72.40, Steps to Find: 5\n",
      "  Tumor Size: 1119 pixels (1.94%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_19_023_98.gif\n",
      "\n",
      "Episode 20: 024_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 6\n",
      "  Tumor Size: 1338 pixels (2.32%)\n",
      "  Action Distribution: [0.05 0.7  0.25]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_20_024_49.gif\n",
      "\n",
      "Episode 21: 026_43.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 2\n",
      "  Tumor Size: 663 pixels (1.15%)\n",
      "  Action Distribution: [0.25 0.4  0.35]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_21_026_43.gif\n",
      "\n",
      "Episode 22: 028_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 799 pixels (1.39%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_22_028_56.gif\n",
      "\n",
      "Episode 23: 030_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 4\n",
      "  Tumor Size: 1979 pixels (3.44%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_23_030_99.gif\n",
      "\n",
      "Episode 24: 030_115.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 2\n",
      "  Tumor Size: 611 pixels (1.06%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_24_030_115.gif\n",
      "\n",
      "Episode 25: 032_134.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 554 pixels (0.96%)\n",
      "  Action Distribution: [0.05 0.75 0.2 ]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_25_032_134.gif\n",
      "\n",
      "Episode 26: 033_86.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 1\n",
      "  Tumor Size: 2788 pixels (4.84%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_26_033_86.gif\n",
      "\n",
      "Episode 27: 034_113.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 4\n",
      "  Tumor Size: 2141 pixels (3.72%)\n",
      "  Action Distribution: [0.3 0.5 0.2]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_27_034_113.gif\n",
      "\n",
      "Episode 28: 035_40.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 88.80, Steps to Find: 3\n",
      "  Tumor Size: 837 pixels (1.45%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_28_035_40.gif\n",
      "\n",
      "Episode 29: 036_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.20, Steps to Find: 4\n",
      "  Tumor Size: 795 pixels (1.38%)\n",
      "  Action Distribution: [0.25 0.4  0.35]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_29_036_83.gif\n",
      "\n",
      "Episode 30: 038_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 1720 pixels (2.99%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_30_038_84.gif\n",
      "\n",
      "Episode 31: 040_46.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 3375 pixels (5.86%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_31_040_46.gif\n",
      "\n",
      "Episode 32: 043_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 12.40, Steps to Find: 2\n",
      "  Tumor Size: 1217 pixels (2.11%)\n",
      "  Action Distribution: [0.7 0.2 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_32_043_48.gif\n",
      "\n",
      "Episode 33: 045_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 473 pixels (0.82%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_33_045_57.gif\n",
      "\n",
      "Episode 34: 045_82.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 24.40, Steps to Find: 14\n",
      "  Tumor Size: 2259 pixels (3.92%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_34_045_82.gif\n",
      "\n",
      "Episode 35: 046_44.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 3\n",
      "  Tumor Size: 1147 pixels (1.99%)\n",
      "  Action Distribution: [0.3 0.3 0.4]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_35_046_44.gif\n",
      "\n",
      "Episode 36: 048_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 49.20, Steps to Find: 3\n",
      "  Tumor Size: 1308 pixels (2.27%)\n",
      "  Action Distribution: [0.45 0.3  0.25]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_36_048_49.gif\n",
      "\n",
      "Episode 37: 049_81.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 66.40, Steps to Find: 3\n",
      "  Tumor Size: 1649 pixels (2.86%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_37_049_81.gif\n",
      "\n",
      "Episode 38: 050_60.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 2\n",
      "  Tumor Size: 2312 pixels (4.01%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_38_050_60.gif\n",
      "\n",
      "Episode 39: 051_94.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 77.60, Steps to Find: 2\n",
      "  Tumor Size: 3155 pixels (5.48%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_39_051_94.gif\n",
      "\n",
      "Episode 40: 052_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 1228 pixels (2.13%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_40_052_98.gif\n",
      "\n",
      "Episode 41: 053_85.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 2\n",
      "  Tumor Size: 2915 pixels (5.06%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_41_053_85.gif\n",
      "\n",
      "Episode 42: 054_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 2\n",
      "  Tumor Size: 2098 pixels (3.64%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_42_054_61.gif\n",
      "\n",
      "Episode 43: 055_61.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 72.40, Steps to Find: 3\n",
      "  Tumor Size: 2578 pixels (4.48%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_43_055_61.gif\n",
      "\n",
      "Episode 44: 057_124.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 3\n",
      "  Tumor Size: 1433 pixels (2.49%)\n",
      "  Action Distribution: [0.1  0.45 0.45]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_44_057_124.gif\n",
      "\n",
      "Episode 45: 058_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1231 pixels (2.14%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_45_058_84.gif\n",
      "\n",
      "Episode 46: 059_67.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 730 pixels (1.27%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_46_059_67.gif\n",
      "\n",
      "Episode 47: 066_116.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 674 pixels (1.17%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_47_066_116.gif\n",
      "\n",
      "Episode 48: 090_73.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 1051 pixels (1.82%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_48_090_73.gif\n",
      "\n",
      "Episode 49: 092_94.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1658 pixels (2.88%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_49_092_94.gif\n",
      "\n",
      "Episode 50: 104_74.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.00, Steps to Find: 2\n",
      "  Tumor Size: 3423 pixels (5.94%)\n",
      "  Action Distribution: [0.25 0.35 0.4 ]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_50_104_74.gif\n",
      "\n",
      "Episode 51: 116_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.80, Steps to Find: 3\n",
      "  Tumor Size: 1855 pixels (3.22%)\n",
      "  Action Distribution: [0.7 0.2 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_51_116_58.gif\n",
      "\n",
      "Episode 52: 119_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1148 pixels (1.99%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_52_119_53.gif\n",
      "\n",
      "Episode 53: 130_39.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 3\n",
      "  Tumor Size: 742 pixels (1.29%)\n",
      "  Action Distribution: [0.1  0.75 0.15]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_53_130_39.gif\n",
      "\n",
      "Episode 54: 147_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2935 pixels (5.10%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_54_147_83.gif\n",
      "\n",
      "Episode 55: 154_87.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1443 pixels (2.51%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_55_154_87.gif\n",
      "\n",
      "Episode 56: 155_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1005 pixels (1.74%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_56_155_48.gif\n",
      "\n",
      "Episode 57: 160_82.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2528 pixels (4.39%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_57_160_82.gif\n",
      "\n",
      "Episode 58: 163_101.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.20, Steps to Find: 3\n",
      "  Tumor Size: 3132 pixels (5.44%)\n",
      "  Action Distribution: [0.2  0.45 0.35]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_58_163_101.gif\n",
      "\n",
      "Episode 59: 171_69.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -11.60, Steps to Find: 2\n",
      "  Tumor Size: 1076 pixels (1.87%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_59_171_69.gif\n",
      "\n",
      "Episode 60: 176_99.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 72.40, Steps to Find: 4\n",
      "  Tumor Size: 2223 pixels (3.86%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_60_176_99.gif\n",
      "\n",
      "Episode 61: 177_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 823 pixels (1.43%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_61_177_57.gif\n",
      "\n",
      "Episode 62: 178_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 2286 pixels (3.97%)\n",
      "  Action Distribution: [0.15 0.45 0.4 ]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_62_178_85.gif\n",
      "\n",
      "Episode 63: 179_70.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 72.40, Steps to Find: 5\n",
      "  Tumor Size: 1958 pixels (3.40%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_63_179_70.gif\n",
      "\n",
      "Episode 64: 180_50.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 2855 pixels (4.96%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_64_180_50.gif\n",
      "\n",
      "Episode 65: 180_72.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 23.60, Steps to Find: 1\n",
      "  Tumor Size: 2771 pixels (4.81%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_65_180_72.gif\n",
      "\n",
      "Episode 66: 184_36.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 77.60, Steps to Find: 2\n",
      "  Tumor Size: 296 pixels (0.51%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_66_184_36.gif\n",
      "\n",
      "Episode 67: 188_62.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 2\n",
      "  Tumor Size: 1754 pixels (3.05%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_67_188_62.gif\n",
      "\n",
      "Episode 68: 190_81.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 71.60, Steps to Find: 6\n",
      "  Tumor Size: 987 pixels (1.71%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_68_190_81.gif\n",
      "\n",
      "Episode 69: 200_45.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 83.60, Steps to Find: 2\n",
      "  Tumor Size: 1239 pixels (2.15%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_69_200_45.gif\n",
      "\n",
      "Episode 70: 204_52.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 893 pixels (1.55%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_70_204_52.gif\n",
      "\n",
      "Episode 71: 226_66.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 4\n",
      "  Tumor Size: 2037 pixels (3.54%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_71_226_66.gif\n",
      "\n",
      "Episode 72: 227_60.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 0.40, Steps to Find: 3\n",
      "  Tumor Size: 1494 pixels (2.59%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_72_227_60.gif\n",
      "\n",
      "Episode 73: 231_90.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 3297 pixels (5.72%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_73_231_90.gif\n",
      "\n",
      "Episode 74: 236_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 2\n",
      "  Tumor Size: 2498 pixels (4.34%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_74_236_58.gif\n",
      "\n",
      "Episode 75: 237_41.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 7.20, Steps to Find: 3\n",
      "  Tumor Size: 840 pixels (1.46%)\n",
      "  Action Distribution: [0.45 0.45 0.1 ]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_75_237_41.gif\n",
      "\n",
      "Episode 76: 240_52.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 2725 pixels (4.73%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_76_240_52.gif\n",
      "\n",
      "Episode 77: 245_35.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.00, Steps to Find: 20\n",
      "  Tumor Size: 1257 pixels (2.18%)\n",
      "  Action Distribution: [0.4 0.5 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_77_245_35.gif\n",
      "\n",
      "Episode 78: 250_45.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 6\n",
      "  Tumor Size: 1616 pixels (2.81%)\n",
      "  Action Distribution: [0.   0.45 0.55]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_78_250_45.gif\n",
      "\n",
      "Episode 79: 255_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 3030 pixels (5.26%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_79_255_56.gif\n",
      "\n",
      "Episode 80: 260_62.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 2\n",
      "  Tumor Size: 1653 pixels (2.87%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_80_260_62.gif\n",
      "\n",
      "Episode 81: 266_105.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1725 pixels (2.99%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_81_266_105.gif\n",
      "\n",
      "Episode 82: 274_90.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.00, Steps to Find: 20\n",
      "  Tumor Size: 4092 pixels (7.10%)\n",
      "  Action Distribution: [0.5 0.4 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_82_274_90.gif\n",
      "\n",
      "Episode 83: 276_102.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.00, Steps to Find: 3\n",
      "  Tumor Size: 1831 pixels (3.18%)\n",
      "  Action Distribution: [0.75 0.1  0.15]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_83_276_102.gif\n",
      "\n",
      "Episode 84: 280_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 905 pixels (1.57%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_84_280_96.gif\n",
      "\n",
      "Episode 85: 282_53.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 4\n",
      "  Tumor Size: 1994 pixels (3.46%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_85_282_53.gif\n",
      "\n",
      "Episode 86: 284_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 4461 pixels (7.74%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_86_284_88.gif\n",
      "\n",
      "Episode 87: 287_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 1807 pixels (3.14%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_87_287_97.gif\n",
      "\n",
      "Episode 88: 289_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -11.60, Steps to Find: 2\n",
      "  Tumor Size: 3435 pixels (5.96%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_88_289_74.gif\n",
      "\n",
      "Episode 89: 299_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2607 pixels (4.53%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_89_299_97.gif\n",
      "\n",
      "Episode 90: 300_107.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2216 pixels (3.85%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_90_300_107.gif\n",
      "\n",
      "Episode 91: 308_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 4910 pixels (8.52%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_91_308_88.gif\n",
      "\n",
      "Episode 92: 314_91.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 84.40, Steps to Find: 4\n",
      "  Tumor Size: 932 pixels (1.62%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_92_314_91.gif\n",
      "\n",
      "Episode 93: 326_68.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 54.40, Steps to Find: 9\n",
      "  Tumor Size: 1227 pixels (2.13%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_93_326_68.gif\n",
      "\n",
      "Episode 94: 333_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 3974 pixels (6.90%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_94_333_91.gif\n",
      "\n",
      "Episode 95: 350_77.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 1879 pixels (3.26%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_95_350_77.gif\n",
      "\n",
      "Episode 96: 356_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 532 pixels (0.92%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_96_356_97.gif\n",
      "\n",
      "Episode 97: 360_103.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 3331 pixels (5.78%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_97_360_103.gif\n",
      "\n",
      "Episode 98: 363_48.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 872 pixels (1.51%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_98_363_48.gif\n",
      "\n",
      "Episode 99: 365_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 2\n",
      "  Tumor Size: 3872 pixels (6.72%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch32_rewards[5.0, -1.0, -0.2]_3actions/episode_99_365_83.gif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_results = testing(\n",
    "    agent=agent,\n",
    "    test_pairs=prepare(mode=\"test\"),\n",
    "    agent_type=\"ppo\",\n",
    "    num_episodes=100,\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    save_gifs=True,\n",
    "    gif_folder=f\"GIFs_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "sucess[f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"] = overall_results['success_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3990801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/martina/codi2/4year/tfg/ppo/wandb/run-20251113_235836-ycmfsc4b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/ycmfsc4b' target=\"_blank\">PPO_batch128_rewards[5.0, -1.0, -0.2]_3actions</a></strong> to <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/ycmfsc4b' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/ycmfsc4b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Global-Aware PPO training...\n",
      "Episode 0 | Avg Reward: -8.96 | Mean Reward (100): -8.96 | Actor Loss: 0.0004\n",
      "New best model saved!\n",
      "Episode 25 | Avg Reward: -9.78 | Mean Reward (100): -9.37 | Actor Loss: -0.0080\n",
      "Episode 50 | Avg Reward: -7.89 | Mean Reward (100): -8.87 | Actor Loss: -0.0009\n",
      "New best model saved!\n",
      "Episode 75 | Avg Reward: -8.61 | Mean Reward (100): -8.81 | Actor Loss: 0.0062\n",
      "New best model saved!\n",
      "Episode 100 | Avg Reward: -5.07 | Mean Reward (100): -7.84 | Actor Loss: 0.0197\n",
      "New best model saved!\n",
      "Episode 125 | Avg Reward: -7.36 | Mean Reward (100): -7.23 | Actor Loss: 0.0011\n",
      "New best model saved!\n",
      "Episode 150 | Avg Reward: -5.86 | Mean Reward (100): -6.72 | Actor Loss: -0.0043\n",
      "New best model saved!\n",
      "Episode 175 | Avg Reward: -7.68 | Mean Reward (100): -6.49 | Actor Loss: -0.0125\n",
      "New best model saved!\n",
      "Episode 200 | Avg Reward: -8.66 | Mean Reward (100): -7.39 | Actor Loss: -0.0285\n",
      "Episode 225 | Avg Reward: -5.78 | Mean Reward (100): -6.99 | Actor Loss: -0.0089\n",
      "Episode 250 | Avg Reward: -0.34 | Mean Reward (100): -5.61 | Actor Loss: -0.0170\n",
      "New best model saved!\n",
      "Episode 275 | Avg Reward: -0.94 | Mean Reward (100): -3.93 | Actor Loss: 0.0041\n",
      "New best model saved!\n",
      "Episode 300 | Avg Reward: -0.50 | Mean Reward (100): -1.89 | Actor Loss: -0.0087\n",
      "New best model saved!\n",
      "Episode 325 | Avg Reward: 11.52 | Mean Reward (100): 2.44 | Actor Loss: 0.0298\n",
      "New best model saved!\n",
      "Episode 350 | Avg Reward: 19.02 | Mean Reward (100): 7.28 | Actor Loss: 0.0805\n",
      "New best model saved!\n",
      "Episode 375 | Avg Reward: 6.18 | Mean Reward (100): 9.06 | Actor Loss: 0.1635\n",
      "New best model saved!\n",
      "Episode 400 | Avg Reward: 10.91 | Mean Reward (100): 11.91 | Actor Loss: 0.0302\n",
      "New best model saved!\n",
      "Episode 425 | Avg Reward: 24.05 | Mean Reward (100): 15.04 | Actor Loss: 0.0045\n",
      "New best model saved!\n",
      "Episode 450 | Avg Reward: 11.52 | Mean Reward (100): 13.16 | Actor Loss: 0.0000\n",
      "Episode 475 | Avg Reward: 18.21 | Mean Reward (100): 16.17 | Actor Loss: 0.0109\n",
      "New best model saved!\n",
      "Episode 500 | Avg Reward: 14.70 | Mean Reward (100): 17.12 | Actor Loss: 0.0000\n",
      "New best model saved!\n",
      "Episode 525 | Avg Reward: 7.46 | Mean Reward (100): 12.97 | Actor Loss: 0.0534\n",
      "Episode 550 | Avg Reward: 13.58 | Mean Reward (100): 13.49 | Actor Loss: 0.0014\n",
      "Episode 575 | Avg Reward: -2.06 | Mean Reward (100): 8.42 | Actor Loss: -0.0092\n",
      "Episode 600 | Avg Reward: 6.70 | Mean Reward (100): 6.42 | Actor Loss: 0.0331\n",
      "Episode 625 | Avg Reward: 11.20 | Mean Reward (100): 7.36 | Actor Loss: -0.0034\n",
      "Episode 650 | Avg Reward: 23.82 | Mean Reward (100): 9.92 | Actor Loss: -0.0079\n",
      "Episode 675 | Avg Reward: 3.78 | Mean Reward (100): 11.38 | Actor Loss: 0.0005\n",
      "Episode 700 | Avg Reward: 25.68 | Mean Reward (100): 16.12 | Actor Loss: 0.0101\n",
      "Episode 725 | Avg Reward: 46.37 | Mean Reward (100): 24.91 | Actor Loss: 0.0254\n",
      "New best model saved!\n",
      "Episode 750 | Avg Reward: 35.33 | Mean Reward (100): 27.79 | Actor Loss: 0.0100\n",
      "New best model saved!\n",
      "Episode 775 | Avg Reward: 46.18 | Mean Reward (100): 38.39 | Actor Loss: 0.0147\n",
      "New best model saved!\n",
      "Episode 800 | Avg Reward: 24.61 | Mean Reward (100): 38.12 | Actor Loss: -0.0072\n",
      "Episode 825 | Avg Reward: 16.75 | Mean Reward (100): 30.72 | Actor Loss: 0.0127\n",
      "Episode 850 | Avg Reward: 3.90 | Mean Reward (100): 22.86 | Actor Loss: 0.0193\n",
      "Episode 875 | Avg Reward: 14.48 | Mean Reward (100): 14.94 | Actor Loss: 0.0413\n",
      "Episode 900 | Avg Reward: 16.48 | Mean Reward (100): 12.90 | Actor Loss: 0.0345\n",
      "Episode 925 | Avg Reward: 5.18 | Mean Reward (100): 10.01 | Actor Loss: 0.0378\n",
      "Episode 950 | Avg Reward: 22.46 | Mean Reward (100): 14.65 | Actor Loss: 0.0315\n",
      "Episode 975 | Avg Reward: 22.26 | Mean Reward (100): 16.60 | Actor Loss: 0.0154\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▂▂▂▂▃▂▂▂▁▂▁▂▂▃▅█▃▂▂▂▂▄▂▂▃▂▂▂▂▃▂▃▂▃▃▄▃▃▃▃</td></tr><tr><td>avg_episode_reward</td><td>▁▁▁▁▂▁▁▁▁▁▂▂▂▄▅▃▄▅▄▄▄▃▄▂▃▄▅▃▅█▇█▅▄▃▄▄▃▅▅</td></tr><tr><td>critic_loss</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▄▆▄▅▆▅▅▆▄▆▄▅▅▇▄▆█▆▇▆▇▅▄▅▃▆▅</td></tr><tr><td>entropy</td><td>████████▇▇▇▆▆▃▂▆▃▃▄▄▃▆▃▃▄▃▃▄▃▁▁▁▂▂▃▅▆▆▄▃</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>mean_reward_100</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▅▄▅▅▄▄▄▃▃▄▄▅▆▆██▇▆▅▄▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>0.01542</td></tr><tr><td>avg_episode_reward</td><td>22.256</td></tr><tr><td>critic_loss</td><td>163.41984</td></tr><tr><td>entropy</td><td>0.51148</td></tr><tr><td>episode</td><td>975</td></tr><tr><td>mean_reward_100</td><td>16.596</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">PPO_batch128_rewards[5.0, -1.0, -0.2]_3actions</strong> at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/ycmfsc4b' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/ycmfsc4b</a><br> View project at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251113_235836-ycmfsc4b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -1.0, -0.2], \n",
    "    'action_space': gym.spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "LR = 3e-4\n",
    "MAX_EPISODES = 1000\n",
    "NUM_STEPS = 512  # Start with smaller rollout for testing\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "env = GlobalAwareGlioblastoma(*train_pairs[0], **CURRENT_CONFIG)\n",
    "model = GlobalAwarePPOActorCritic(env, learning_rate=LR, device='cpu')\n",
    "agent = GlobalAwarePPOAgent(\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    model=model,\n",
    "    train_pairs=train_pairs,\n",
    "    env_class=GlobalAwareGlioblastoma,  # Use the new environment class\n",
    "    gamma=0.99,\n",
    "    clip_epsilon=0.2,\n",
    "    ppo_epochs=4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "\n",
    "wandb.init(project=\"TFG_Glioblastoma_PPO\", \n",
    "           name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\",\n",
    "           config={\n",
    "               \"learning_rate\": LR,\n",
    "               \"max_episodes\": MAX_EPISODES,\n",
    "               \"num_steps\": NUM_STEPS,\n",
    "               \"batch_size\": BATCH_SIZE,\n",
    "               \"configuration\": CURRENT_CONFIG\n",
    "           })\n",
    "\n",
    "# Start training\n",
    "agent.train(max_episodes=MAX_EPISODES, num_steps=NUM_STEPS)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6e4afec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 100 pairs out of 100 listed in CSV.\n",
      "Saved GIF for episode 0 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_0_002_58.gif\n",
      "Saved GIF for episode 10 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_10_013_86.gif\n",
      "Saved GIF for episode 20 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_20_024_49.gif\n",
      "Saved GIF for episode 30 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_30_038_84.gif\n",
      "Saved GIF for episode 40 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_40_052_98.gif\n",
      "Saved GIF for episode 50 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_50_104_74.gif\n",
      "Saved GIF for episode 60 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_60_176_99.gif\n",
      "Saved GIF for episode 70 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_70_204_52.gif\n",
      "Saved GIF for episode 80 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_80_260_62.gif\n",
      "Saved GIF for episode 90 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_90_300_107.gif\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS (PPO Agent)\n",
      "============================================================\n",
      "Success Rate: 30.00%\n",
      "Average Episode Reward: 5.39\n",
      "Average Steps to Find Tumor: 12.40\n",
      "Average Tumor Rewards per Episode: 3.79\n",
      "Tumor Size Statistics:\n",
      "  Biggest Tumor: 4910 pixels (8.52%)\n",
      "  Smallest Tumor: 296 pixels (0.51%)\n",
      "  Average Tumor: 1873 pixels (3.25%)\n",
      "Overall Action Distribution: [0.6785 0.155  0.1665]\n",
      "  Successful Episodes: [0.875      0.06333333 0.06166667]\n",
      "  Unsuccessful Episodes: [0.59428571 0.19428571 0.21142857]\n",
      "\n",
      "Detailed Results for 100 episodes:\n",
      "--------------------------------------------------------------------------------\n",
      "Episode 0: 002_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -17.60, Steps to Find: 3\n",
      "  Tumor Size: 2049 pixels (3.56%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_0_002_58.gif\n",
      "\n",
      "Episode 1: 004_87.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2727 pixels (4.73%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_1_004_87.gif\n",
      "\n",
      "Episode 2: 005_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 768 pixels (1.33%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_2_005_94.gif\n",
      "\n",
      "Episode 3: 006_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 2\n",
      "  Tumor Size: 2834 pixels (4.92%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_3_006_83.gif\n",
      "\n",
      "Episode 4: 007_54.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1299 pixels (2.26%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_4_007_54.gif\n",
      "\n",
      "Episode 5: 008_41.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1243 pixels (2.16%)\n",
      "  Action Distribution: [0.15 0.3  0.55]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_5_008_41.gif\n",
      "\n",
      "Episode 6: 009_65.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 4172 pixels (7.24%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_6_009_65.gif\n",
      "\n",
      "Episode 7: 010_89.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1327 pixels (2.30%)\n",
      "  Action Distribution: [0.1  0.45 0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_7_010_89.gif\n",
      "\n",
      "Episode 8: 011_103.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 831 pixels (1.44%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_8_011_103.gif\n",
      "\n",
      "Episode 9: 012_69.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1365 pixels (2.37%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_9_012_69.gif\n",
      "\n",
      "Episode 10: 013_86.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 2\n",
      "  Tumor Size: 1536 pixels (2.67%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_10_013_86.gif\n",
      "\n",
      "Episode 11: 014_46.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 2035 pixels (3.53%)\n",
      "  Action Distribution: [0.25 0.4  0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_11_014_46.gif\n",
      "\n",
      "Episode 12: 015_71.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 4\n",
      "  Tumor Size: 2195 pixels (3.81%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_12_015_71.gif\n",
      "\n",
      "Episode 13: 016_95.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 2\n",
      "  Tumor Size: 2999 pixels (5.21%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_13_016_95.gif\n",
      "\n",
      "Episode 14: 017_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 2255 pixels (3.91%)\n",
      "  Action Distribution: [0.5  0.35 0.15]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_14_017_68.gif\n",
      "\n",
      "Episode 15: 018_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 3\n",
      "  Tumor Size: 1676 pixels (2.91%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_15_018_84.gif\n",
      "\n",
      "Episode 16: 019_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1280 pixels (2.22%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_16_019_52.gif\n",
      "\n",
      "Episode 17: 021_96.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -17.60, Steps to Find: 4\n",
      "  Tumor Size: 867 pixels (1.51%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_17_021_96.gif\n",
      "\n",
      "Episode 18: 022_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1566 pixels (2.72%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_18_022_89.gif\n",
      "\n",
      "Episode 19: 023_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1119 pixels (1.94%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_19_023_98.gif\n",
      "\n",
      "Episode 20: 024_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1338 pixels (2.32%)\n",
      "  Action Distribution: [0.1 0.6 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_20_024_49.gif\n",
      "\n",
      "Episode 21: 026_43.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 5.60, Steps to Find: 3\n",
      "  Tumor Size: 663 pixels (1.15%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_21_026_43.gif\n",
      "\n",
      "Episode 22: 028_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 799 pixels (1.39%)\n",
      "  Action Distribution: [0.25 0.25 0.5 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_22_028_56.gif\n",
      "\n",
      "Episode 23: 030_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 1\n",
      "  Tumor Size: 1979 pixels (3.44%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_23_030_99.gif\n",
      "\n",
      "Episode 24: 030_115.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 47.60, Steps to Find: 2\n",
      "  Tumor Size: 611 pixels (1.06%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_24_030_115.gif\n",
      "\n",
      "Episode 25: 032_134.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 554 pixels (0.96%)\n",
      "  Action Distribution: [0.35 0.3  0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_25_032_134.gif\n",
      "\n",
      "Episode 26: 033_86.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 2788 pixels (4.84%)\n",
      "  Action Distribution: [0.25 0.25 0.5 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_26_033_86.gif\n",
      "\n",
      "Episode 27: 034_113.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2141 pixels (3.72%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_27_034_113.gif\n",
      "\n",
      "Episode 28: 035_40.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 837 pixels (1.45%)\n",
      "  Action Distribution: [0.3  0.35 0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_28_035_40.gif\n",
      "\n",
      "Episode 29: 036_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 795 pixels (1.38%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_29_036_83.gif\n",
      "\n",
      "Episode 30: 038_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1720 pixels (2.99%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_30_038_84.gif\n",
      "\n",
      "Episode 31: 040_46.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 52.80, Steps to Find: 1\n",
      "  Tumor Size: 3375 pixels (5.86%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_31_040_46.gif\n",
      "\n",
      "Episode 32: 043_48.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 71.60, Steps to Find: 6\n",
      "  Tumor Size: 1217 pixels (2.11%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_32_043_48.gif\n",
      "\n",
      "Episode 33: 045_57.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 473 pixels (0.82%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_33_045_57.gif\n",
      "\n",
      "Episode 34: 045_82.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 2259 pixels (3.92%)\n",
      "  Action Distribution: [0.15 0.2  0.65]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_34_045_82.gif\n",
      "\n",
      "Episode 35: 046_44.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -16.80, Steps to Find: 8\n",
      "  Tumor Size: 1147 pixels (1.99%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_35_046_44.gif\n",
      "\n",
      "Episode 36: 048_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1308 pixels (2.27%)\n",
      "  Action Distribution: [0.2 0.4 0.4]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_36_048_49.gif\n",
      "\n",
      "Episode 37: 049_81.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1649 pixels (2.86%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_37_049_81.gif\n",
      "\n",
      "Episode 38: 050_60.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 2\n",
      "  Tumor Size: 2312 pixels (4.01%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_38_050_60.gif\n",
      "\n",
      "Episode 39: 051_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 37.20, Steps to Find: 2\n",
      "  Tumor Size: 3155 pixels (5.48%)\n",
      "  Action Distribution: [0.45 0.35 0.2 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_39_051_94.gif\n",
      "\n",
      "Episode 40: 052_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1228 pixels (2.13%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_40_052_98.gif\n",
      "\n",
      "Episode 41: 053_85.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 3\n",
      "  Tumor Size: 2915 pixels (5.06%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_41_053_85.gif\n",
      "\n",
      "Episode 42: 054_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 2\n",
      "  Tumor Size: 2098 pixels (3.64%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_42_054_61.gif\n",
      "\n",
      "Episode 43: 055_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 32.00, Steps to Find: 5\n",
      "  Tumor Size: 2578 pixels (4.48%)\n",
      "  Action Distribution: [0.6  0.25 0.15]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_43_055_61.gif\n",
      "\n",
      "Episode 44: 057_124.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 24.40, Steps to Find: 5\n",
      "  Tumor Size: 1433 pixels (2.49%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_44_057_124.gif\n",
      "\n",
      "Episode 45: 058_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1231 pixels (2.14%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_45_058_84.gif\n",
      "\n",
      "Episode 46: 059_67.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 11.60, Steps to Find: 16\n",
      "  Tumor Size: 730 pixels (1.27%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_46_059_67.gif\n",
      "\n",
      "Episode 47: 066_116.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 674 pixels (1.17%)\n",
      "  Action Distribution: [0.15 0.5  0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_47_066_116.gif\n",
      "\n",
      "Episode 48: 090_73.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1051 pixels (1.82%)\n",
      "  Action Distribution: [0.2 0.2 0.6]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_48_090_73.gif\n",
      "\n",
      "Episode 49: 092_94.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1658 pixels (2.88%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_49_092_94.gif\n",
      "\n",
      "Episode 50: 104_74.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.80, Steps to Find: 1\n",
      "  Tumor Size: 3423 pixels (5.94%)\n",
      "  Action Distribution: [0.3 0.4 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_50_104_74.gif\n",
      "\n",
      "Episode 51: 116_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 2\n",
      "  Tumor Size: 1855 pixels (3.22%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_51_116_58.gif\n",
      "\n",
      "Episode 52: 119_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1148 pixels (1.99%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_52_119_53.gif\n",
      "\n",
      "Episode 53: 130_39.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 42.40, Steps to Find: 4\n",
      "  Tumor Size: 742 pixels (1.29%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_53_130_39.gif\n",
      "\n",
      "Episode 54: 147_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2935 pixels (5.10%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_54_147_83.gif\n",
      "\n",
      "Episode 55: 154_87.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 82.80, Steps to Find: 4\n",
      "  Tumor Size: 1443 pixels (2.51%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_55_154_87.gif\n",
      "\n",
      "Episode 56: 155_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1005 pixels (1.74%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_56_155_48.gif\n",
      "\n",
      "Episode 57: 160_82.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 2528 pixels (4.39%)\n",
      "  Action Distribution: [0.7  0.25 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_57_160_82.gif\n",
      "\n",
      "Episode 58: 163_101.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 3132 pixels (5.44%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_58_163_101.gif\n",
      "\n",
      "Episode 59: 171_69.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 82.80, Steps to Find: 4\n",
      "  Tumor Size: 1076 pixels (1.87%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_59_171_69.gif\n",
      "\n",
      "Episode 60: 176_99.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2223 pixels (3.86%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_60_176_99.gif\n",
      "\n",
      "Episode 61: 177_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 823 pixels (1.43%)\n",
      "  Action Distribution: [0.3  0.25 0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_61_177_57.gif\n",
      "\n",
      "Episode 62: 178_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 2286 pixels (3.97%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_62_178_85.gif\n",
      "\n",
      "Episode 63: 179_70.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1958 pixels (3.40%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_63_179_70.gif\n",
      "\n",
      "Episode 64: 180_50.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 2855 pixels (4.96%)\n",
      "  Action Distribution: [0.2 0.3 0.5]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_64_180_50.gif\n",
      "\n",
      "Episode 65: 180_72.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 2771 pixels (4.81%)\n",
      "  Action Distribution: [0.15 0.4  0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_65_180_72.gif\n",
      "\n",
      "Episode 66: 184_36.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 296 pixels (0.51%)\n",
      "  Action Distribution: [0.2  0.35 0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_66_184_36.gif\n",
      "\n",
      "Episode 67: 188_62.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 2\n",
      "  Tumor Size: 1754 pixels (3.05%)\n",
      "  Action Distribution: [0.15 0.35 0.5 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_67_188_62.gif\n",
      "\n",
      "Episode 68: 190_81.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 987 pixels (1.71%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_68_190_81.gif\n",
      "\n",
      "Episode 69: 200_45.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1239 pixels (2.15%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_69_200_45.gif\n",
      "\n",
      "Episode 70: 204_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 42.40, Steps to Find: 2\n",
      "  Tumor Size: 893 pixels (1.55%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_70_204_52.gif\n",
      "\n",
      "Episode 71: 226_66.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 2037 pixels (3.54%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_71_226_66.gif\n",
      "\n",
      "Episode 72: 227_60.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -17.60, Steps to Find: 3\n",
      "  Tumor Size: 1494 pixels (2.59%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_72_227_60.gif\n",
      "\n",
      "Episode 73: 231_90.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 3297 pixels (5.72%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_73_231_90.gif\n",
      "\n",
      "Episode 74: 236_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.20, Steps to Find: 8\n",
      "  Tumor Size: 2498 pixels (4.34%)\n",
      "  Action Distribution: [0.7 0.2 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_74_236_58.gif\n",
      "\n",
      "Episode 75: 237_41.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 840 pixels (1.46%)\n",
      "  Action Distribution: [0.15 0.4  0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_75_237_41.gif\n",
      "\n",
      "Episode 76: 240_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2725 pixels (4.73%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_76_240_52.gif\n",
      "\n",
      "Episode 77: 245_35.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1257 pixels (2.18%)\n",
      "  Action Distribution: [0.2 0.3 0.5]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_77_245_35.gif\n",
      "\n",
      "Episode 78: 250_45.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1616 pixels (2.81%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_78_250_45.gif\n",
      "\n",
      "Episode 79: 255_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 15\n",
      "  Tumor Size: 3030 pixels (5.26%)\n",
      "  Action Distribution: [0.55 0.2  0.25]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_79_255_56.gif\n",
      "\n",
      "Episode 80: 260_62.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 82.80, Steps to Find: 4\n",
      "  Tumor Size: 1653 pixels (2.87%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_80_260_62.gif\n",
      "\n",
      "Episode 81: 266_105.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1725 pixels (2.99%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_81_266_105.gif\n",
      "\n",
      "Episode 82: 274_90.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.80, Steps to Find: 1\n",
      "  Tumor Size: 4092 pixels (7.10%)\n",
      "  Action Distribution: [0.15 0.45 0.4 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_82_274_90.gif\n",
      "\n",
      "Episode 83: 276_102.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 2\n",
      "  Tumor Size: 1831 pixels (3.18%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_83_276_102.gif\n",
      "\n",
      "Episode 84: 280_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 905 pixels (1.57%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_84_280_96.gif\n",
      "\n",
      "Episode 85: 282_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1994 pixels (3.46%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_85_282_53.gif\n",
      "\n",
      "Episode 86: 284_88.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.80, Steps to Find: 2\n",
      "  Tumor Size: 4461 pixels (7.74%)\n",
      "  Action Distribution: [0.35 0.35 0.3 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_86_284_88.gif\n",
      "\n",
      "Episode 87: 287_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 2\n",
      "  Tumor Size: 1807 pixels (3.14%)\n",
      "  Action Distribution: [0.3  0.35 0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_87_287_97.gif\n",
      "\n",
      "Episode 88: 289_74.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 3435 pixels (5.96%)\n",
      "  Action Distribution: [0.2  0.45 0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_88_289_74.gif\n",
      "\n",
      "Episode 89: 299_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 2607 pixels (4.53%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_89_299_97.gif\n",
      "\n",
      "Episode 90: 300_107.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -10.00, Steps to Find: 3\n",
      "  Tumor Size: 2216 pixels (3.85%)\n",
      "  Action Distribution: [0.3  0.35 0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_90_300_107.gif\n",
      "\n",
      "Episode 91: 308_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 1\n",
      "  Tumor Size: 4910 pixels (8.52%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_91_308_88.gif\n",
      "\n",
      "Episode 92: 314_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 932 pixels (1.62%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_92_314_91.gif\n",
      "\n",
      "Episode 93: 326_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1227 pixels (2.13%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_93_326_68.gif\n",
      "\n",
      "Episode 94: 333_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 3974 pixels (6.90%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_94_333_91.gif\n",
      "\n",
      "Episode 95: 350_77.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.00, Steps to Find: 5\n",
      "  Tumor Size: 1879 pixels (3.26%)\n",
      "  Action Distribution: [0.3 0.3 0.4]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_95_350_77.gif\n",
      "\n",
      "Episode 96: 356_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 532 pixels (0.92%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_96_356_97.gif\n",
      "\n",
      "Episode 97: 360_103.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 88.80, Steps to Find: 3\n",
      "  Tumor Size: 3331 pixels (5.78%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_97_360_103.gif\n",
      "\n",
      "Episode 98: 363_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 872 pixels (1.51%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_98_363_48.gif\n",
      "\n",
      "Episode 99: 365_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 3872 pixels (6.72%)\n",
      "  Action Distribution: [0.4  0.25 0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_99_365_83.gif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_results = testing(\n",
    "    agent=agent,\n",
    "    test_pairs=prepare(mode=\"test\"),\n",
    "    agent_type=\"ppo\",\n",
    "    num_episodes=100,\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    save_gifs=True,\n",
    "    gif_folder=f\"GIFs_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "sucess[f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"] = overall_results['success_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af6ea9e",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d18fde33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/martina/codi2/4year/tfg/ppo/wandb/run-20251114_000209-arrrwj3o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/arrrwj3o' target=\"_blank\">PPO_batch128_rewards[5.0, -1.0, -0.2]_3actions</a></strong> to <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/arrrwj3o' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/arrrwj3o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Global-Aware PPO training...\n",
      "Episode 0 | Avg Reward: -10.02 | Mean Reward (100): -10.02 | Actor Loss: -0.0133\n",
      "New best model saved!\n",
      "Episode 25 | Avg Reward: -9.18 | Mean Reward (100): -9.60 | Actor Loss: -0.0044\n",
      "New best model saved!\n",
      "Episode 50 | Avg Reward: -8.40 | Mean Reward (100): -9.20 | Actor Loss: 0.0154\n",
      "New best model saved!\n",
      "Episode 75 | Avg Reward: -8.70 | Mean Reward (100): -9.08 | Actor Loss: 0.0052\n",
      "New best model saved!\n",
      "Episode 100 | Avg Reward: -7.98 | Mean Reward (100): -8.57 | Actor Loss: -0.0040\n",
      "New best model saved!\n",
      "Episode 125 | Avg Reward: -6.99 | Mean Reward (100): -8.02 | Actor Loss: -0.0001\n",
      "New best model saved!\n",
      "Episode 150 | Avg Reward: -7.14 | Mean Reward (100): -7.70 | Actor Loss: 0.0014\n",
      "New best model saved!\n",
      "Episode 175 | Avg Reward: -9.36 | Mean Reward (100): -7.87 | Actor Loss: -0.0068\n",
      "Episode 200 | Avg Reward: -7.55 | Mean Reward (100): -7.76 | Actor Loss: 0.0147\n",
      "Episode 225 | Avg Reward: -9.60 | Mean Reward (100): -8.41 | Actor Loss: -0.0148\n",
      "Episode 250 | Avg Reward: -7.23 | Mean Reward (100): -8.44 | Actor Loss: 0.0081\n",
      "Episode 275 | Avg Reward: -3.79 | Mean Reward (100): -7.04 | Actor Loss: -0.0255\n",
      "New best model saved!\n",
      "Episode 300 | Avg Reward: -5.73 | Mean Reward (100): -6.59 | Actor Loss: -0.0011\n",
      "New best model saved!\n",
      "Episode 325 | Avg Reward: 2.19 | Mean Reward (100): -3.64 | Actor Loss: -0.0145\n",
      "New best model saved!\n",
      "Episode 350 | Avg Reward: 3.70 | Mean Reward (100): -0.91 | Actor Loss: -0.0057\n",
      "New best model saved!\n",
      "Episode 375 | Avg Reward: 20.26 | Mean Reward (100): 5.10 | Actor Loss: 0.0174\n",
      "New best model saved!\n",
      "Episode 400 | Avg Reward: 20.43 | Mean Reward (100): 11.64 | Actor Loss: 0.0479\n",
      "New best model saved!\n",
      "Episode 425 | Avg Reward: -8.50 | Mean Reward (100): 8.97 | Actor Loss: -0.0248\n",
      "Episode 450 | Avg Reward: 4.54 | Mean Reward (100): 9.18 | Actor Loss: -0.0084\n",
      "Episode 475 | Avg Reward: 14.88 | Mean Reward (100): 7.84 | Actor Loss: -0.0059\n",
      "Episode 500 | Avg Reward: 11.02 | Mean Reward (100): 5.49 | Actor Loss: 0.0013\n",
      "Episode 525 | Avg Reward: 12.05 | Mean Reward (100): 10.62 | Actor Loss: 0.0059\n",
      "Episode 550 | Avg Reward: 5.49 | Mean Reward (100): 10.86 | Actor Loss: 0.0054\n",
      "Episode 575 | Avg Reward: 11.31 | Mean Reward (100): 9.97 | Actor Loss: -0.0079\n",
      "Episode 600 | Avg Reward: 14.67 | Mean Reward (100): 10.88 | Actor Loss: 0.0009\n",
      "Episode 625 | Avg Reward: -4.13 | Mean Reward (100): 6.84 | Actor Loss: -0.0004\n",
      "Episode 650 | Avg Reward: 10.75 | Mean Reward (100): 8.15 | Actor Loss: -0.0185\n",
      "Episode 675 | Avg Reward: 10.34 | Mean Reward (100): 7.91 | Actor Loss: -0.0150\n",
      "Episode 700 | Avg Reward: 21.09 | Mean Reward (100): 9.51 | Actor Loss: -0.0177\n",
      "Episode 725 | Avg Reward: 17.25 | Mean Reward (100): 14.86 | Actor Loss: 0.0018\n",
      "New best model saved!\n",
      "Episode 750 | Avg Reward: 25.65 | Mean Reward (100): 18.58 | Actor Loss: 0.0067\n",
      "New best model saved!\n",
      "Episode 775 | Avg Reward: 1.66 | Mean Reward (100): 16.41 | Actor Loss: -0.0028\n",
      "Episode 800 | Avg Reward: 6.98 | Mean Reward (100): 12.88 | Actor Loss: -0.0079\n",
      "Episode 825 | Avg Reward: 22.54 | Mean Reward (100): 14.21 | Actor Loss: 0.0018\n",
      "Episode 850 | Avg Reward: 8.08 | Mean Reward (100): 9.82 | Actor Loss: -0.0058\n",
      "Episode 875 | Avg Reward: 9.12 | Mean Reward (100): 11.68 | Actor Loss: 0.0052\n",
      "Episode 900 | Avg Reward: 14.53 | Mean Reward (100): 13.57 | Actor Loss: 0.0106\n",
      "Episode 925 | Avg Reward: 32.75 | Mean Reward (100): 16.12 | Actor Loss: 0.0096\n",
      "Episode 950 | Avg Reward: 17.90 | Mean Reward (100): 18.58 | Actor Loss: 0.0176\n",
      "Episode 975 | Avg Reward: 6.67 | Mean Reward (100): 17.96 | Actor Loss: 0.0032\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▂▃▅▄▃▃▄▃▅▂▄▁▃▂▃▅█▁▃▃▄▄▄▃▄▃▂▂▂▄▄▃▃▄▃▄▄▄▅▄</td></tr><tr><td>avg_episode_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▆▆▁▃▅▄▅▄▄▅▂▄▄▆▅▇▃▄▆▄▄▅█▆▄</td></tr><tr><td>critic_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▇▇▃▄▆▆▅▅▆▅▃▄▅▆▇▇▅▅▇▅▄▆█▇▅</td></tr><tr><td>entropy</td><td>████████████▇▇▅▂▁▃▄▂▂▂▄▄▄▅▅▄▃▂▃▃▄▂▃▃▃▂▂▄</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>mean_reward_100</td><td>▁▁▁▁▁▁▂▂▂▁▁▂▂▃▃▅▆▆▆▅▅▆▆▆▆▅▅▅▆▇█▇▇▇▆▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>0.00322</td></tr><tr><td>avg_episode_reward</td><td>6.672</td></tr><tr><td>critic_loss</td><td>167.68151</td></tr><tr><td>entropy</td><td>0.62044</td></tr><tr><td>episode</td><td>975</td></tr><tr><td>mean_reward_100</td><td>17.964</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">PPO_batch128_rewards[5.0, -1.0, -0.2]_3actions</strong> at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/arrrwj3o' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/arrrwj3o</a><br> View project at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251114_000209-arrrwj3o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -1.0, -0.2], \n",
    "    'action_space': gym.spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "LR = 1e-4\n",
    "MAX_EPISODES = 1000\n",
    "NUM_STEPS = 512  # Start with smaller rollout for testing\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "env = GlobalAwareGlioblastoma(*train_pairs[0], **CURRENT_CONFIG)\n",
    "model = GlobalAwarePPOActorCritic(env, learning_rate=LR, device='cpu')\n",
    "agent = GlobalAwarePPOAgent(\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    model=model,\n",
    "    train_pairs=train_pairs,\n",
    "    env_class=GlobalAwareGlioblastoma,  # Use the new environment class\n",
    "    gamma=0.99,\n",
    "    clip_epsilon=0.2,\n",
    "    ppo_epochs=4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "\n",
    "wandb.init(project=\"TFG_Glioblastoma_PPO\", \n",
    "           name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\",\n",
    "           config={\n",
    "               \"learning_rate\": LR,\n",
    "               \"max_episodes\": MAX_EPISODES,\n",
    "               \"num_steps\": NUM_STEPS,\n",
    "               \"batch_size\": BATCH_SIZE,\n",
    "               \"configuration\": CURRENT_CONFIG\n",
    "           })\n",
    "\n",
    "# Start training\n",
    "agent.train(max_episodes=MAX_EPISODES, num_steps=NUM_STEPS)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ed6b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 100 pairs out of 100 listed in CSV.\n",
      "Saved GIF for episode 0 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_0_002_58.gif\n",
      "Saved GIF for episode 10 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_10_013_86.gif\n",
      "Saved GIF for episode 20 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_20_024_49.gif\n",
      "Saved GIF for episode 30 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_30_038_84.gif\n",
      "Saved GIF for episode 40 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_40_052_98.gif\n",
      "Saved GIF for episode 50 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_50_104_74.gif\n",
      "Saved GIF for episode 60 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_60_176_99.gif\n",
      "Saved GIF for episode 70 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_70_204_52.gif\n",
      "Saved GIF for episode 80 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_80_260_62.gif\n",
      "Saved GIF for episode 90 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_90_300_107.gif\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS (PPO Agent)\n",
      "============================================================\n",
      "Success Rate: 54.00%\n",
      "Average Episode Reward: 23.32\n",
      "Average Steps to Find Tumor: 10.87\n",
      "Average Tumor Rewards per Episode: 6.86\n",
      "Tumor Size Statistics:\n",
      "  Biggest Tumor: 4910 pixels (8.52%)\n",
      "  Smallest Tumor: 296 pixels (0.51%)\n",
      "  Average Tumor: 1873 pixels (3.25%)\n",
      "Overall Action Distribution: [0.7945 0.0995 0.106 ]\n",
      "  Successful Episodes: [0.84814815 0.0787037  0.07314815]\n",
      "  Unsuccessful Episodes: [0.73152174 0.12391304 0.14456522]\n",
      "\n",
      "Detailed Results for 100 episodes:\n",
      "--------------------------------------------------------------------------------\n",
      "Episode 0: 002_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 76.80, Steps to Find: 5\n",
      "  Tumor Size: 2049 pixels (3.56%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_0_002_58.gif\n",
      "\n",
      "Episode 1: 004_87.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 49.20, Steps to Find: 10\n",
      "  Tumor Size: 2727 pixels (4.73%)\n",
      "  Action Distribution: [0.55 0.35 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_1_004_87.gif\n",
      "\n",
      "Episode 2: 005_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 768 pixels (1.33%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_2_005_94.gif\n",
      "\n",
      "Episode 3: 006_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 6\n",
      "  Tumor Size: 2834 pixels (4.92%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_3_006_83.gif\n",
      "\n",
      "Episode 4: 007_54.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -17.60, Steps to Find: 14\n",
      "  Tumor Size: 1299 pixels (2.26%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_4_007_54.gif\n",
      "\n",
      "Episode 5: 008_41.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 82.80, Steps to Find: 4\n",
      "  Tumor Size: 1243 pixels (2.16%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_5_008_41.gif\n",
      "\n",
      "Episode 6: 009_65.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 4172 pixels (7.24%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_6_009_65.gif\n",
      "\n",
      "Episode 7: 010_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 5\n",
      "  Tumor Size: 1327 pixels (2.30%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_7_010_89.gif\n",
      "\n",
      "Episode 8: 011_103.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 831 pixels (1.44%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_8_011_103.gif\n",
      "\n",
      "Episode 9: 012_69.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1365 pixels (2.37%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_9_012_69.gif\n",
      "\n",
      "Episode 10: 013_86.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 53.60, Steps to Find: 9\n",
      "  Tumor Size: 1536 pixels (2.67%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_10_013_86.gif\n",
      "\n",
      "Episode 11: 014_46.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 82.80, Steps to Find: 4\n",
      "  Tumor Size: 2035 pixels (3.53%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_11_014_46.gif\n",
      "\n",
      "Episode 12: 015_71.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 2195 pixels (3.81%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_12_015_71.gif\n",
      "\n",
      "Episode 13: 016_95.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 3\n",
      "  Tumor Size: 2999 pixels (5.21%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_13_016_95.gif\n",
      "\n",
      "Episode 14: 017_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 2255 pixels (3.91%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_14_017_68.gif\n",
      "\n",
      "Episode 15: 018_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -17.60, Steps to Find: 2\n",
      "  Tumor Size: 1676 pixels (2.91%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_15_018_84.gif\n",
      "\n",
      "Episode 16: 019_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 32.00, Steps to Find: 4\n",
      "  Tumor Size: 1280 pixels (2.22%)\n",
      "  Action Distribution: [0.55 0.15 0.3 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_16_019_52.gif\n",
      "\n",
      "Episode 17: 021_96.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -17.60, Steps to Find: 7\n",
      "  Tumor Size: 867 pixels (1.51%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_17_021_96.gif\n",
      "\n",
      "Episode 18: 022_89.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1566 pixels (2.72%)\n",
      "  Action Distribution: [0.4  0.15 0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_18_022_89.gif\n",
      "\n",
      "Episode 19: 023_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1119 pixels (1.94%)\n",
      "  Action Distribution: [0.45 0.3  0.25]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_19_023_98.gif\n",
      "\n",
      "Episode 20: 024_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1338 pixels (2.32%)\n",
      "  Action Distribution: [0.65 0.15 0.2 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_20_024_49.gif\n",
      "\n",
      "Episode 21: 026_43.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 663 pixels (1.15%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_21_026_43.gif\n",
      "\n",
      "Episode 22: 028_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 799 pixels (1.39%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_22_028_56.gif\n",
      "\n",
      "Episode 23: 030_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -17.60, Steps to Find: 3\n",
      "  Tumor Size: 1979 pixels (3.44%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_23_030_99.gif\n",
      "\n",
      "Episode 24: 030_115.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 611 pixels (1.06%)\n",
      "  Action Distribution: [0.45 0.2  0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_24_030_115.gif\n",
      "\n",
      "Episode 25: 032_134.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.00, Steps to Find: 14\n",
      "  Tumor Size: 554 pixels (0.96%)\n",
      "  Action Distribution: [0.55 0.25 0.2 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_25_032_134.gif\n",
      "\n",
      "Episode 26: 033_86.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 1\n",
      "  Tumor Size: 2788 pixels (4.84%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_26_033_86.gif\n",
      "\n",
      "Episode 27: 034_113.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 53.60, Steps to Find: 9\n",
      "  Tumor Size: 2141 pixels (3.72%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_27_034_113.gif\n",
      "\n",
      "Episode 28: 035_40.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 837 pixels (1.45%)\n",
      "  Action Distribution: [0.5 0.3 0.2]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_28_035_40.gif\n",
      "\n",
      "Episode 29: 036_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 795 pixels (1.38%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_29_036_83.gif\n",
      "\n",
      "Episode 30: 038_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1720 pixels (2.99%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_30_038_84.gif\n",
      "\n",
      "Episode 31: 040_46.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 3375 pixels (5.86%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_31_040_46.gif\n",
      "\n",
      "Episode 32: 043_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 53.60, Steps to Find: 2\n",
      "  Tumor Size: 1217 pixels (2.11%)\n",
      "  Action Distribution: [0.75 0.2  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_32_043_48.gif\n",
      "\n",
      "Episode 33: 045_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 473 pixels (0.82%)\n",
      "  Action Distribution: [0.55 0.2  0.25]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_33_045_57.gif\n",
      "\n",
      "Episode 34: 045_82.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 43.20, Steps to Find: 8\n",
      "  Tumor Size: 2259 pixels (3.92%)\n",
      "  Action Distribution: [0.65 0.25 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_34_045_82.gif\n",
      "\n",
      "Episode 35: 046_44.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 0.40, Steps to Find: 7\n",
      "  Tumor Size: 1147 pixels (1.99%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_35_046_44.gif\n",
      "\n",
      "Episode 36: 048_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1308 pixels (2.27%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_36_048_49.gif\n",
      "\n",
      "Episode 37: 049_81.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -16.80, Steps to Find: 10\n",
      "  Tumor Size: 1649 pixels (2.86%)\n",
      "  Action Distribution: [0.8  0.15 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_37_049_81.gif\n",
      "\n",
      "Episode 38: 050_60.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2312 pixels (4.01%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_38_050_60.gif\n",
      "\n",
      "Episode 39: 051_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 2\n",
      "  Tumor Size: 3155 pixels (5.48%)\n",
      "  Action Distribution: [0.5 0.3 0.2]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_39_051_94.gif\n",
      "\n",
      "Episode 40: 052_98.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 4\n",
      "  Tumor Size: 1228 pixels (2.13%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_40_052_98.gif\n",
      "\n",
      "Episode 41: 053_85.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 6\n",
      "  Tumor Size: 2915 pixels (5.06%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_41_053_85.gif\n",
      "\n",
      "Episode 42: 054_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 36.40, Steps to Find: 2\n",
      "  Tumor Size: 2098 pixels (3.64%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_42_054_61.gif\n",
      "\n",
      "Episode 43: 055_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2578 pixels (4.48%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_43_055_61.gif\n",
      "\n",
      "Episode 44: 057_124.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -17.60, Steps to Find: 6\n",
      "  Tumor Size: 1433 pixels (2.49%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_44_057_124.gif\n",
      "\n",
      "Episode 45: 058_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -17.60, Steps to Find: 16\n",
      "  Tumor Size: 1231 pixels (2.14%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_45_058_84.gif\n",
      "\n",
      "Episode 46: 059_67.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 65.60, Steps to Find: 7\n",
      "  Tumor Size: 730 pixels (1.27%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_46_059_67.gif\n",
      "\n",
      "Episode 47: 066_116.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 2\n",
      "  Tumor Size: 674 pixels (1.17%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_47_066_116.gif\n",
      "\n",
      "Episode 48: 090_73.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 0.40, Steps to Find: 18\n",
      "  Tumor Size: 1051 pixels (1.82%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_48_090_73.gif\n",
      "\n",
      "Episode 49: 092_94.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1658 pixels (2.88%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_49_092_94.gif\n",
      "\n",
      "Episode 50: 104_74.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 3423 pixels (5.94%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_50_104_74.gif\n",
      "\n",
      "Episode 51: 116_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 1855 pixels (3.22%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_51_116_58.gif\n",
      "\n",
      "Episode 52: 119_53.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -11.60, Steps to Find: 4\n",
      "  Tumor Size: 1148 pixels (1.99%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_52_119_53.gif\n",
      "\n",
      "Episode 53: 130_39.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 742 pixels (1.29%)\n",
      "  Action Distribution: [0.4 0.3 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_53_130_39.gif\n",
      "\n",
      "Episode 54: 147_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 71.60, Steps to Find: 6\n",
      "  Tumor Size: 2935 pixels (5.10%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_54_147_83.gif\n",
      "\n",
      "Episode 55: 154_87.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1443 pixels (2.51%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_55_154_87.gif\n",
      "\n",
      "Episode 56: 155_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1005 pixels (1.74%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_56_155_48.gif\n",
      "\n",
      "Episode 57: 160_82.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 65.60, Steps to Find: 7\n",
      "  Tumor Size: 2528 pixels (4.39%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_57_160_82.gif\n",
      "\n",
      "Episode 58: 163_101.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 3132 pixels (5.44%)\n",
      "  Action Distribution: [0.5 0.2 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_58_163_101.gif\n",
      "\n",
      "Episode 59: 171_69.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -0.40, Steps to Find: 2\n",
      "  Tumor Size: 1076 pixels (1.87%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_59_171_69.gif\n",
      "\n",
      "Episode 60: 176_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 88.80, Steps to Find: 3\n",
      "  Tumor Size: 2223 pixels (3.86%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_60_176_99.gif\n",
      "\n",
      "Episode 61: 177_57.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 71.60, Steps to Find: 6\n",
      "  Tumor Size: 823 pixels (1.43%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_61_177_57.gif\n",
      "\n",
      "Episode 62: 178_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2286 pixels (3.97%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_62_178_85.gif\n",
      "\n",
      "Episode 63: 179_70.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1958 pixels (3.40%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_63_179_70.gif\n",
      "\n",
      "Episode 64: 180_50.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.80, Steps to Find: 20\n",
      "  Tumor Size: 2855 pixels (4.96%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_64_180_50.gif\n",
      "\n",
      "Episode 65: 180_72.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 2771 pixels (4.81%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_65_180_72.gif\n",
      "\n",
      "Episode 66: 184_36.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 82.80, Steps to Find: 4\n",
      "  Tumor Size: 296 pixels (0.51%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_66_184_36.gif\n",
      "\n",
      "Episode 67: 188_62.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.00, Steps to Find: 20\n",
      "  Tumor Size: 1754 pixels (3.05%)\n",
      "  Action Distribution: [0.5 0.1 0.4]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_67_188_62.gif\n",
      "\n",
      "Episode 68: 190_81.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 71.60, Steps to Find: 6\n",
      "  Tumor Size: 987 pixels (1.71%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_68_190_81.gif\n",
      "\n",
      "Episode 69: 200_45.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1239 pixels (2.15%)\n",
      "  Action Distribution: [0.45 0.25 0.3 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_69_200_45.gif\n",
      "\n",
      "Episode 70: 204_52.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 893 pixels (1.55%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_70_204_52.gif\n",
      "\n",
      "Episode 71: 226_66.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 4\n",
      "  Tumor Size: 2037 pixels (3.54%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_71_226_66.gif\n",
      "\n",
      "Episode 72: 227_60.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -16.00, Steps to Find: 20\n",
      "  Tumor Size: 1494 pixels (2.59%)\n",
      "  Action Distribution: [0.6 0.1 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_72_227_60.gif\n",
      "\n",
      "Episode 73: 231_90.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 3297 pixels (5.72%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_73_231_90.gif\n",
      "\n",
      "Episode 74: 236_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 4\n",
      "  Tumor Size: 2498 pixels (4.34%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_74_236_58.gif\n",
      "\n",
      "Episode 75: 237_41.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 83.60, Steps to Find: 4\n",
      "  Tumor Size: 840 pixels (1.46%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_75_237_41.gif\n",
      "\n",
      "Episode 76: 240_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 2725 pixels (4.73%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_76_240_52.gif\n",
      "\n",
      "Episode 77: 245_35.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -15.20, Steps to Find: 20\n",
      "  Tumor Size: 1257 pixels (2.18%)\n",
      "  Action Distribution: [0.25 0.3  0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_77_245_35.gif\n",
      "\n",
      "Episode 78: 250_45.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1616 pixels (2.81%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_78_250_45.gif\n",
      "\n",
      "Episode 79: 255_56.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 72.40, Steps to Find: 6\n",
      "  Tumor Size: 3030 pixels (5.26%)\n",
      "  Action Distribution: [0.55 0.1  0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_79_255_56.gif\n",
      "\n",
      "Episode 80: 260_62.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 42.40, Steps to Find: 11\n",
      "  Tumor Size: 1653 pixels (2.87%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_80_260_62.gif\n",
      "\n",
      "Episode 81: 266_105.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1725 pixels (2.99%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_81_266_105.gif\n",
      "\n",
      "Episode 82: 274_90.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 70.80, Steps to Find: 6\n",
      "  Tumor Size: 4092 pixels (7.10%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_82_274_90.gif\n",
      "\n",
      "Episode 83: 276_102.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1831 pixels (3.18%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_83_276_102.gif\n",
      "\n",
      "Episode 84: 280_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 905 pixels (1.57%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_84_280_96.gif\n",
      "\n",
      "Episode 85: 282_53.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1994 pixels (3.46%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_85_282_53.gif\n",
      "\n",
      "Episode 86: 284_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 88.80, Steps to Find: 3\n",
      "  Tumor Size: 4461 pixels (7.74%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_86_284_88.gif\n",
      "\n",
      "Episode 87: 287_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 1807 pixels (3.14%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_87_287_97.gif\n",
      "\n",
      "Episode 88: 289_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 3435 pixels (5.96%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_88_289_74.gif\n",
      "\n",
      "Episode 89: 299_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 2607 pixels (4.53%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_89_299_97.gif\n",
      "\n",
      "Episode 90: 300_107.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 76.80, Steps to Find: 5\n",
      "  Tumor Size: 2216 pixels (3.85%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_90_300_107.gif\n",
      "\n",
      "Episode 91: 308_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 4910 pixels (8.52%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_91_308_88.gif\n",
      "\n",
      "Episode 92: 314_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 932 pixels (1.62%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_92_314_91.gif\n",
      "\n",
      "Episode 93: 326_68.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 1227 pixels (2.13%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_93_326_68.gif\n",
      "\n",
      "Episode 94: 333_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 3974 pixels (6.90%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_94_333_91.gif\n",
      "\n",
      "Episode 95: 350_77.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -17.60, Steps to Find: 20\n",
      "  Tumor Size: 1879 pixels (3.26%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_95_350_77.gif\n",
      "\n",
      "Episode 96: 356_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -18.40, Steps to Find: 20\n",
      "  Tumor Size: 532 pixels (0.92%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_96_356_97.gif\n",
      "\n",
      "Episode 97: 360_103.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 71.60, Steps to Find: 6\n",
      "  Tumor Size: 3331 pixels (5.78%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_97_360_103.gif\n",
      "\n",
      "Episode 98: 363_48.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 77.60, Steps to Find: 5\n",
      "  Tumor Size: 872 pixels (1.51%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_98_363_48.gif\n",
      "\n",
      "Episode 99: 365_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -18.40, Steps to Find: 2\n",
      "  Tumor Size: 3872 pixels (6.72%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_3actions/episode_99_365_83.gif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_results = testing(\n",
    "    agent=agent,\n",
    "    test_pairs=prepare(mode=\"test\"),\n",
    "    agent_type=\"ppo\",\n",
    "    num_episodes=100,\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    save_gifs=True,\n",
    "    gif_folder=f\"GIFs_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "sucess[f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"] = overall_results['success_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de54e990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/martina/codi2/4year/tfg/ppo/wandb/run-20251114_000644-3mcka02v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/3mcka02v' target=\"_blank\">PPO_batch128_rewards[5.0, -0.5, -0.2]_3actions</a></strong> to <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/3mcka02v' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/3mcka02v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Global-Aware PPO training...\n",
      "Episode 0 | Avg Reward: 3.32 | Mean Reward (100): 3.32 | Actor Loss: -0.0195\n",
      "New best model saved!\n",
      "Episode 25 | Avg Reward: -0.38 | Mean Reward (100): 1.47 | Actor Loss: -0.0050\n",
      "Episode 50 | Avg Reward: 1.63 | Mean Reward (100): 1.52 | Actor Loss: -0.0062\n",
      "Episode 75 | Avg Reward: -1.61 | Mean Reward (100): 0.74 | Actor Loss: 0.0010\n",
      "Episode 100 | Avg Reward: 8.10 | Mean Reward (100): 1.94 | Actor Loss: 0.0121\n",
      "Episode 125 | Avg Reward: 11.76 | Mean Reward (100): 4.97 | Actor Loss: 0.0237\n",
      "New best model saved!\n",
      "Episode 150 | Avg Reward: 2.48 | Mean Reward (100): 5.18 | Actor Loss: 0.0120\n",
      "New best model saved!\n",
      "Episode 175 | Avg Reward: 22.87 | Mean Reward (100): 11.30 | Actor Loss: 0.0225\n",
      "New best model saved!\n",
      "Episode 200 | Avg Reward: 20.41 | Mean Reward (100): 14.38 | Actor Loss: 0.0293\n",
      "New best model saved!\n",
      "Episode 225 | Avg Reward: 13.02 | Mean Reward (100): 14.69 | Actor Loss: 0.0058\n",
      "New best model saved!\n",
      "Episode 250 | Avg Reward: 12.29 | Mean Reward (100): 17.15 | Actor Loss: 0.0039\n",
      "New best model saved!\n",
      "Episode 275 | Avg Reward: 13.22 | Mean Reward (100): 14.73 | Actor Loss: 0.0037\n",
      "Episode 300 | Avg Reward: 28.40 | Mean Reward (100): 16.73 | Actor Loss: -0.0033\n",
      "Episode 325 | Avg Reward: 19.45 | Mean Reward (100): 18.34 | Actor Loss: -0.0151\n",
      "New best model saved!\n",
      "Episode 350 | Avg Reward: 14.49 | Mean Reward (100): 18.89 | Actor Loss: 0.0115\n",
      "New best model saved!\n",
      "Episode 375 | Avg Reward: 10.40 | Mean Reward (100): 18.18 | Actor Loss: 0.0016\n",
      "Episode 400 | Avg Reward: 22.40 | Mean Reward (100): 16.68 | Actor Loss: -0.0050\n",
      "Episode 425 | Avg Reward: 19.83 | Mean Reward (100): 16.78 | Actor Loss: -0.0049\n",
      "Episode 450 | Avg Reward: 18.24 | Mean Reward (100): 17.72 | Actor Loss: -0.0009\n",
      "Episode 475 | Avg Reward: 14.66 | Mean Reward (100): 18.78 | Actor Loss: -0.0059\n",
      "Episode 500 | Avg Reward: 11.42 | Mean Reward (100): 16.04 | Actor Loss: 0.0068\n",
      "Episode 525 | Avg Reward: 23.98 | Mean Reward (100): 17.07 | Actor Loss: -0.0010\n",
      "Episode 550 | Avg Reward: 12.70 | Mean Reward (100): 15.69 | Actor Loss: -0.0024\n",
      "Episode 575 | Avg Reward: 12.40 | Mean Reward (100): 15.12 | Actor Loss: 0.0041\n",
      "Episode 600 | Avg Reward: 6.30 | Mean Reward (100): 13.84 | Actor Loss: 0.0172\n",
      "Episode 625 | Avg Reward: 12.17 | Mean Reward (100): 10.89 | Actor Loss: 0.0074\n",
      "Episode 650 | Avg Reward: 14.16 | Mean Reward (100): 11.26 | Actor Loss: 0.0092\n",
      "Episode 675 | Avg Reward: 19.11 | Mean Reward (100): 12.93 | Actor Loss: -0.0041\n",
      "Episode 700 | Avg Reward: 15.90 | Mean Reward (100): 15.33 | Actor Loss: 0.0041\n",
      "Episode 725 | Avg Reward: 23.57 | Mean Reward (100): 18.18 | Actor Loss: 0.0051\n",
      "Episode 750 | Avg Reward: 21.17 | Mean Reward (100): 19.94 | Actor Loss: -0.0019\n",
      "New best model saved!\n",
      "Episode 775 | Avg Reward: 20.24 | Mean Reward (100): 20.22 | Actor Loss: 0.0054\n",
      "New best model saved!\n",
      "Episode 800 | Avg Reward: 26.06 | Mean Reward (100): 22.76 | Actor Loss: -0.0100\n",
      "New best model saved!\n",
      "Episode 825 | Avg Reward: 29.72 | Mean Reward (100): 24.30 | Actor Loss: 0.0079\n",
      "New best model saved!\n",
      "Episode 850 | Avg Reward: 20.05 | Mean Reward (100): 24.02 | Actor Loss: -0.0059\n",
      "Episode 875 | Avg Reward: 8.30 | Mean Reward (100): 21.04 | Actor Loss: -0.0083\n",
      "Episode 900 | Avg Reward: 22.70 | Mean Reward (100): 20.19 | Actor Loss: -0.0273\n",
      "Episode 925 | Avg Reward: 36.23 | Mean Reward (100): 21.82 | Actor Loss: -0.0012\n",
      "Episode 950 | Avg Reward: 26.20 | Mean Reward (100): 23.36 | Actor Loss: 0.0045\n",
      "Episode 975 | Avg Reward: 18.52 | Mean Reward (100): 25.91 | Actor Loss: -0.0055\n",
      "New best model saved!\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▂▄▄▅▆▇▆▇█▅▅▅▄▃▆▅▄▄▄▄▅▄▄▅▆▅▆▄▅▅▄▅▃▅▄▃▁▄▅▄</td></tr><tr><td>avg_episode_reward</td><td>▂▁▂▁▃▃▂▆▅▄▄▄▇▅▄▃▅▅▅▄▃▆▄▄▂▄▄▅▄▆▅▅▆▇▅▃▅█▆▅</td></tr><tr><td>critic_loss</td><td>▁▁▁▁▂▄▃▅▇▅▅▅▇▇▅▄▅▆▅▆▄▆▄▃▃▅▅▆▆▆▇▇▇▇▇▅▇██▇</td></tr><tr><td>entropy</td><td>███▇▇▅▇▄▂▄▄▄▄▃▅▄▄▄▃▃▃▃▄▄▄▃▃▂▃▃▃▂▃▂▃▂▃▂▁▁</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>mean_reward_100</td><td>▂▁▁▁▁▂▂▄▅▅▆▅▅▆▆▆▅▅▆▆▅▆▅▅▅▄▄▄▅▆▆▆▇█▇▇▆▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>-0.0055</td></tr><tr><td>avg_episode_reward</td><td>18.524</td></tr><tr><td>critic_loss</td><td>161.93659</td></tr><tr><td>entropy</td><td>0.4338</td></tr><tr><td>episode</td><td>975</td></tr><tr><td>mean_reward_100</td><td>25.915</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">PPO_batch128_rewards[5.0, -0.5, -0.2]_3actions</strong> at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/3mcka02v' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/3mcka02v</a><br> View project at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251114_000644-3mcka02v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -0.5, -0.2], \n",
    "    'action_space': gym.spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "LR = 1e-4\n",
    "MAX_EPISODES = 1000\n",
    "NUM_STEPS = 512  # Start with smaller rollout for testing\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "env = GlobalAwareGlioblastoma(*train_pairs[0], **CURRENT_CONFIG)\n",
    "model = GlobalAwarePPOActorCritic(env, learning_rate=LR, device='cpu')\n",
    "agent = GlobalAwarePPOAgent(\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    model=model,\n",
    "    train_pairs=train_pairs,\n",
    "    env_class=GlobalAwareGlioblastoma,  # Use the new environment class\n",
    "    gamma=0.99,\n",
    "    clip_epsilon=0.2,\n",
    "    ppo_epochs=4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "\n",
    "wandb.init(project=\"TFG_Glioblastoma_PPO\",\n",
    "           name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\",\n",
    "           config={\n",
    "               \"learning_rate\": LR,\n",
    "               \"max_episodes\": MAX_EPISODES,\n",
    "               \"num_steps\": NUM_STEPS,\n",
    "               \"batch_size\": BATCH_SIZE,\n",
    "               \"configuration\": CURRENT_CONFIG\n",
    "           })\n",
    "\n",
    "# Start training\n",
    "agent.train(max_episodes=MAX_EPISODES, num_steps=NUM_STEPS)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c1d75d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 100 pairs out of 100 listed in CSV.\n",
      "Saved GIF for episode 0 at GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_0_002_58.gif\n",
      "Saved GIF for episode 10 at GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_10_013_86.gif\n",
      "Saved GIF for episode 20 at GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_20_024_49.gif\n",
      "Saved GIF for episode 30 at GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_30_038_84.gif\n",
      "Saved GIF for episode 40 at GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_40_052_98.gif\n",
      "Saved GIF for episode 50 at GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_50_104_74.gif\n",
      "Saved GIF for episode 60 at GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_60_176_99.gif\n",
      "Saved GIF for episode 70 at GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_70_204_52.gif\n",
      "Saved GIF for episode 80 at GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_80_260_62.gif\n",
      "Saved GIF for episode 90 at GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_90_300_107.gif\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS (PPO Agent)\n",
      "============================================================\n",
      "Success Rate: 28.00%\n",
      "Average Episode Reward: 11.78\n",
      "Average Steps to Find Tumor: 14.06\n",
      "Average Tumor Rewards per Episode: 3.80\n",
      "Tumor Size Statistics:\n",
      "  Biggest Tumor: 4910 pixels (8.52%)\n",
      "  Smallest Tumor: 296 pixels (0.51%)\n",
      "  Average Tumor: 1873 pixels (3.25%)\n",
      "Overall Action Distribution: [0.754 0.094 0.152]\n",
      "  Successful Episodes: [0.88571429 0.05535714 0.05892857]\n",
      "  Unsuccessful Episodes: [0.70277778 0.10902778 0.18819444]\n",
      "\n",
      "Detailed Results for 100 episodes:\n",
      "--------------------------------------------------------------------------------\n",
      "Episode 0: 002_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.50, Steps to Find: 20\n",
      "  Tumor Size: 2049 pixels (3.56%)\n",
      "  Action Distribution: [0.4 0.1 0.5]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_0_002_58.gif\n",
      "\n",
      "Episode 1: 004_87.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 2727 pixels (4.73%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_1_004_87.gif\n",
      "\n",
      "Episode 2: 005_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 768 pixels (1.33%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_2_005_94.gif\n",
      "\n",
      "Episode 3: 006_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.70, Steps to Find: 20\n",
      "  Tumor Size: 2834 pixels (4.92%)\n",
      "  Action Distribution: [0.95 0.   0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_3_006_83.gif\n",
      "\n",
      "Episode 4: 007_54.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -9.10, Steps to Find: 15\n",
      "  Tumor Size: 1299 pixels (2.26%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_4_007_54.gif\n",
      "\n",
      "Episode 5: 008_41.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.30, Steps to Find: 3\n",
      "  Tumor Size: 1243 pixels (2.16%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_5_008_41.gif\n",
      "\n",
      "Episode 6: 009_65.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 18.40, Steps to Find: 2\n",
      "  Tumor Size: 4172 pixels (7.24%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_6_009_65.gif\n",
      "\n",
      "Episode 7: 010_89.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 1327 pixels (2.30%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_7_010_89.gif\n",
      "\n",
      "Episode 8: 011_103.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 831 pixels (1.44%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_8_011_103.gif\n",
      "\n",
      "Episode 9: 012_69.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 1365 pixels (2.37%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_9_012_69.gif\n",
      "\n",
      "Episode 10: 013_86.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 1536 pixels (2.67%)\n",
      "  Action Distribution: [0.7 0.  0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_10_013_86.gif\n",
      "\n",
      "Episode 11: 014_46.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.50, Steps to Find: 2\n",
      "  Tumor Size: 2035 pixels (3.53%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_11_014_46.gif\n",
      "\n",
      "Episode 12: 015_71.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 2195 pixels (3.81%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_12_015_71.gif\n",
      "\n",
      "Episode 13: 016_95.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 2999 pixels (5.21%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_13_016_95.gif\n",
      "\n",
      "Episode 14: 017_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 2255 pixels (3.91%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_14_017_68.gif\n",
      "\n",
      "Episode 15: 018_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -9.40, Steps to Find: 2\n",
      "  Tumor Size: 1676 pixels (2.91%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_15_018_84.gif\n",
      "\n",
      "Episode 16: 019_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 1280 pixels (2.22%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_16_019_52.gif\n",
      "\n",
      "Episode 17: 021_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 867 pixels (1.51%)\n",
      "  Action Distribution: [0.3 0.3 0.4]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_17_021_96.gif\n",
      "\n",
      "Episode 18: 022_89.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.80, Steps to Find: 20\n",
      "  Tumor Size: 1566 pixels (2.72%)\n",
      "  Action Distribution: [0.75 0.05 0.2 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_18_022_89.gif\n",
      "\n",
      "Episode 19: 023_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 1119 pixels (1.94%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_19_023_98.gif\n",
      "\n",
      "Episode 20: 024_49.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -9.10, Steps to Find: 3\n",
      "  Tumor Size: 1338 pixels (2.32%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_20_024_49.gif\n",
      "\n",
      "Episode 21: 026_43.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.50, Steps to Find: 20\n",
      "  Tumor Size: 663 pixels (1.15%)\n",
      "  Action Distribution: [0.35 0.1  0.55]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_21_026_43.gif\n",
      "\n",
      "Episode 22: 028_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 799 pixels (1.39%)\n",
      "  Action Distribution: [0.35 0.2  0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_22_028_56.gif\n",
      "\n",
      "Episode 23: 030_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.30, Steps to Find: 3\n",
      "  Tumor Size: 1979 pixels (3.44%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_23_030_99.gif\n",
      "\n",
      "Episode 24: 030_115.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 611 pixels (1.06%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_24_030_115.gif\n",
      "\n",
      "Episode 25: 032_134.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 19.00, Steps to Find: 7\n",
      "  Tumor Size: 554 pixels (0.96%)\n",
      "  Action Distribution: [0.4 0.2 0.4]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_25_032_134.gif\n",
      "\n",
      "Episode 26: 033_86.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 2788 pixels (4.84%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_26_033_86.gif\n",
      "\n",
      "Episode 27: 034_113.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 2141 pixels (3.72%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_27_034_113.gif\n",
      "\n",
      "Episode 28: 035_40.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 12.90, Steps to Find: 1\n",
      "  Tumor Size: 837 pixels (1.45%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_28_035_40.gif\n",
      "\n",
      "Episode 29: 036_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 795 pixels (1.38%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_29_036_83.gif\n",
      "\n",
      "Episode 30: 038_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 1720 pixels (2.99%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_30_038_84.gif\n",
      "\n",
      "Episode 31: 040_46.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.80, Steps to Find: 20\n",
      "  Tumor Size: 3375 pixels (5.86%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_31_040_46.gif\n",
      "\n",
      "Episode 32: 043_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 12.90, Steps to Find: 3\n",
      "  Tumor Size: 1217 pixels (2.11%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_32_043_48.gif\n",
      "\n",
      "Episode 33: 045_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 473 pixels (0.82%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_33_045_57.gif\n",
      "\n",
      "Episode 34: 045_82.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 2259 pixels (3.92%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_34_045_82.gif\n",
      "\n",
      "Episode 35: 046_44.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 1147 pixels (1.99%)\n",
      "  Action Distribution: [0.3  0.25 0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_35_046_44.gif\n",
      "\n",
      "Episode 36: 048_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 1308 pixels (2.27%)\n",
      "  Action Distribution: [0.65 0.15 0.2 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_36_048_49.gif\n",
      "\n",
      "Episode 37: 049_81.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 1649 pixels (2.86%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_37_049_81.gif\n",
      "\n",
      "Episode 38: 050_60.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -9.40, Steps to Find: 3\n",
      "  Tumor Size: 2312 pixels (4.01%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_38_050_60.gif\n",
      "\n",
      "Episode 39: 051_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 3155 pixels (5.48%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_39_051_94.gif\n",
      "\n",
      "Episode 40: 052_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 1228 pixels (2.13%)\n",
      "  Action Distribution: [0.5  0.15 0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_40_052_98.gif\n",
      "\n",
      "Episode 41: 053_85.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -9.40, Steps to Find: 8\n",
      "  Tumor Size: 2915 pixels (5.06%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_41_053_85.gif\n",
      "\n",
      "Episode 42: 054_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 4\n",
      "  Tumor Size: 2098 pixels (3.64%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_42_054_61.gif\n",
      "\n",
      "Episode 43: 055_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.50, Steps to Find: 11\n",
      "  Tumor Size: 2578 pixels (4.48%)\n",
      "  Action Distribution: [0.3  0.25 0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_43_055_61.gif\n",
      "\n",
      "Episode 44: 057_124.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.50, Steps to Find: 20\n",
      "  Tumor Size: 1433 pixels (2.49%)\n",
      "  Action Distribution: [0.3 0.1 0.6]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_44_057_124.gif\n",
      "\n",
      "Episode 45: 058_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 1231 pixels (2.14%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_45_058_84.gif\n",
      "\n",
      "Episode 46: 059_67.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 730 pixels (1.27%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_46_059_67.gif\n",
      "\n",
      "Episode 47: 066_116.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -9.40, Steps to Find: 4\n",
      "  Tumor Size: 674 pixels (1.17%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_47_066_116.gif\n",
      "\n",
      "Episode 48: 090_73.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 1051 pixels (1.82%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_48_090_73.gif\n",
      "\n",
      "Episode 49: 092_94.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1658 pixels (2.88%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_49_092_94.gif\n",
      "\n",
      "Episode 50: 104_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 3423 pixels (5.94%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_50_104_74.gif\n",
      "\n",
      "Episode 51: 116_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 1855 pixels (3.22%)\n",
      "  Action Distribution: [0.4  0.25 0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_51_116_58.gif\n",
      "\n",
      "Episode 52: 119_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 1148 pixels (1.99%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_52_119_53.gif\n",
      "\n",
      "Episode 53: 130_39.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -9.10, Steps to Find: 4\n",
      "  Tumor Size: 742 pixels (1.29%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_53_130_39.gif\n",
      "\n",
      "Episode 54: 147_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.30, Steps to Find: 3\n",
      "  Tumor Size: 2935 pixels (5.10%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_54_147_83.gif\n",
      "\n",
      "Episode 55: 154_87.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.50, Steps to Find: 20\n",
      "  Tumor Size: 1443 pixels (2.51%)\n",
      "  Action Distribution: [0.6 0.1 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_55_154_87.gif\n",
      "\n",
      "Episode 56: 155_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.50, Steps to Find: 20\n",
      "  Tumor Size: 1005 pixels (1.74%)\n",
      "  Action Distribution: [0.45 0.1  0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_56_155_48.gif\n",
      "\n",
      "Episode 57: 160_82.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.60, Steps to Find: 3\n",
      "  Tumor Size: 2528 pixels (4.39%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_57_160_82.gif\n",
      "\n",
      "Episode 58: 163_101.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 3132 pixels (5.44%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_58_163_101.gif\n",
      "\n",
      "Episode 59: 171_69.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 72.80, Steps to Find: 6\n",
      "  Tumor Size: 1076 pixels (1.87%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_59_171_69.gif\n",
      "\n",
      "Episode 60: 176_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2223 pixels (3.86%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_60_176_99.gif\n",
      "\n",
      "Episode 61: 177_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 823 pixels (1.43%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_61_177_57.gif\n",
      "\n",
      "Episode 62: 178_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 2286 pixels (3.97%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_62_178_85.gif\n",
      "\n",
      "Episode 63: 179_70.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 1958 pixels (3.40%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_63_179_70.gif\n",
      "\n",
      "Episode 64: 180_50.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 2855 pixels (4.96%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_64_180_50.gif\n",
      "\n",
      "Episode 65: 180_72.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 2771 pixels (4.81%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_65_180_72.gif\n",
      "\n",
      "Episode 66: 184_36.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.80, Steps to Find: 20\n",
      "  Tumor Size: 296 pixels (0.51%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_66_184_36.gif\n",
      "\n",
      "Episode 67: 188_62.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.50, Steps to Find: 7\n",
      "  Tumor Size: 1754 pixels (3.05%)\n",
      "  Action Distribution: [0.7 0.2 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_67_188_62.gif\n",
      "\n",
      "Episode 68: 190_81.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.50, Steps to Find: 20\n",
      "  Tumor Size: 987 pixels (1.71%)\n",
      "  Action Distribution: [0.6 0.1 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_68_190_81.gif\n",
      "\n",
      "Episode 69: 200_45.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.30, Steps to Find: 3\n",
      "  Tumor Size: 1239 pixels (2.15%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_69_200_45.gif\n",
      "\n",
      "Episode 70: 204_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 893 pixels (1.55%)\n",
      "  Action Distribution: [0.45 0.2  0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_70_204_52.gif\n",
      "\n",
      "Episode 71: 226_66.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 2037 pixels (3.54%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_71_226_66.gif\n",
      "\n",
      "Episode 72: 227_60.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.80, Steps to Find: 20\n",
      "  Tumor Size: 1494 pixels (2.59%)\n",
      "  Action Distribution: [0.6  0.05 0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_72_227_60.gif\n",
      "\n",
      "Episode 73: 231_90.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.20, Steps to Find: 2\n",
      "  Tumor Size: 3297 pixels (5.72%)\n",
      "  Action Distribution: [0.55 0.3  0.15]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_73_231_90.gif\n",
      "\n",
      "Episode 74: 236_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -9.40, Steps to Find: 3\n",
      "  Tumor Size: 2498 pixels (4.34%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_74_236_58.gif\n",
      "\n",
      "Episode 75: 237_41.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 840 pixels (1.46%)\n",
      "  Action Distribution: [0.6  0.25 0.15]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_75_237_41.gif\n",
      "\n",
      "Episode 76: 240_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 2725 pixels (4.73%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_76_240_52.gif\n",
      "\n",
      "Episode 77: 245_35.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.50, Steps to Find: 20\n",
      "  Tumor Size: 1257 pixels (2.18%)\n",
      "  Action Distribution: [0.55 0.35 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_77_245_35.gif\n",
      "\n",
      "Episode 78: 250_45.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 84.10, Steps to Find: 4\n",
      "  Tumor Size: 1616 pixels (2.81%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_78_250_45.gif\n",
      "\n",
      "Episode 79: 255_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 3030 pixels (5.26%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_79_255_56.gif\n",
      "\n",
      "Episode 80: 260_62.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 1653 pixels (2.87%)\n",
      "  Action Distribution: [0.4 0.2 0.4]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_80_260_62.gif\n",
      "\n",
      "Episode 81: 266_105.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 1725 pixels (2.99%)\n",
      "  Action Distribution: [0.4  0.35 0.25]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_81_266_105.gif\n",
      "\n",
      "Episode 82: 274_90.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 4092 pixels (7.10%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_82_274_90.gif\n",
      "\n",
      "Episode 83: 276_102.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -9.40, Steps to Find: 2\n",
      "  Tumor Size: 1831 pixels (3.18%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_83_276_102.gif\n",
      "\n",
      "Episode 84: 280_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 905 pixels (1.57%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_84_280_96.gif\n",
      "\n",
      "Episode 85: 282_53.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1994 pixels (3.46%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_85_282_53.gif\n",
      "\n",
      "Episode 86: 284_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 4461 pixels (7.74%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_86_284_88.gif\n",
      "\n",
      "Episode 87: 287_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 1807 pixels (3.14%)\n",
      "  Action Distribution: [0.3 0.2 0.5]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_87_287_97.gif\n",
      "\n",
      "Episode 88: 289_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.30, Steps to Find: 3\n",
      "  Tumor Size: 3435 pixels (5.96%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_88_289_74.gif\n",
      "\n",
      "Episode 89: 299_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.50, Steps to Find: 20\n",
      "  Tumor Size: 2607 pixels (4.53%)\n",
      "  Action Distribution: [0.45 0.1  0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_89_299_97.gif\n",
      "\n",
      "Episode 90: 300_107.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 2216 pixels (3.85%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_90_300_107.gif\n",
      "\n",
      "Episode 91: 308_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 4910 pixels (8.52%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_91_308_88.gif\n",
      "\n",
      "Episode 92: 314_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 932 pixels (1.62%)\n",
      "  Action Distribution: [0.15 0.25 0.6 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_92_314_91.gif\n",
      "\n",
      "Episode 93: 326_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 1227 pixels (2.13%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_93_326_68.gif\n",
      "\n",
      "Episode 94: 333_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 3974 pixels (6.90%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_94_333_91.gif\n",
      "\n",
      "Episode 95: 350_77.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.10, Steps to Find: 20\n",
      "  Tumor Size: 1879 pixels (3.26%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_95_350_77.gif\n",
      "\n",
      "Episode 96: 356_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.40, Steps to Find: 20\n",
      "  Tumor Size: 532 pixels (0.92%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_96_356_97.gif\n",
      "\n",
      "Episode 97: 360_103.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 3331 pixels (5.78%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_97_360_103.gif\n",
      "\n",
      "Episode 98: 363_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 872 pixels (1.51%)\n",
      "  Action Distribution: [0.25 0.25 0.5 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_98_363_48.gif\n",
      "\n",
      "Episode 99: 365_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.20, Steps to Find: 20\n",
      "  Tumor Size: 3872 pixels (6.72%)\n",
      "  Action Distribution: [0.25 0.3  0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.5, -0.2]_3actions/episode_99_365_83.gif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_results = testing(\n",
    "    agent=agent,\n",
    "    test_pairs=prepare(mode=\"test\"),\n",
    "    agent_type=\"ppo\",\n",
    "    num_episodes=100,\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    save_gifs=True,\n",
    "    gif_folder=f\"GIFs_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "sucess[f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"] = overall_results['success_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8f1fc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/martina/codi2/4year/tfg/ppo/wandb/run-20251114_001200-51iaxmc3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/51iaxmc3' target=\"_blank\">PPO_batch128_rewards[5.0, -0.2, -0.05]_3actions</a></strong> to <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/51iaxmc3' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/51iaxmc3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Global-Aware PPO training...\n",
      "Episode 0 | Avg Reward: 7.54 | Mean Reward (100): 7.54 | Actor Loss: -0.0115\n",
      "New best model saved!\n",
      "Episode 25 | Avg Reward: 4.63 | Mean Reward (100): 6.08 | Actor Loss: 0.0016\n",
      "Episode 50 | Avg Reward: 9.25 | Mean Reward (100): 7.14 | Actor Loss: -0.0159\n",
      "Episode 75 | Avg Reward: 8.81 | Mean Reward (100): 7.56 | Actor Loss: -0.0141\n",
      "New best model saved!\n",
      "Episode 100 | Avg Reward: 23.44 | Mean Reward (100): 11.53 | Actor Loss: -0.0050\n",
      "New best model saved!\n",
      "Episode 125 | Avg Reward: 12.02 | Mean Reward (100): 13.38 | Actor Loss: 0.0031\n",
      "New best model saved!\n",
      "Episode 150 | Avg Reward: 11.56 | Mean Reward (100): 13.96 | Actor Loss: -0.0088\n",
      "New best model saved!\n",
      "Episode 175 | Avg Reward: 27.18 | Mean Reward (100): 18.55 | Actor Loss: 0.0113\n",
      "New best model saved!\n",
      "Episode 200 | Avg Reward: 19.85 | Mean Reward (100): 17.65 | Actor Loss: -0.0101\n",
      "Episode 225 | Avg Reward: 20.11 | Mean Reward (100): 19.68 | Actor Loss: 0.0058\n",
      "New best model saved!\n",
      "Episode 250 | Avg Reward: 23.76 | Mean Reward (100): 22.72 | Actor Loss: -0.0032\n",
      "New best model saved!\n",
      "Episode 275 | Avg Reward: 26.01 | Mean Reward (100): 22.43 | Actor Loss: -0.0067\n",
      "Episode 300 | Avg Reward: 17.73 | Mean Reward (100): 21.90 | Actor Loss: 0.0055\n",
      "Episode 325 | Avg Reward: 29.77 | Mean Reward (100): 24.32 | Actor Loss: 0.0134\n",
      "New best model saved!\n",
      "Episode 350 | Avg Reward: 36.46 | Mean Reward (100): 27.49 | Actor Loss: 0.0134\n",
      "New best model saved!\n",
      "Episode 375 | Avg Reward: 27.90 | Mean Reward (100): 27.97 | Actor Loss: -0.0161\n",
      "New best model saved!\n",
      "Episode 400 | Avg Reward: 28.90 | Mean Reward (100): 30.76 | Actor Loss: 0.0124\n",
      "New best model saved!\n",
      "Episode 425 | Avg Reward: 39.88 | Mean Reward (100): 33.28 | Actor Loss: -0.0019\n",
      "New best model saved!\n",
      "Episode 450 | Avg Reward: 35.13 | Mean Reward (100): 32.95 | Actor Loss: -0.0127\n",
      "Episode 475 | Avg Reward: 21.21 | Mean Reward (100): 31.28 | Actor Loss: -0.0060\n",
      "Episode 500 | Avg Reward: 24.70 | Mean Reward (100): 30.23 | Actor Loss: 0.0073\n",
      "Episode 525 | Avg Reward: 27.03 | Mean Reward (100): 27.02 | Actor Loss: -0.0171\n",
      "Episode 550 | Avg Reward: 30.08 | Mean Reward (100): 25.75 | Actor Loss: -0.0084\n",
      "Episode 575 | Avg Reward: 8.81 | Mean Reward (100): 22.65 | Actor Loss: -0.0028\n",
      "Episode 600 | Avg Reward: 43.62 | Mean Reward (100): 27.38 | Actor Loss: 0.0050\n",
      "Episode 625 | Avg Reward: 21.78 | Mean Reward (100): 26.07 | Actor Loss: 0.0210\n",
      "Episode 650 | Avg Reward: 23.88 | Mean Reward (100): 24.52 | Actor Loss: 0.0047\n",
      "Episode 675 | Avg Reward: 53.98 | Mean Reward (100): 35.81 | Actor Loss: 0.0175\n",
      "New best model saved!\n",
      "Episode 700 | Avg Reward: 34.73 | Mean Reward (100): 33.59 | Actor Loss: -0.0084\n",
      "Episode 725 | Avg Reward: 24.08 | Mean Reward (100): 34.16 | Actor Loss: -0.0013\n",
      "Episode 750 | Avg Reward: 28.03 | Mean Reward (100): 35.20 | Actor Loss: -0.0018\n",
      "Episode 775 | Avg Reward: 20.82 | Mean Reward (100): 26.91 | Actor Loss: 0.0118\n",
      "Episode 800 | Avg Reward: 35.65 | Mean Reward (100): 27.14 | Actor Loss: 0.0037\n",
      "Episode 825 | Avg Reward: 34.09 | Mean Reward (100): 29.64 | Actor Loss: -0.0121\n",
      "Episode 850 | Avg Reward: 38.33 | Mean Reward (100): 32.22 | Actor Loss: 0.0061\n",
      "Episode 875 | Avg Reward: 24.98 | Mean Reward (100): 33.26 | Actor Loss: -0.0044\n",
      "Episode 900 | Avg Reward: 30.90 | Mean Reward (100): 32.07 | Actor Loss: 0.0075\n",
      "Episode 925 | Avg Reward: 31.95 | Mean Reward (100): 31.54 | Actor Loss: -0.0099\n",
      "Episode 950 | Avg Reward: 24.60 | Mean Reward (100): 28.11 | Actor Loss: 0.0071\n",
      "Episode 975 | Avg Reward: 24.54 | Mean Reward (100): 28.00 | Actor Loss: -0.0124\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▂▄▁▂▃▅▃▆▂▅▄▃▅▇▇▁▆▄▂▃▅▁▃▄▅█▅▇▃▄▄▆▅▂▅▃▆▂▅▂</td></tr><tr><td>avg_episode_reward</td><td>▁▁▂▂▄▂▂▄▃▃▄▄▃▅▆▄▄▆▅▃▄▄▅▂▇▃▄█▅▄▄▃▅▅▆▄▅▅▄▄</td></tr><tr><td>critic_loss</td><td>▁▁▁▂▄▃▃▅▅▄▆▆▅▆▆▇▆█▇▅▆▆▆▄█▅▆█▇▆▆▅▇▇▇▅▆▆▅▅</td></tr><tr><td>entropy</td><td>███▇▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▂▂</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>mean_reward_100</td><td>▁▁▁▁▂▃▃▄▄▄▅▅▅▅▆▆▇▇▇▇▇▆▆▅▆▆▅█▇██▆▆▇▇▇▇▇▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>-0.01239</td></tr><tr><td>avg_episode_reward</td><td>24.536</td></tr><tr><td>critic_loss</td><td>160.59939</td></tr><tr><td>entropy</td><td>0.25473</td></tr><tr><td>episode</td><td>975</td></tr><tr><td>mean_reward_100</td><td>27.996</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">PPO_batch128_rewards[5.0, -0.2, -0.05]_3actions</strong> at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/51iaxmc3' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/51iaxmc3</a><br> View project at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251114_001200-51iaxmc3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -0.2, -0.05], \n",
    "    'action_space': gym.spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "LR = 1e-4\n",
    "MAX_EPISODES = 1000\n",
    "NUM_STEPS = 512  # Start with smaller rollout for testing\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "env = GlobalAwareGlioblastoma(*train_pairs[0], **CURRENT_CONFIG)\n",
    "model = GlobalAwarePPOActorCritic(env, learning_rate=LR, device='cpu')\n",
    "agent = GlobalAwarePPOAgent(\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    model=model,\n",
    "    train_pairs=train_pairs,\n",
    "    env_class=GlobalAwareGlioblastoma,  # Use the new environment class\n",
    "    gamma=0.99,\n",
    "    clip_epsilon=0.2,\n",
    "    ppo_epochs=4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "\n",
    "wandb.init(project=\"TFG_Glioblastoma_PPO\", \n",
    "           name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\",\n",
    "           config={\n",
    "               \"learning_rate\": LR,\n",
    "               \"max_episodes\": MAX_EPISODES,\n",
    "               \"num_steps\": NUM_STEPS,\n",
    "               \"batch_size\": BATCH_SIZE,\n",
    "               \"configuration\": CURRENT_CONFIG\n",
    "           })\n",
    "\n",
    "# Start training\n",
    "agent.train(max_episodes=MAX_EPISODES, num_steps=NUM_STEPS)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73c489b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 100 pairs out of 100 listed in CSV.\n",
      "Saved GIF for episode 0 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_0_002_58.gif\n",
      "Saved GIF for episode 10 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_10_013_86.gif\n",
      "Saved GIF for episode 20 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_20_024_49.gif\n",
      "Saved GIF for episode 30 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_30_038_84.gif\n",
      "Saved GIF for episode 40 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_40_052_98.gif\n",
      "Saved GIF for episode 50 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_50_104_74.gif\n",
      "Saved GIF for episode 60 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_60_176_99.gif\n",
      "Saved GIF for episode 70 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_70_204_52.gif\n",
      "Saved GIF for episode 80 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_80_260_62.gif\n",
      "Saved GIF for episode 90 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_90_300_107.gif\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS (PPO Agent)\n",
      "============================================================\n",
      "Success Rate: 44.00%\n",
      "Average Episode Reward: 27.42\n",
      "Average Steps to Find Tumor: 11.61\n",
      "Average Tumor Rewards per Episode: 5.97\n",
      "Tumor Size Statistics:\n",
      "  Biggest Tumor: 4910 pixels (8.52%)\n",
      "  Smallest Tumor: 296 pixels (0.51%)\n",
      "  Average Tumor: 1873 pixels (3.25%)\n",
      "Overall Action Distribution: [0.7515 0.1205 0.128 ]\n",
      "  Successful Episodes: [0.87954545 0.06363636 0.05681818]\n",
      "  Unsuccessful Episodes: [0.65089286 0.16517857 0.18392857]\n",
      "\n",
      "Detailed Results for 100 episodes:\n",
      "--------------------------------------------------------------------------------\n",
      "Episode 0: 002_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.75, Steps to Find: 3\n",
      "  Tumor Size: 2049 pixels (3.56%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_0_002_58.gif\n",
      "\n",
      "Episode 1: 004_87.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 2727 pixels (4.73%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_1_004_87.gif\n",
      "\n",
      "Episode 2: 005_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 768 pixels (1.33%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_2_005_94.gif\n",
      "\n",
      "Episode 3: 006_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.70, Steps to Find: 2\n",
      "  Tumor Size: 2834 pixels (4.92%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_3_006_83.gif\n",
      "\n",
      "Episode 4: 007_54.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 8\n",
      "  Tumor Size: 1299 pixels (2.26%)\n",
      "  Action Distribution: [0.  0.3 0.7]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_4_007_54.gif\n",
      "\n",
      "Episode 5: 008_41.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 1243 pixels (2.16%)\n",
      "  Action Distribution: [0.   0.55 0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_5_008_41.gif\n",
      "\n",
      "Episode 6: 009_65.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 4172 pixels (7.24%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_6_009_65.gif\n",
      "\n",
      "Episode 7: 010_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.70, Steps to Find: 2\n",
      "  Tumor Size: 1327 pixels (2.30%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_7_010_89.gif\n",
      "\n",
      "Episode 8: 011_103.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 831 pixels (1.44%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_8_011_103.gif\n",
      "\n",
      "Episode 9: 012_69.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1365 pixels (2.37%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_9_012_69.gif\n",
      "\n",
      "Episode 10: 013_86.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.70, Steps to Find: 2\n",
      "  Tumor Size: 1536 pixels (2.67%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_10_013_86.gif\n",
      "\n",
      "Episode 11: 014_46.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 2035 pixels (3.53%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_11_014_46.gif\n",
      "\n",
      "Episode 12: 015_71.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 2195 pixels (3.81%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_12_015_71.gif\n",
      "\n",
      "Episode 13: 016_95.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.70, Steps to Find: 2\n",
      "  Tumor Size: 2999 pixels (5.21%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_13_016_95.gif\n",
      "\n",
      "Episode 14: 017_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 2255 pixels (3.91%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_14_017_68.gif\n",
      "\n",
      "Episode 15: 018_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.70, Steps to Find: 2\n",
      "  Tumor Size: 1676 pixels (2.91%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_15_018_84.gif\n",
      "\n",
      "Episode 16: 019_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 1280 pixels (2.22%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_16_019_52.gif\n",
      "\n",
      "Episode 17: 021_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 867 pixels (1.51%)\n",
      "  Action Distribution: [0.  0.7 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_17_021_96.gif\n",
      "\n",
      "Episode 18: 022_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 1566 pixels (2.72%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_18_022_89.gif\n",
      "\n",
      "Episode 19: 023_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1119 pixels (1.94%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_19_023_98.gif\n",
      "\n",
      "Episode 20: 024_49.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 58.85, Steps to Find: 3\n",
      "  Tumor Size: 1338 pixels (2.32%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_20_024_49.gif\n",
      "\n",
      "Episode 21: 026_43.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 663 pixels (1.15%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_21_026_43.gif\n",
      "\n",
      "Episode 22: 028_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 799 pixels (1.39%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_22_028_56.gif\n",
      "\n",
      "Episode 23: 030_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.90, Steps to Find: 3\n",
      "  Tumor Size: 1979 pixels (3.44%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_23_030_99.gif\n",
      "\n",
      "Episode 24: 030_115.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 611 pixels (1.06%)\n",
      "  Action Distribution: [0.   0.45 0.55]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_24_030_115.gif\n",
      "\n",
      "Episode 25: 032_134.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 1.95, Steps to Find: 3\n",
      "  Tumor Size: 554 pixels (0.96%)\n",
      "  Action Distribution: [0.   0.55 0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_25_032_134.gif\n",
      "\n",
      "Episode 26: 033_86.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 2788 pixels (4.84%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_26_033_86.gif\n",
      "\n",
      "Episode 27: 034_113.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 2141 pixels (3.72%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_27_034_113.gif\n",
      "\n",
      "Episode 28: 035_40.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.90, Steps to Find: 1\n",
      "  Tumor Size: 837 pixels (1.45%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_28_035_40.gif\n",
      "\n",
      "Episode 29: 036_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 795 pixels (1.38%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_29_036_83.gif\n",
      "\n",
      "Episode 30: 038_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1720 pixels (2.99%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_30_038_84.gif\n",
      "\n",
      "Episode 31: 040_46.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 3375 pixels (5.86%)\n",
      "  Action Distribution: [0.   0.35 0.65]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_31_040_46.gif\n",
      "\n",
      "Episode 32: 043_48.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.90, Steps to Find: 3\n",
      "  Tumor Size: 1217 pixels (2.11%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_32_043_48.gif\n",
      "\n",
      "Episode 33: 045_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 473 pixels (0.82%)\n",
      "  Action Distribution: [0.  0.4 0.6]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_33_045_57.gif\n",
      "\n",
      "Episode 34: 045_82.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 2259 pixels (3.92%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_34_045_82.gif\n",
      "\n",
      "Episode 35: 046_44.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 1.65, Steps to Find: 3\n",
      "  Tumor Size: 1147 pixels (1.99%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_35_046_44.gif\n",
      "\n",
      "Episode 36: 048_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 1308 pixels (2.27%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_36_048_49.gif\n",
      "\n",
      "Episode 37: 049_81.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1649 pixels (2.86%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_37_049_81.gif\n",
      "\n",
      "Episode 38: 050_60.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 2312 pixels (4.01%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_38_050_60.gif\n",
      "\n",
      "Episode 39: 051_94.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 3155 pixels (5.48%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_39_051_94.gif\n",
      "\n",
      "Episode 40: 052_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1228 pixels (2.13%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_40_052_98.gif\n",
      "\n",
      "Episode 41: 053_85.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 2915 pixels (5.06%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_41_053_85.gif\n",
      "\n",
      "Episode 42: 054_61.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 74.30, Steps to Find: 2\n",
      "  Tumor Size: 2098 pixels (3.64%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_42_054_61.gif\n",
      "\n",
      "Episode 43: 055_61.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.55, Steps to Find: 8\n",
      "  Tumor Size: 2578 pixels (4.48%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_43_055_61.gif\n",
      "\n",
      "Episode 44: 057_124.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 6\n",
      "  Tumor Size: 1433 pixels (2.49%)\n",
      "  Action Distribution: [0.  0.5 0.5]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_44_057_124.gif\n",
      "\n",
      "Episode 45: 058_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1231 pixels (2.14%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_45_058_84.gif\n",
      "\n",
      "Episode 46: 059_67.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 730 pixels (1.27%)\n",
      "  Action Distribution: [0.  0.4 0.6]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_46_059_67.gif\n",
      "\n",
      "Episode 47: 066_116.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.70, Steps to Find: 2\n",
      "  Tumor Size: 674 pixels (1.17%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_47_066_116.gif\n",
      "\n",
      "Episode 48: 090_73.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1051 pixels (1.82%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_48_090_73.gif\n",
      "\n",
      "Episode 49: 092_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 1658 pixels (2.88%)\n",
      "  Action Distribution: [0.  0.4 0.6]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_49_092_94.gif\n",
      "\n",
      "Episode 50: 104_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 3423 pixels (5.94%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_50_104_74.gif\n",
      "\n",
      "Episode 51: 116_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 1855 pixels (3.22%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_51_116_58.gif\n",
      "\n",
      "Episode 52: 119_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 1148 pixels (1.99%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_52_119_53.gif\n",
      "\n",
      "Episode 53: 130_39.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.40, Steps to Find: 20\n",
      "  Tumor Size: 742 pixels (1.29%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_53_130_39.gif\n",
      "\n",
      "Episode 54: 147_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 2935 pixels (5.10%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_54_147_83.gif\n",
      "\n",
      "Episode 55: 154_87.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 1443 pixels (2.51%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_55_154_87.gif\n",
      "\n",
      "Episode 56: 155_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 1005 pixels (1.74%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_56_155_48.gif\n",
      "\n",
      "Episode 57: 160_82.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 2528 pixels (4.39%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_57_160_82.gif\n",
      "\n",
      "Episode 58: 163_101.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 3132 pixels (5.44%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_58_163_101.gif\n",
      "\n",
      "Episode 59: 171_69.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 1076 pixels (1.87%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_59_171_69.gif\n",
      "\n",
      "Episode 60: 176_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 2223 pixels (3.86%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_60_176_99.gif\n",
      "\n",
      "Episode 61: 177_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 823 pixels (1.43%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_61_177_57.gif\n",
      "\n",
      "Episode 62: 178_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 2286 pixels (3.97%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_62_178_85.gif\n",
      "\n",
      "Episode 63: 179_70.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1958 pixels (3.40%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_63_179_70.gif\n",
      "\n",
      "Episode 64: 180_50.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 2855 pixels (4.96%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_64_180_50.gif\n",
      "\n",
      "Episode 65: 180_72.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 2771 pixels (4.81%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_65_180_72.gif\n",
      "\n",
      "Episode 66: 184_36.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.90, Steps to Find: 3\n",
      "  Tumor Size: 296 pixels (0.51%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_66_184_36.gif\n",
      "\n",
      "Episode 67: 188_62.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.90, Steps to Find: 3\n",
      "  Tumor Size: 1754 pixels (3.05%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_67_188_62.gif\n",
      "\n",
      "Episode 68: 190_81.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 987 pixels (1.71%)\n",
      "  Action Distribution: [0.  0.4 0.6]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_68_190_81.gif\n",
      "\n",
      "Episode 69: 200_45.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 1239 pixels (2.15%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_69_200_45.gif\n",
      "\n",
      "Episode 70: 204_52.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 893 pixels (1.55%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_70_204_52.gif\n",
      "\n",
      "Episode 71: 226_66.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.90, Steps to Find: 3\n",
      "  Tumor Size: 2037 pixels (3.54%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_71_226_66.gif\n",
      "\n",
      "Episode 72: 227_60.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.70, Steps to Find: 2\n",
      "  Tumor Size: 1494 pixels (2.59%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_72_227_60.gif\n",
      "\n",
      "Episode 73: 231_90.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 3297 pixels (5.72%)\n",
      "  Action Distribution: [0.   0.45 0.55]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_73_231_90.gif\n",
      "\n",
      "Episode 74: 236_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 7.15, Steps to Find: 5\n",
      "  Tumor Size: 2498 pixels (4.34%)\n",
      "  Action Distribution: [0.25 0.35 0.4 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_74_236_58.gif\n",
      "\n",
      "Episode 75: 237_41.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.90, Steps to Find: 3\n",
      "  Tumor Size: 840 pixels (1.46%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_75_237_41.gif\n",
      "\n",
      "Episode 76: 240_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 2725 pixels (4.73%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_76_240_52.gif\n",
      "\n",
      "Episode 77: 245_35.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 1257 pixels (2.18%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_77_245_35.gif\n",
      "\n",
      "Episode 78: 250_45.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 1616 pixels (2.81%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_78_250_45.gif\n",
      "\n",
      "Episode 79: 255_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 3030 pixels (5.26%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_79_255_56.gif\n",
      "\n",
      "Episode 80: 260_62.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 1653 pixels (2.87%)\n",
      "  Action Distribution: [0.  0.4 0.6]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_80_260_62.gif\n",
      "\n",
      "Episode 81: 266_105.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1725 pixels (2.99%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_81_266_105.gif\n",
      "\n",
      "Episode 82: 274_90.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 4092 pixels (7.10%)\n",
      "  Action Distribution: [0.05 0.55 0.4 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_82_274_90.gif\n",
      "\n",
      "Episode 83: 276_102.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.70, Steps to Find: 2\n",
      "  Tumor Size: 1831 pixels (3.18%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_83_276_102.gif\n",
      "\n",
      "Episode 84: 280_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 905 pixels (1.57%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_84_280_96.gif\n",
      "\n",
      "Episode 85: 282_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 1994 pixels (3.46%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_85_282_53.gif\n",
      "\n",
      "Episode 86: 284_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 4461 pixels (7.74%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_86_284_88.gif\n",
      "\n",
      "Episode 87: 287_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1807 pixels (3.14%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_87_287_97.gif\n",
      "\n",
      "Episode 88: 289_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.55, Steps to Find: 3\n",
      "  Tumor Size: 3435 pixels (5.96%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_88_289_74.gif\n",
      "\n",
      "Episode 89: 299_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 2607 pixels (4.53%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_89_299_97.gif\n",
      "\n",
      "Episode 90: 300_107.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 2216 pixels (3.85%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_90_300_107.gif\n",
      "\n",
      "Episode 91: 308_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 4910 pixels (8.52%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_91_308_88.gif\n",
      "\n",
      "Episode 92: 314_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 932 pixels (1.62%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_92_314_91.gif\n",
      "\n",
      "Episode 93: 326_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1227 pixels (2.13%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_93_326_68.gif\n",
      "\n",
      "Episode 94: 333_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 3974 pixels (6.90%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_94_333_91.gif\n",
      "\n",
      "Episode 95: 350_77.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 1879 pixels (3.26%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_95_350_77.gif\n",
      "\n",
      "Episode 96: 356_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.70, Steps to Find: 20\n",
      "  Tumor Size: 532 pixels (0.92%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_96_356_97.gif\n",
      "\n",
      "Episode 97: 360_103.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 3331 pixels (5.78%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_97_360_103.gif\n",
      "\n",
      "Episode 98: 363_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.55, Steps to Find: 20\n",
      "  Tumor Size: 872 pixels (1.51%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_98_363_48.gif\n",
      "\n",
      "Episode 99: 365_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -3.70, Steps to Find: 2\n",
      "  Tumor Size: 3872 pixels (6.72%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_3actions/episode_99_365_83.gif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_results = testing(\n",
    "    agent=agent,\n",
    "    test_pairs=prepare(mode=\"test\"),\n",
    "    agent_type=\"ppo\",\n",
    "    num_episodes=100,\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    save_gifs=True,\n",
    "    gif_folder=f\"GIFs_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "sucess[f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"] = overall_results['success_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22ca1981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/martina/codi2/4year/tfg/ppo/wandb/run-20251114_001723-5vg5efsm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/5vg5efsm' target=\"_blank\">PPO_batch128_rewards[5.0, -0.1, -0.02]_3actions</a></strong> to <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/5vg5efsm' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/5vg5efsm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Global-Aware PPO training...\n",
      "Episode 0 | Avg Reward: 4.95 | Mean Reward (100): 4.95 | Actor Loss: -0.0096\n",
      "New best model saved!\n",
      "Episode 25 | Avg Reward: 6.35 | Mean Reward (100): 5.65 | Actor Loss: 0.0090\n",
      "New best model saved!\n",
      "Episode 50 | Avg Reward: 6.17 | Mean Reward (100): 5.82 | Actor Loss: -0.0203\n",
      "New best model saved!\n",
      "Episode 75 | Avg Reward: 7.99 | Mean Reward (100): 6.36 | Actor Loss: -0.0003\n",
      "New best model saved!\n",
      "Episode 100 | Avg Reward: 22.64 | Mean Reward (100): 10.79 | Actor Loss: -0.0339\n",
      "New best model saved!\n",
      "Episode 125 | Avg Reward: 20.32 | Mean Reward (100): 14.28 | Actor Loss: -0.0050\n",
      "New best model saved!\n",
      "Episode 150 | Avg Reward: 27.66 | Mean Reward (100): 19.65 | Actor Loss: 0.0137\n",
      "New best model saved!\n",
      "Episode 175 | Avg Reward: 15.19 | Mean Reward (100): 21.45 | Actor Loss: -0.0092\n",
      "New best model saved!\n",
      "Episode 200 | Avg Reward: 19.11 | Mean Reward (100): 20.57 | Actor Loss: -0.0170\n",
      "Episode 225 | Avg Reward: 14.44 | Mean Reward (100): 19.10 | Actor Loss: -0.0064\n",
      "Episode 250 | Avg Reward: 19.70 | Mean Reward (100): 17.11 | Actor Loss: -0.0155\n",
      "Episode 275 | Avg Reward: 26.61 | Mean Reward (100): 19.97 | Actor Loss: -0.0070\n",
      "Episode 300 | Avg Reward: 17.73 | Mean Reward (100): 19.62 | Actor Loss: -0.0148\n",
      "Episode 325 | Avg Reward: 19.52 | Mean Reward (100): 20.89 | Actor Loss: -0.0110\n",
      "Episode 350 | Avg Reward: 20.47 | Mean Reward (100): 21.08 | Actor Loss: -0.0033\n",
      "Episode 375 | Avg Reward: 25.33 | Mean Reward (100): 20.76 | Actor Loss: -0.0036\n",
      "Episode 400 | Avg Reward: 31.05 | Mean Reward (100): 24.09 | Actor Loss: 0.0119\n",
      "New best model saved!\n",
      "Episode 425 | Avg Reward: 29.85 | Mean Reward (100): 26.68 | Actor Loss: 0.0002\n",
      "New best model saved!\n",
      "Episode 450 | Avg Reward: 19.59 | Mean Reward (100): 26.45 | Actor Loss: 0.0002\n",
      "Episode 475 | Avg Reward: 38.40 | Mean Reward (100): 29.72 | Actor Loss: 0.0069\n",
      "New best model saved!\n",
      "Episode 500 | Avg Reward: 34.94 | Mean Reward (100): 30.70 | Actor Loss: -0.0008\n",
      "New best model saved!\n",
      "Episode 525 | Avg Reward: 20.07 | Mean Reward (100): 28.25 | Actor Loss: -0.0041\n",
      "Episode 550 | Avg Reward: 37.77 | Mean Reward (100): 32.80 | Actor Loss: -0.0035\n",
      "New best model saved!\n",
      "Episode 575 | Avg Reward: 34.77 | Mean Reward (100): 31.89 | Actor Loss: -0.0058\n",
      "Episode 600 | Avg Reward: 25.61 | Mean Reward (100): 29.56 | Actor Loss: -0.0197\n",
      "Episode 625 | Avg Reward: 24.50 | Mean Reward (100): 30.66 | Actor Loss: 0.0085\n",
      "Episode 650 | Avg Reward: 28.16 | Mean Reward (100): 28.26 | Actor Loss: -0.0023\n",
      "Episode 675 | Avg Reward: 28.20 | Mean Reward (100): 26.62 | Actor Loss: -0.0166\n",
      "Episode 700 | Avg Reward: 33.34 | Mean Reward (100): 28.55 | Actor Loss: 0.0076\n",
      "Episode 725 | Avg Reward: 22.97 | Mean Reward (100): 28.17 | Actor Loss: -0.0081\n",
      "Episode 750 | Avg Reward: 24.11 | Mean Reward (100): 27.15 | Actor Loss: 0.0119\n",
      "Episode 775 | Avg Reward: 26.58 | Mean Reward (100): 26.75 | Actor Loss: -0.0006\n",
      "Episode 800 | Avg Reward: 20.47 | Mean Reward (100): 23.53 | Actor Loss: 0.0082\n",
      "Episode 825 | Avg Reward: 25.62 | Mean Reward (100): 24.20 | Actor Loss: -0.0062\n",
      "Episode 850 | Avg Reward: 38.02 | Mean Reward (100): 27.67 | Actor Loss: -0.0004\n",
      "Episode 875 | Avg Reward: 28.81 | Mean Reward (100): 28.23 | Actor Loss: 0.0060\n",
      "Episode 900 | Avg Reward: 26.41 | Mean Reward (100): 29.72 | Actor Loss: 0.0037\n",
      "Episode 925 | Avg Reward: 16.58 | Mean Reward (100): 27.46 | Actor Loss: -0.0044\n",
      "Episode 950 | Avg Reward: 30.09 | Mean Reward (100): 25.47 | Actor Loss: -0.0080\n",
      "Episode 975 | Avg Reward: 41.44 | Mean Reward (100): 28.63 | Actor Loss: -0.0046\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▅▇▃▆▁▅█▅▃▅▄▅▄▄▅▅█▆▆▇▆▅▅▅▃▇▆▄▇▅█▆▇▅▆▇▇▅▅▅</td></tr><tr><td>avg_episode_reward</td><td>▁▁▁▂▄▄▅▃▄▃▄▅▃▄▄▅▆▆▄▇▇▄▇▇▅▅▅▅▆▄▅▅▄▅▇▆▅▃▆█</td></tr><tr><td>critic_loss</td><td>▁▁▁▁▄▄▆▄▅▄▄▆▄▅▆▆▆▆▆▇▇▆▇▇▆▇▆▇▆▆▆▆▅▅█▆▆▅▆▇</td></tr><tr><td>entropy</td><td>██▇▇▆▄▄▄▄▄▄▃▅▃▃▂▃▂▂▃▂▃▁▃▃▁▂▂▃▃▂▃▂▃▂▂▂▂▃▁</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>mean_reward_100</td><td>▁▁▁▁▂▃▅▅▅▅▄▅▅▅▅▅▆▆▆▇▇▇██▇▇▇▆▇▇▇▆▆▆▇▇▇▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>-0.00462</td></tr><tr><td>avg_episode_reward</td><td>41.44</td></tr><tr><td>critic_loss</td><td>182.87313</td></tr><tr><td>entropy</td><td>0.40932</td></tr><tr><td>episode</td><td>975</td></tr><tr><td>mean_reward_100</td><td>28.6312</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">PPO_batch128_rewards[5.0, -0.1, -0.02]_3actions</strong> at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/5vg5efsm' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/5vg5efsm</a><br> View project at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251114_001723-5vg5efsm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -0.1, -0.02], \n",
    "    'action_space': gym.spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "LR = 1e-4\n",
    "MAX_EPISODES = 1000\n",
    "NUM_STEPS = 512  # Start with smaller rollout for testing\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "env = GlobalAwareGlioblastoma(*train_pairs[0], **CURRENT_CONFIG)\n",
    "model = GlobalAwarePPOActorCritic(env, learning_rate=LR, device='cpu')\n",
    "agent = GlobalAwarePPOAgent(\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    model=model,\n",
    "    train_pairs=train_pairs,\n",
    "    env_class=GlobalAwareGlioblastoma,  # Use the new environment class\n",
    "    gamma=0.99,\n",
    "    clip_epsilon=0.2,\n",
    "    ppo_epochs=4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "\n",
    "wandb.init(project=\"TFG_Glioblastoma_PPO\", \n",
    "           name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\",\n",
    "           config={\n",
    "               \"learning_rate\": LR,\n",
    "               \"max_episodes\": MAX_EPISODES,\n",
    "               \"num_steps\": NUM_STEPS,\n",
    "               \"batch_size\": BATCH_SIZE,\n",
    "               \"configuration\": CURRENT_CONFIG\n",
    "           })\n",
    "\n",
    "# Start training\n",
    "agent.train(max_episodes=MAX_EPISODES, num_steps=NUM_STEPS)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cddeb890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 100 pairs out of 100 listed in CSV.\n",
      "Saved GIF for episode 0 at GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_0_002_58.gif\n",
      "Saved GIF for episode 10 at GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_10_013_86.gif\n",
      "Saved GIF for episode 20 at GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_20_024_49.gif\n",
      "Saved GIF for episode 30 at GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_30_038_84.gif\n",
      "Saved GIF for episode 40 at GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_40_052_98.gif\n",
      "Saved GIF for episode 50 at GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_50_104_74.gif\n",
      "Saved GIF for episode 60 at GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_60_176_99.gif\n",
      "Saved GIF for episode 70 at GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_70_204_52.gif\n",
      "Saved GIF for episode 80 at GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_80_260_62.gif\n",
      "Saved GIF for episode 90 at GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_90_300_107.gif\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS (PPO Agent)\n",
      "============================================================\n",
      "Success Rate: 37.00%\n",
      "Average Episode Reward: 23.81\n",
      "Average Steps to Find Tumor: 12.05\n",
      "Average Tumor Rewards per Episode: 5.01\n",
      "Tumor Size Statistics:\n",
      "  Biggest Tumor: 4910 pixels (8.52%)\n",
      "  Smallest Tumor: 296 pixels (0.51%)\n",
      "  Average Tumor: 1873 pixels (3.25%)\n",
      "Overall Action Distribution: [0.694  0.1365 0.1695]\n",
      "  Successful Episodes: [0.86081081 0.07027027 0.06891892]\n",
      "  Unsuccessful Episodes: [0.59603175 0.17539683 0.22857143]\n",
      "\n",
      "Detailed Results for 100 episodes:\n",
      "--------------------------------------------------------------------------------\n",
      "Episode 0: 002_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.92, Steps to Find: 20\n",
      "  Tumor Size: 2049 pixels (3.56%)\n",
      "  Action Distribution: [0.95 0.   0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_0_002_58.gif\n",
      "\n",
      "Episode 1: 004_87.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 2727 pixels (4.73%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_1_004_87.gif\n",
      "\n",
      "Episode 2: 005_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.84, Steps to Find: 20\n",
      "  Tumor Size: 768 pixels (1.33%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_2_005_94.gif\n",
      "\n",
      "Episode 3: 006_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 4\n",
      "  Tumor Size: 2834 pixels (4.92%)\n",
      "  Action Distribution: [0.2 0.3 0.5]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_3_006_83.gif\n",
      "\n",
      "Episode 4: 007_54.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.76, Steps to Find: 16\n",
      "  Tumor Size: 1299 pixels (2.26%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_4_007_54.gif\n",
      "\n",
      "Episode 5: 008_41.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 23.66, Steps to Find: 3\n",
      "  Tumor Size: 1243 pixels (2.16%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_5_008_41.gif\n",
      "\n",
      "Episode 6: 009_65.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.88, Steps to Find: 3\n",
      "  Tumor Size: 4172 pixels (7.24%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_6_009_65.gif\n",
      "\n",
      "Episode 7: 010_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.96, Steps to Find: 3\n",
      "  Tumor Size: 1327 pixels (2.30%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_7_010_89.gif\n",
      "\n",
      "Episode 8: 011_103.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 831 pixels (1.44%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_8_011_103.gif\n",
      "\n",
      "Episode 9: 012_69.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.84, Steps to Find: 20\n",
      "  Tumor Size: 1365 pixels (2.37%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_9_012_69.gif\n",
      "\n",
      "Episode 10: 013_86.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 1536 pixels (2.67%)\n",
      "  Action Distribution: [0.45 0.3  0.25]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_10_013_86.gif\n",
      "\n",
      "Episode 11: 014_46.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 54.26, Steps to Find: 6\n",
      "  Tumor Size: 2035 pixels (3.53%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_11_014_46.gif\n",
      "\n",
      "Episode 12: 015_71.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.84, Steps to Find: 20\n",
      "  Tumor Size: 2195 pixels (3.81%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_12_015_71.gif\n",
      "\n",
      "Episode 13: 016_95.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.84, Steps to Find: 2\n",
      "  Tumor Size: 2999 pixels (5.21%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_13_016_95.gif\n",
      "\n",
      "Episode 14: 017_68.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 79.76, Steps to Find: 5\n",
      "  Tumor Size: 2255 pixels (3.91%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_14_017_68.gif\n",
      "\n",
      "Episode 15: 018_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 6\n",
      "  Tumor Size: 1676 pixels (2.91%)\n",
      "  Action Distribution: [0.3  0.45 0.25]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_15_018_84.gif\n",
      "\n",
      "Episode 16: 019_52.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 3.34, Steps to Find: 20\n",
      "  Tumor Size: 1280 pixels (2.22%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_16_019_52.gif\n",
      "\n",
      "Episode 17: 021_96.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.76, Steps to Find: 2\n",
      "  Tumor Size: 867 pixels (1.51%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_17_021_96.gif\n",
      "\n",
      "Episode 18: 022_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 84.78, Steps to Find: 4\n",
      "  Tumor Size: 1566 pixels (2.72%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_18_022_89.gif\n",
      "\n",
      "Episode 19: 023_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 1119 pixels (1.94%)\n",
      "  Action Distribution: [0.4 0.4 0.2]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_19_023_98.gif\n",
      "\n",
      "Episode 20: 024_49.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 79.84, Steps to Find: 5\n",
      "  Tumor Size: 1338 pixels (2.32%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_20_024_49.gif\n",
      "\n",
      "Episode 21: 026_43.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 74.66, Steps to Find: 6\n",
      "  Tumor Size: 663 pixels (1.15%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_21_026_43.gif\n",
      "\n",
      "Episode 22: 028_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 799 pixels (1.39%)\n",
      "  Action Distribution: [0.45 0.2  0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_22_028_56.gif\n",
      "\n",
      "Episode 23: 030_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 79.76, Steps to Find: 5\n",
      "  Tumor Size: 1979 pixels (3.44%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_23_030_99.gif\n",
      "\n",
      "Episode 24: 030_115.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.84, Steps to Find: 3\n",
      "  Tumor Size: 611 pixels (1.06%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_24_030_115.gif\n",
      "\n",
      "Episode 25: 032_134.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 554 pixels (0.96%)\n",
      "  Action Distribution: [0.35 0.25 0.4 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_25_032_134.gif\n",
      "\n",
      "Episode 26: 033_86.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.98, Steps to Find: 2\n",
      "  Tumor Size: 2788 pixels (4.84%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_26_033_86.gif\n",
      "\n",
      "Episode 27: 034_113.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 69.64, Steps to Find: 3\n",
      "  Tumor Size: 2141 pixels (3.72%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_27_034_113.gif\n",
      "\n",
      "Episode 28: 035_40.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 59.52, Steps to Find: 2\n",
      "  Tumor Size: 837 pixels (1.45%)\n",
      "  Action Distribution: [0.65 0.2  0.15]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_28_035_40.gif\n",
      "\n",
      "Episode 29: 036_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.70, Steps to Find: 7\n",
      "  Tumor Size: 795 pixels (1.38%)\n",
      "  Action Distribution: [0.3 0.3 0.4]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_29_036_83.gif\n",
      "\n",
      "Episode 30: 038_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 1720 pixels (2.99%)\n",
      "  Action Distribution: [0.45 0.15 0.4 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_30_038_84.gif\n",
      "\n",
      "Episode 31: 040_46.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 18.56, Steps to Find: 2\n",
      "  Tumor Size: 3375 pixels (5.86%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_31_040_46.gif\n",
      "\n",
      "Episode 32: 043_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 1217 pixels (2.11%)\n",
      "  Action Distribution: [0.25 0.2  0.55]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_32_043_48.gif\n",
      "\n",
      "Episode 33: 045_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 54.34, Steps to Find: 6\n",
      "  Tumor Size: 473 pixels (0.82%)\n",
      "  Action Distribution: [0.8  0.15 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_33_045_57.gif\n",
      "\n",
      "Episode 34: 045_82.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 23.74, Steps to Find: 16\n",
      "  Tumor Size: 2259 pixels (3.92%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_34_045_82.gif\n",
      "\n",
      "Episode 35: 046_44.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 1147 pixels (1.99%)\n",
      "  Action Distribution: [0.1  0.35 0.55]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_35_046_44.gif\n",
      "\n",
      "Episode 36: 048_49.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 3.26, Steps to Find: 20\n",
      "  Tumor Size: 1308 pixels (2.27%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_36_048_49.gif\n",
      "\n",
      "Episode 37: 049_81.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.84, Steps to Find: 20\n",
      "  Tumor Size: 1649 pixels (2.86%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_37_049_81.gif\n",
      "\n",
      "Episode 38: 050_60.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 2312 pixels (4.01%)\n",
      "  Action Distribution: [0.2 0.4 0.4]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_38_050_60.gif\n",
      "\n",
      "Episode 39: 051_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 8.60, Steps to Find: 3\n",
      "  Tumor Size: 3155 pixels (5.48%)\n",
      "  Action Distribution: [0.35 0.35 0.3 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_39_051_94.gif\n",
      "\n",
      "Episode 40: 052_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 1228 pixels (2.13%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_40_052_98.gif\n",
      "\n",
      "Episode 41: 053_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 2\n",
      "  Tumor Size: 2915 pixels (5.06%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_41_053_85.gif\n",
      "\n",
      "Episode 42: 054_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 2098 pixels (3.64%)\n",
      "  Action Distribution: [0.35 0.35 0.3 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_42_054_61.gif\n",
      "\n",
      "Episode 43: 055_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 2578 pixels (4.48%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_43_055_61.gif\n",
      "\n",
      "Episode 44: 057_124.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 1433 pixels (2.49%)\n",
      "  Action Distribution: [0.05 0.45 0.5 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_44_057_124.gif\n",
      "\n",
      "Episode 45: 058_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.76, Steps to Find: 5\n",
      "  Tumor Size: 1231 pixels (2.14%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_45_058_84.gif\n",
      "\n",
      "Episode 46: 059_67.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 730 pixels (1.27%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_46_059_67.gif\n",
      "\n",
      "Episode 47: 066_116.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 674 pixels (1.17%)\n",
      "  Action Distribution: [0.3 0.4 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_47_066_116.gif\n",
      "\n",
      "Episode 48: 090_73.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 59.36, Steps to Find: 9\n",
      "  Tumor Size: 1051 pixels (1.82%)\n",
      "  Action Distribution: [0.8 0.1 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_48_090_73.gif\n",
      "\n",
      "Episode 49: 092_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 1658 pixels (2.88%)\n",
      "  Action Distribution: [0.4  0.25 0.35]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_49_092_94.gif\n",
      "\n",
      "Episode 50: 104_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 3423 pixels (5.94%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_50_104_74.gif\n",
      "\n",
      "Episode 51: 116_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 84.78, Steps to Find: 4\n",
      "  Tumor Size: 1855 pixels (3.22%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_51_116_58.gif\n",
      "\n",
      "Episode 52: 119_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 1148 pixels (1.99%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_52_119_53.gif\n",
      "\n",
      "Episode 53: 130_39.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 742 pixels (1.29%)\n",
      "  Action Distribution: [0.35 0.25 0.4 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_53_130_39.gif\n",
      "\n",
      "Episode 54: 147_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.88, Steps to Find: 3\n",
      "  Tumor Size: 2935 pixels (5.10%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_54_147_83.gif\n",
      "\n",
      "Episode 55: 154_87.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.98, Steps to Find: 2\n",
      "  Tumor Size: 1443 pixels (2.51%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_55_154_87.gif\n",
      "\n",
      "Episode 56: 155_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 1005 pixels (1.74%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_56_155_48.gif\n",
      "\n",
      "Episode 57: 160_82.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 2528 pixels (4.39%)\n",
      "  Action Distribution: [0.4 0.2 0.4]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_57_160_82.gif\n",
      "\n",
      "Episode 58: 163_101.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 3132 pixels (5.44%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_58_163_101.gif\n",
      "\n",
      "Episode 59: 171_69.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.76, Steps to Find: 4\n",
      "  Tumor Size: 1076 pixels (1.87%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_59_171_69.gif\n",
      "\n",
      "Episode 60: 176_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.98, Steps to Find: 2\n",
      "  Tumor Size: 2223 pixels (3.86%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_60_176_99.gif\n",
      "\n",
      "Episode 61: 177_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.84, Steps to Find: 20\n",
      "  Tumor Size: 823 pixels (1.43%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_61_177_57.gif\n",
      "\n",
      "Episode 62: 178_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 2286 pixels (3.97%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_62_178_85.gif\n",
      "\n",
      "Episode 63: 179_70.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.84, Steps to Find: 20\n",
      "  Tumor Size: 1958 pixels (3.40%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_63_179_70.gif\n",
      "\n",
      "Episode 64: 180_50.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 69.64, Steps to Find: 4\n",
      "  Tumor Size: 2855 pixels (4.96%)\n",
      "  Action Distribution: [0.8  0.05 0.15]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_64_180_50.gif\n",
      "\n",
      "Episode 65: 180_72.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 2771 pixels (4.81%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_65_180_72.gif\n",
      "\n",
      "Episode 66: 184_36.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 296 pixels (0.51%)\n",
      "  Action Distribution: [0.4  0.15 0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_66_184_36.gif\n",
      "\n",
      "Episode 67: 188_62.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 64.46, Steps to Find: 2\n",
      "  Tumor Size: 1754 pixels (3.05%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_67_188_62.gif\n",
      "\n",
      "Episode 68: 190_81.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 987 pixels (1.71%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_68_190_81.gif\n",
      "\n",
      "Episode 69: 200_45.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.88, Steps to Find: 3\n",
      "  Tumor Size: 1239 pixels (2.15%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_69_200_45.gif\n",
      "\n",
      "Episode 70: 204_52.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 893 pixels (1.55%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_70_204_52.gif\n",
      "\n",
      "Episode 71: 226_66.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 2037 pixels (3.54%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_71_226_66.gif\n",
      "\n",
      "Episode 72: 227_60.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 1494 pixels (2.59%)\n",
      "  Action Distribution: [0.2  0.25 0.55]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_72_227_60.gif\n",
      "\n",
      "Episode 73: 231_90.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.84, Steps to Find: 2\n",
      "  Tumor Size: 3297 pixels (5.72%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_73_231_90.gif\n",
      "\n",
      "Episode 74: 236_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 2498 pixels (4.34%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_74_236_58.gif\n",
      "\n",
      "Episode 75: 237_41.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 28.76, Steps to Find: 2\n",
      "  Tumor Size: 840 pixels (1.46%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_75_237_41.gif\n",
      "\n",
      "Episode 76: 240_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 2725 pixels (4.73%)\n",
      "  Action Distribution: [0.25 0.2  0.55]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_76_240_52.gif\n",
      "\n",
      "Episode 77: 245_35.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 1257 pixels (2.18%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_77_245_35.gif\n",
      "\n",
      "Episode 78: 250_45.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 1616 pixels (2.81%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_78_250_45.gif\n",
      "\n",
      "Episode 79: 255_56.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 84.86, Steps to Find: 4\n",
      "  Tumor Size: 3030 pixels (5.26%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_79_255_56.gif\n",
      "\n",
      "Episode 80: 260_62.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 1653 pixels (2.87%)\n",
      "  Action Distribution: [0.1 0.4 0.5]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_80_260_62.gif\n",
      "\n",
      "Episode 81: 266_105.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 1725 pixels (2.99%)\n",
      "  Action Distribution: [0.2  0.25 0.55]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_81_266_105.gif\n",
      "\n",
      "Episode 82: 274_90.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 8.52, Steps to Find: 1\n",
      "  Tumor Size: 4092 pixels (7.10%)\n",
      "  Action Distribution: [0.4 0.2 0.4]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_82_274_90.gif\n",
      "\n",
      "Episode 83: 276_102.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.84, Steps to Find: 2\n",
      "  Tumor Size: 1831 pixels (3.18%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_83_276_102.gif\n",
      "\n",
      "Episode 84: 280_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.84, Steps to Find: 20\n",
      "  Tumor Size: 905 pixels (1.57%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_84_280_96.gif\n",
      "\n",
      "Episode 85: 282_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 1994 pixels (3.46%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_85_282_53.gif\n",
      "\n",
      "Episode 86: 284_88.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.62, Steps to Find: 1\n",
      "  Tumor Size: 4461 pixels (7.74%)\n",
      "  Action Distribution: [0.2  0.25 0.55]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_86_284_88.gif\n",
      "\n",
      "Episode 87: 287_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.76, Steps to Find: 20\n",
      "  Tumor Size: 1807 pixels (3.14%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_87_287_97.gif\n",
      "\n",
      "Episode 88: 289_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.76, Steps to Find: 4\n",
      "  Tumor Size: 3435 pixels (5.96%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_88_289_74.gif\n",
      "\n",
      "Episode 89: 299_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 2607 pixels (4.53%)\n",
      "  Action Distribution: [0.2  0.35 0.45]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_89_299_97.gif\n",
      "\n",
      "Episode 90: 300_107.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.88, Steps to Find: 3\n",
      "  Tumor Size: 2216 pixels (3.85%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_90_300_107.gif\n",
      "\n",
      "Episode 91: 308_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.98, Steps to Find: 1\n",
      "  Tumor Size: 4910 pixels (8.52%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_91_308_88.gif\n",
      "\n",
      "Episode 92: 314_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.84, Steps to Find: 20\n",
      "  Tumor Size: 932 pixels (1.62%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_92_314_91.gif\n",
      "\n",
      "Episode 93: 326_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.84, Steps to Find: 20\n",
      "  Tumor Size: 1227 pixels (2.13%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_93_326_68.gif\n",
      "\n",
      "Episode 94: 333_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.70, Steps to Find: 15\n",
      "  Tumor Size: 3974 pixels (6.90%)\n",
      "  Action Distribution: [0.5 0.2 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_94_333_91.gif\n",
      "\n",
      "Episode 95: 350_77.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.84, Steps to Find: 20\n",
      "  Tumor Size: 1879 pixels (3.26%)\n",
      "  Action Distribution: [0.9  0.05 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_95_350_77.gif\n",
      "\n",
      "Episode 96: 356_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.70, Steps to Find: 7\n",
      "  Tumor Size: 532 pixels (0.92%)\n",
      "  Action Distribution: [0.1 0.6 0.3]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_96_356_97.gif\n",
      "\n",
      "Episode 97: 360_103.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.52, Steps to Find: 20\n",
      "  Tumor Size: 3331 pixels (5.78%)\n",
      "  Action Distribution: [0.15 0.25 0.6 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_97_360_103.gif\n",
      "\n",
      "Episode 98: 363_48.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 84.86, Steps to Find: 4\n",
      "  Tumor Size: 872 pixels (1.51%)\n",
      "  Action Distribution: [0.85 0.05 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_98_363_48.gif\n",
      "\n",
      "Episode 99: 365_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.98, Steps to Find: 2\n",
      "  Tumor Size: 3872 pixels (6.72%)\n",
      "  Action Distribution: [0.85 0.1  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.1, -0.02]_3actions/episode_99_365_83.gif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_results = testing(\n",
    "    agent=agent,\n",
    "    test_pairs=prepare(mode=\"test\"),\n",
    "    agent_type=\"ppo\",\n",
    "    num_episodes=100,\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    save_gifs=True,\n",
    "    gif_folder=f\"GIFs_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"\n",
    ")\n",
    "\n",
    "sucess[f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_3actions\"] = overall_results['success_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbb2cb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/martina/codi2/4year/tfg/ppo/wandb/run-20251114_002222-s1lxush2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/s1lxush2' target=\"_blank\">PPO_batch128_rewards[5.0, -0.2, -0.05]_5actions</a></strong> to <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/s1lxush2' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/s1lxush2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Global-Aware PPO training...\n",
      "Episode 0 | Avg Reward: 5.89 | Mean Reward (100): 5.89 | Actor Loss: -0.0219\n",
      "New best model saved!\n",
      "Episode 25 | Avg Reward: 14.90 | Mean Reward (100): 10.40 | Actor Loss: 0.0053\n",
      "New best model saved!\n",
      "Episode 50 | Avg Reward: 2.68 | Mean Reward (100): 7.82 | Actor Loss: 0.0027\n",
      "Episode 75 | Avg Reward: 6.56 | Mean Reward (100): 7.51 | Actor Loss: -0.0113\n",
      "Episode 100 | Avg Reward: 10.81 | Mean Reward (100): 8.74 | Actor Loss: 0.0024\n",
      "Episode 125 | Avg Reward: 9.48 | Mean Reward (100): 7.38 | Actor Loss: 0.0006\n",
      "Episode 150 | Avg Reward: 17.03 | Mean Reward (100): 10.97 | Actor Loss: 0.0018\n",
      "New best model saved!\n",
      "Episode 175 | Avg Reward: 13.26 | Mean Reward (100): 12.64 | Actor Loss: -0.0111\n",
      "New best model saved!\n",
      "Episode 200 | Avg Reward: 16.40 | Mean Reward (100): 14.04 | Actor Loss: -0.0131\n",
      "New best model saved!\n",
      "Episode 225 | Avg Reward: 8.00 | Mean Reward (100): 13.67 | Actor Loss: -0.0096\n",
      "Episode 250 | Avg Reward: 14.09 | Mean Reward (100): 12.93 | Actor Loss: -0.0125\n",
      "Episode 275 | Avg Reward: 3.55 | Mean Reward (100): 10.51 | Actor Loss: -0.0020\n",
      "Episode 300 | Avg Reward: 15.20 | Mean Reward (100): 10.21 | Actor Loss: -0.0008\n",
      "Episode 325 | Avg Reward: 11.59 | Mean Reward (100): 11.11 | Actor Loss: -0.0119\n",
      "Episode 350 | Avg Reward: 13.52 | Mean Reward (100): 10.96 | Actor Loss: 0.0012\n",
      "Episode 375 | Avg Reward: 19.01 | Mean Reward (100): 14.83 | Actor Loss: -0.0073\n",
      "New best model saved!\n",
      "Episode 400 | Avg Reward: 11.88 | Mean Reward (100): 14.00 | Actor Loss: -0.0191\n",
      "Episode 425 | Avg Reward: 15.46 | Mean Reward (100): 14.97 | Actor Loss: 0.0037\n",
      "New best model saved!\n",
      "Episode 450 | Avg Reward: 13.19 | Mean Reward (100): 14.88 | Actor Loss: -0.0108\n",
      "Episode 475 | Avg Reward: 14.34 | Mean Reward (100): 13.72 | Actor Loss: -0.0027\n",
      "Episode 500 | Avg Reward: 21.02 | Mean Reward (100): 16.00 | Actor Loss: -0.0088\n",
      "New best model saved!\n",
      "Episode 525 | Avg Reward: 30.79 | Mean Reward (100): 19.84 | Actor Loss: 0.0129\n",
      "New best model saved!\n",
      "Episode 550 | Avg Reward: 15.30 | Mean Reward (100): 20.36 | Actor Loss: -0.0016\n",
      "New best model saved!\n",
      "Episode 575 | Avg Reward: 17.69 | Mean Reward (100): 21.20 | Actor Loss: -0.0017\n",
      "New best model saved!\n",
      "Episode 600 | Avg Reward: 18.34 | Mean Reward (100): 20.53 | Actor Loss: -0.0115\n",
      "Episode 625 | Avg Reward: 16.48 | Mean Reward (100): 16.95 | Actor Loss: 0.0043\n",
      "Episode 650 | Avg Reward: 19.67 | Mean Reward (100): 18.05 | Actor Loss: 0.0140\n",
      "Episode 675 | Avg Reward: 20.18 | Mean Reward (100): 18.67 | Actor Loss: -0.0066\n",
      "Episode 700 | Avg Reward: 14.79 | Mean Reward (100): 17.78 | Actor Loss: -0.0081\n",
      "Episode 725 | Avg Reward: 17.57 | Mean Reward (100): 18.05 | Actor Loss: -0.0002\n",
      "Episode 750 | Avg Reward: 30.09 | Mean Reward (100): 20.66 | Actor Loss: -0.0176\n",
      "Episode 775 | Avg Reward: 24.12 | Mean Reward (100): 21.64 | Actor Loss: -0.0076\n",
      "New best model saved!\n",
      "Episode 800 | Avg Reward: 27.39 | Mean Reward (100): 24.79 | Actor Loss: 0.0072\n",
      "New best model saved!\n",
      "Episode 825 | Avg Reward: 33.22 | Mean Reward (100): 28.70 | Actor Loss: 0.0044\n",
      "New best model saved!\n",
      "Episode 850 | Avg Reward: 19.54 | Mean Reward (100): 26.07 | Actor Loss: -0.0077\n",
      "Episode 875 | Avg Reward: 24.12 | Mean Reward (100): 26.07 | Actor Loss: 0.0009\n",
      "Episode 900 | Avg Reward: 35.49 | Mean Reward (100): 28.09 | Actor Loss: 0.0139\n",
      "Episode 925 | Avg Reward: 18.14 | Mean Reward (100): 24.32 | Actor Loss: -0.0080\n",
      "Episode 950 | Avg Reward: 32.00 | Mean Reward (100): 27.44 | Actor Loss: 0.0118\n",
      "Episode 975 | Avg Reward: 20.16 | Mean Reward (100): 26.45 | Actor Loss: -0.0083\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▁▆▆▃▆▅▆▃▃▃▃▅▅▃▆▄▂▆▃▅▄█▅▅▃▆█▄▄▅▂▄▇▆▄▅█▄█▄</td></tr><tr><td>avg_episode_reward</td><td>▂▄▁▂▃▂▄▃▄▂▃▁▄▃▃▄▃▄▃▃▅▇▄▄▄▄▅▅▄▄▇▆▆█▅▆█▄▇▅</td></tr><tr><td>critic_loss</td><td>▁▃▁▂▂▂▂▂▃▂▂▁▃▂▂▂▂▃▂▂▄▅▄▃▃▃▄▄▃▄▆▆▆█▅▅█▄▇▄</td></tr><tr><td>entropy</td><td>██████████▇▇▇▇▇▆▇▇▆▆▅▅▅▅▅▅▄▄▄▄▃▃▂▁▂▂▁▂▂▃</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>mean_reward_100</td><td>▁▂▂▁▂▁▃▃▄▃▃▂▂▃▃▄▃▄▄▃▄▅▅▆▅▄▅▅▅▅▆▆▇█▇▇█▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>-0.00828</td></tr><tr><td>avg_episode_reward</td><td>20.164</td></tr><tr><td>critic_loss</td><td>75.03027</td></tr><tr><td>entropy</td><td>0.86347</td></tr><tr><td>episode</td><td>975</td></tr><tr><td>mean_reward_100</td><td>26.449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">PPO_batch128_rewards[5.0, -0.2, -0.05]_5actions</strong> at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/s1lxush2' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/s1lxush2</a><br> View project at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251114_002222-s1lxush2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -0.2, -0.05], \n",
    "    'action_space': gym.spaces.Discrete(5)\n",
    "}\n",
    "\n",
    "LR = 1e-4\n",
    "MAX_EPISODES = 1000\n",
    "NUM_STEPS = 512  # Start with smaller rollout for testing\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "env = GlobalAwareGlioblastoma(*train_pairs[0], **CURRENT_CONFIG)\n",
    "model = GlobalAwarePPOActorCritic(env, learning_rate=LR, device='cpu')\n",
    "agent = GlobalAwarePPOAgent(\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    model=model,\n",
    "    train_pairs=train_pairs,\n",
    "    env_class=GlobalAwareGlioblastoma,  # Use the new environment class\n",
    "    gamma=0.99,\n",
    "    clip_epsilon=0.2,\n",
    "    ppo_epochs=4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_5actions\"\n",
    ")\n",
    "\n",
    "\n",
    "wandb.init(project=\"TFG_Glioblastoma_PPO\", \n",
    "           name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_5actions\",\n",
    "           config={\n",
    "               \"learning_rate\": LR,\n",
    "               \"max_episodes\": MAX_EPISODES,\n",
    "               \"num_steps\": NUM_STEPS,\n",
    "               \"batch_size\": BATCH_SIZE,\n",
    "               \"configuration\": CURRENT_CONFIG\n",
    "           })\n",
    "\n",
    "# Start training\n",
    "agent.train(max_episodes=MAX_EPISODES, num_steps=NUM_STEPS)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad1da300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 100 pairs out of 100 listed in CSV.\n",
      "Saved GIF for episode 0 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_0_002_58.gif\n",
      "Saved GIF for episode 10 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_10_013_86.gif\n",
      "Saved GIF for episode 20 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_20_024_49.gif\n",
      "Saved GIF for episode 30 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_30_038_84.gif\n",
      "Saved GIF for episode 40 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_40_052_98.gif\n",
      "Saved GIF for episode 50 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_50_104_74.gif\n",
      "Saved GIF for episode 60 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_60_176_99.gif\n",
      "Saved GIF for episode 70 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_70_204_52.gif\n",
      "Saved GIF for episode 80 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_80_260_62.gif\n",
      "Saved GIF for episode 90 at GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_90_300_107.gif\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS (PPO Agent)\n",
      "============================================================\n",
      "Success Rate: 37.00%\n",
      "Average Episode Reward: 22.41\n",
      "Average Steps to Find Tumor: 10.00\n",
      "Average Tumor Rewards per Episode: 4.70\n",
      "Tumor Size Statistics:\n",
      "  Biggest Tumor: 4910 pixels (8.52%)\n",
      "  Smallest Tumor: 296 pixels (0.51%)\n",
      "  Average Tumor: 1873 pixels (3.25%)\n",
      "Overall Action Distribution: [0.0315 0.4755 0.091  0.3735 0.0285]\n",
      "  Successful Episodes: [0.02972973 0.49054054 0.08513514 0.36891892 0.02567568]\n",
      "  Unsuccessful Episodes: [0.03253968 0.46666667 0.09444444 0.37619048 0.03015873]\n",
      "\n",
      "Detailed Results for 100 episodes:\n",
      "--------------------------------------------------------------------------------\n",
      "Episode 0: 002_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 19.05, Steps to Find: 2\n",
      "  Tumor Size: 2049 pixels (3.56%)\n",
      "  Action Distribution: [0.1  0.45 0.1  0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_0_002_58.gif\n",
      "\n",
      "Episode 1: 004_87.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.60, Steps to Find: 20\n",
      "  Tumor Size: 2727 pixels (4.73%)\n",
      "  Action Distribution: [0.   0.6  0.05 0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_1_004_87.gif\n",
      "\n",
      "Episode 2: 005_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.00, Steps to Find: 20\n",
      "  Tumor Size: 768 pixels (1.33%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_2_005_94.gif\n",
      "\n",
      "Episode 3: 006_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 18.90, Steps to Find: 9\n",
      "  Tumor Size: 2834 pixels (4.92%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_3_006_83.gif\n",
      "\n",
      "Episode 4: 007_54.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 39.10, Steps to Find: 4\n",
      "  Tumor Size: 1299 pixels (2.26%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_4_007_54.gif\n",
      "\n",
      "Episode 5: 008_41.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 39.25, Steps to Find: 3\n",
      "  Tumor Size: 1243 pixels (2.16%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_5_008_41.gif\n",
      "\n",
      "Episode 6: 009_65.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 7.90, Steps to Find: 2\n",
      "  Tumor Size: 4172 pixels (7.24%)\n",
      "  Action Distribution: [0.05 0.65 0.1  0.2  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_6_009_65.gif\n",
      "\n",
      "Episode 7: 010_89.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.00, Steps to Find: 2\n",
      "  Tumor Size: 1327 pixels (2.30%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_7_010_89.gif\n",
      "\n",
      "Episode 8: 011_103.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 9.10, Steps to Find: 16\n",
      "  Tumor Size: 831 pixels (1.44%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_8_011_103.gif\n",
      "\n",
      "Episode 9: 012_69.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.30, Steps to Find: 20\n",
      "  Tumor Size: 1365 pixels (2.37%)\n",
      "  Action Distribution: [0.1  0.45 0.05 0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_9_012_69.gif\n",
      "\n",
      "Episode 10: 013_86.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 8.95, Steps to Find: 8\n",
      "  Tumor Size: 1536 pixels (2.67%)\n",
      "  Action Distribution: [0.   0.45 0.05 0.45 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_10_013_86.gif\n",
      "\n",
      "Episode 11: 014_46.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 74.45, Steps to Find: 1\n",
      "  Tumor Size: 2035 pixels (3.53%)\n",
      "  Action Distribution: [0.1  0.55 0.05 0.3  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_11_014_46.gif\n",
      "\n",
      "Episode 12: 015_71.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.30, Steps to Find: 20\n",
      "  Tumor Size: 2195 pixels (3.81%)\n",
      "  Action Distribution: [0.   0.45 0.05 0.5  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_12_015_71.gif\n",
      "\n",
      "Episode 13: 016_95.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 3.90, Steps to Find: 3\n",
      "  Tumor Size: 2999 pixels (5.21%)\n",
      "  Action Distribution: [0.  0.5 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_13_016_95.gif\n",
      "\n",
      "Episode 14: 017_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.00, Steps to Find: 20\n",
      "  Tumor Size: 2255 pixels (3.91%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_14_017_68.gif\n",
      "\n",
      "Episode 15: 018_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 3.15, Steps to Find: 3\n",
      "  Tumor Size: 1676 pixels (2.91%)\n",
      "  Action Distribution: [0.  0.4 0.3 0.2 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_15_018_84.gif\n",
      "\n",
      "Episode 16: 019_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.30, Steps to Find: 20\n",
      "  Tumor Size: 1280 pixels (2.22%)\n",
      "  Action Distribution: [0.05 0.4  0.1  0.35 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_16_019_52.gif\n",
      "\n",
      "Episode 17: 021_96.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 7.60, Steps to Find: 17\n",
      "  Tumor Size: 867 pixels (1.51%)\n",
      "  Action Distribution: [0.   0.7  0.05 0.2  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_17_021_96.gif\n",
      "\n",
      "Episode 18: 022_89.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 7.75, Steps to Find: 18\n",
      "  Tumor Size: 1566 pixels (2.72%)\n",
      "  Action Distribution: [0.05 0.65 0.05 0.25 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_18_022_89.gif\n",
      "\n",
      "Episode 19: 023_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 18.90, Steps to Find: 9\n",
      "  Tumor Size: 1119 pixels (1.94%)\n",
      "  Action Distribution: [0.  0.4 0.1 0.4 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_19_023_98.gif\n",
      "\n",
      "Episode 20: 024_49.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 28.70, Steps to Find: 9\n",
      "  Tumor Size: 1338 pixels (2.32%)\n",
      "  Action Distribution: [0.1  0.45 0.1  0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_20_024_49.gif\n",
      "\n",
      "Episode 21: 026_43.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 39.40, Steps to Find: 2\n",
      "  Tumor Size: 663 pixels (1.15%)\n",
      "  Action Distribution: [0.  0.5 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_21_026_43.gif\n",
      "\n",
      "Episode 22: 028_56.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 34.35, Steps to Find: 10\n",
      "  Tumor Size: 799 pixels (1.39%)\n",
      "  Action Distribution: [0.  0.5 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_22_028_56.gif\n",
      "\n",
      "Episode 23: 030_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 54.55, Steps to Find: 5\n",
      "  Tumor Size: 1979 pixels (3.44%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_23_030_99.gif\n",
      "\n",
      "Episode 24: 030_115.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 39.40, Steps to Find: 2\n",
      "  Tumor Size: 611 pixels (1.06%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_24_030_115.gif\n",
      "\n",
      "Episode 25: 032_134.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.60, Steps to Find: 20\n",
      "  Tumor Size: 554 pixels (0.96%)\n",
      "  Action Distribution: [0.   0.45 0.15 0.3  0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_25_032_134.gif\n",
      "\n",
      "Episode 26: 033_86.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 54.55, Steps to Find: 3\n",
      "  Tumor Size: 2788 pixels (4.84%)\n",
      "  Action Distribution: [0.05 0.4  0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_26_033_86.gif\n",
      "\n",
      "Episode 27: 034_113.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.00, Steps to Find: 20\n",
      "  Tumor Size: 2141 pixels (3.72%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_27_034_113.gif\n",
      "\n",
      "Episode 28: 035_40.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 44.00, Steps to Find: 11\n",
      "  Tumor Size: 837 pixels (1.45%)\n",
      "  Action Distribution: [0.15 0.35 0.1  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_28_035_40.gif\n",
      "\n",
      "Episode 29: 036_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.30, Steps to Find: 20\n",
      "  Tumor Size: 795 pixels (1.38%)\n",
      "  Action Distribution: [0.1  0.5  0.05 0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_29_036_83.gif\n",
      "\n",
      "Episode 30: 038_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 14.15, Steps to Find: 3\n",
      "  Tumor Size: 1720 pixels (2.99%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_30_038_84.gif\n",
      "\n",
      "Episode 31: 040_46.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 3375 pixels (5.86%)\n",
      "  Action Distribution: [0.   0.45 0.05 0.5  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_31_040_46.gif\n",
      "\n",
      "Episode 32: 043_48.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 38.35, Steps to Find: 10\n",
      "  Tumor Size: 1217 pixels (2.11%)\n",
      "  Action Distribution: [0.05 0.65 0.05 0.25 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_32_043_48.gif\n",
      "\n",
      "Episode 33: 045_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 39.40, Steps to Find: 3\n",
      "  Tumor Size: 473 pixels (0.82%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_33_045_57.gif\n",
      "\n",
      "Episode 34: 045_82.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 24.10, Steps to Find: 4\n",
      "  Tumor Size: 2259 pixels (3.92%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.35 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_34_045_82.gif\n",
      "\n",
      "Episode 35: 046_44.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 3.60, Steps to Find: 14\n",
      "  Tumor Size: 1147 pixels (1.99%)\n",
      "  Action Distribution: [0.1  0.4  0.1  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_35_046_44.gif\n",
      "\n",
      "Episode 36: 048_49.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 8.80, Steps to Find: 17\n",
      "  Tumor Size: 1308 pixels (2.27%)\n",
      "  Action Distribution: [0.  0.5 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_36_048_49.gif\n",
      "\n",
      "Episode 37: 049_81.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 3.90, Steps to Find: 4\n",
      "  Tumor Size: 1649 pixels (2.86%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_37_049_81.gif\n",
      "\n",
      "Episode 38: 050_60.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 18.75, Steps to Find: 2\n",
      "  Tumor Size: 2312 pixels (4.01%)\n",
      "  Action Distribution: [0.1 0.4 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_38_050_60.gif\n",
      "\n",
      "Episode 39: 051_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.85, Steps to Find: 3\n",
      "  Tumor Size: 3155 pixels (5.48%)\n",
      "  Action Distribution: [0.1 0.4 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_39_051_94.gif\n",
      "\n",
      "Episode 40: 052_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 29.30, Steps to Find: 7\n",
      "  Tumor Size: 1228 pixels (2.13%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_40_052_98.gif\n",
      "\n",
      "Episode 41: 053_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 24.10, Steps to Find: 2\n",
      "  Tumor Size: 2915 pixels (5.06%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.35 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_41_053_85.gif\n",
      "\n",
      "Episode 42: 054_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.25, Steps to Find: 2\n",
      "  Tumor Size: 2098 pixels (3.64%)\n",
      "  Action Distribution: [0.1  0.55 0.1  0.25 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_42_054_61.gif\n",
      "\n",
      "Episode 43: 055_61.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 24.10, Steps to Find: 4\n",
      "  Tumor Size: 2578 pixels (4.48%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_43_055_61.gif\n",
      "\n",
      "Episode 44: 057_124.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 23.50, Steps to Find: 5\n",
      "  Tumor Size: 1433 pixels (2.49%)\n",
      "  Action Distribution: [0.   0.55 0.1  0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_44_057_124.gif\n",
      "\n",
      "Episode 45: 058_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.30, Steps to Find: 20\n",
      "  Tumor Size: 1231 pixels (2.14%)\n",
      "  Action Distribution: [0.05 0.4  0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_45_058_84.gif\n",
      "\n",
      "Episode 46: 059_67.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.45, Steps to Find: 20\n",
      "  Tumor Size: 730 pixels (1.27%)\n",
      "  Action Distribution: [0.  0.3 0.2 0.3 0.2]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_46_059_67.gif\n",
      "\n",
      "Episode 47: 066_116.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 2.70, Steps to Find: 20\n",
      "  Tumor Size: 674 pixels (1.17%)\n",
      "  Action Distribution: [0.05 0.65 0.1  0.15 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_47_066_116.gif\n",
      "\n",
      "Episode 48: 090_73.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 13.10, Steps to Find: 12\n",
      "  Tumor Size: 1051 pixels (1.82%)\n",
      "  Action Distribution: [0.05 0.65 0.05 0.25 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_48_090_73.gif\n",
      "\n",
      "Episode 49: 092_94.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 49.50, Steps to Find: 7\n",
      "  Tumor Size: 1658 pixels (2.88%)\n",
      "  Action Distribution: [0.  0.5 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_49_092_94.gif\n",
      "\n",
      "Episode 50: 104_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 84.85, Steps to Find: 2\n",
      "  Tumor Size: 3423 pixels (5.94%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_50_104_74.gif\n",
      "\n",
      "Episode 51: 116_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.90, Steps to Find: 2\n",
      "  Tumor Size: 1855 pixels (3.22%)\n",
      "  Action Distribution: [0.05 0.5  0.05 0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_51_116_58.gif\n",
      "\n",
      "Episode 52: 119_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.00, Steps to Find: 20\n",
      "  Tumor Size: 1148 pixels (1.99%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_52_119_53.gif\n",
      "\n",
      "Episode 53: 130_39.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.10, Steps to Find: 20\n",
      "  Tumor Size: 742 pixels (1.29%)\n",
      "  Action Distribution: [0.05 0.5  0.45 0.   0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_53_130_39.gif\n",
      "\n",
      "Episode 54: 147_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 29.00, Steps to Find: 3\n",
      "  Tumor Size: 2935 pixels (5.10%)\n",
      "  Action Distribution: [0.05 0.5  0.15 0.3  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_54_147_83.gif\n",
      "\n",
      "Episode 55: 154_87.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 29.15, Steps to Find: 8\n",
      "  Tumor Size: 1443 pixels (2.51%)\n",
      "  Action Distribution: [0.05 0.4  0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_55_154_87.gif\n",
      "\n",
      "Episode 56: 155_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.15, Steps to Find: 20\n",
      "  Tumor Size: 1005 pixels (1.74%)\n",
      "  Action Distribution: [0.05 0.5  0.05 0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_56_155_48.gif\n",
      "\n",
      "Episode 57: 160_82.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 8.35, Steps to Find: 18\n",
      "  Tumor Size: 2528 pixels (4.39%)\n",
      "  Action Distribution: [0.1  0.45 0.05 0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_57_160_82.gif\n",
      "\n",
      "Episode 58: 163_101.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 29.00, Steps to Find: 13\n",
      "  Tumor Size: 3132 pixels (5.44%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_58_163_101.gif\n",
      "\n",
      "Episode 59: 171_69.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 34.35, Steps to Find: 5\n",
      "  Tumor Size: 1076 pixels (1.87%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_59_171_69.gif\n",
      "\n",
      "Episode 60: 176_99.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 23.50, Steps to Find: 11\n",
      "  Tumor Size: 2223 pixels (3.86%)\n",
      "  Action Distribution: [0.05 0.55 0.05 0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_60_176_99.gif\n",
      "\n",
      "Episode 61: 177_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 3.90, Steps to Find: 18\n",
      "  Tumor Size: 823 pixels (1.43%)\n",
      "  Action Distribution: [0.   0.4  0.1  0.45 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_61_177_57.gif\n",
      "\n",
      "Episode 62: 178_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 3.75, Steps to Find: 4\n",
      "  Tumor Size: 2286 pixels (3.97%)\n",
      "  Action Distribution: [0.1  0.4  0.05 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_62_178_85.gif\n",
      "\n",
      "Episode 63: 179_70.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.15, Steps to Find: 20\n",
      "  Tumor Size: 1958 pixels (3.40%)\n",
      "  Action Distribution: [0.   0.45 0.05 0.4  0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_63_179_70.gif\n",
      "\n",
      "Episode 64: 180_50.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.95, Steps to Find: 2\n",
      "  Tumor Size: 2855 pixels (4.96%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_64_180_50.gif\n",
      "\n",
      "Episode 65: 180_72.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 59.45, Steps to Find: 3\n",
      "  Tumor Size: 2771 pixels (4.81%)\n",
      "  Action Distribution: [0.   0.45 0.05 0.5  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_65_180_72.gif\n",
      "\n",
      "Episode 66: 184_36.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 18.45, Steps to Find: 7\n",
      "  Tumor Size: 296 pixels (0.51%)\n",
      "  Action Distribution: [0.05 0.5  0.25 0.2  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_66_184_36.gif\n",
      "\n",
      "Episode 67: 188_62.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 8.80, Steps to Find: 6\n",
      "  Tumor Size: 1754 pixels (3.05%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_67_188_62.gif\n",
      "\n",
      "Episode 68: 190_81.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.45, Steps to Find: 20\n",
      "  Tumor Size: 987 pixels (1.71%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.3  0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_68_190_81.gif\n",
      "\n",
      "Episode 69: 200_45.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 69.70, Steps to Find: 5\n",
      "  Tumor Size: 1239 pixels (2.15%)\n",
      "  Action Distribution: [0.05 0.5  0.05 0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_69_200_45.gif\n",
      "\n",
      "Episode 70: 204_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.30, Steps to Find: 20\n",
      "  Tumor Size: 893 pixels (1.55%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_70_204_52.gif\n",
      "\n",
      "Episode 71: 226_66.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 18.60, Steps to Find: 8\n",
      "  Tumor Size: 2037 pixels (3.54%)\n",
      "  Action Distribution: [0.   0.4  0.25 0.25 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_71_226_66.gif\n",
      "\n",
      "Episode 72: 227_60.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.15, Steps to Find: 4\n",
      "  Tumor Size: 1494 pixels (2.59%)\n",
      "  Action Distribution: [0.05 0.5  0.05 0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_72_227_60.gif\n",
      "\n",
      "Episode 73: 231_90.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 44.45, Steps to Find: 2\n",
      "  Tumor Size: 3297 pixels (5.72%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_73_231_90.gif\n",
      "\n",
      "Episode 74: 236_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 33.75, Steps to Find: 9\n",
      "  Tumor Size: 2498 pixels (4.34%)\n",
      "  Action Distribution: [0.05 0.5  0.05 0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_74_236_58.gif\n",
      "\n",
      "Episode 75: 237_41.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 29.00, Steps to Find: 7\n",
      "  Tumor Size: 840 pixels (1.46%)\n",
      "  Action Distribution: [0.   0.55 0.1  0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_75_237_41.gif\n",
      "\n",
      "Episode 76: 240_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.30, Steps to Find: 20\n",
      "  Tumor Size: 2725 pixels (4.73%)\n",
      "  Action Distribution: [0.05 0.45 0.05 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_76_240_52.gif\n",
      "\n",
      "Episode 77: 245_35.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 23.95, Steps to Find: 16\n",
      "  Tumor Size: 1257 pixels (2.18%)\n",
      "  Action Distribution: [0.05 0.5  0.1  0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_77_245_35.gif\n",
      "\n",
      "Episode 78: 250_45.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.15, Steps to Find: 20\n",
      "  Tumor Size: 1616 pixels (2.81%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_78_250_45.gif\n",
      "\n",
      "Episode 79: 255_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.00, Steps to Find: 20\n",
      "  Tumor Size: 3030 pixels (5.26%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_79_255_56.gif\n",
      "\n",
      "Episode 80: 260_62.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 38.95, Steps to Find: 2\n",
      "  Tumor Size: 1653 pixels (2.87%)\n",
      "  Action Distribution: [0.1  0.35 0.2  0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_80_260_62.gif\n",
      "\n",
      "Episode 81: 266_105.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.15, Steps to Find: 20\n",
      "  Tumor Size: 1725 pixels (2.99%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_81_266_105.gif\n",
      "\n",
      "Episode 82: 274_90.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 54.40, Steps to Find: 10\n",
      "  Tumor Size: 4092 pixels (7.10%)\n",
      "  Action Distribution: [0.   0.4  0.05 0.5  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_82_274_90.gif\n",
      "\n",
      "Episode 83: 276_102.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 8.65, Steps to Find: 10\n",
      "  Tumor Size: 1831 pixels (3.18%)\n",
      "  Action Distribution: [0.   0.4  0.15 0.35 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_83_276_102.gif\n",
      "\n",
      "Episode 84: 280_96.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.30, Steps to Find: 20\n",
      "  Tumor Size: 905 pixels (1.57%)\n",
      "  Action Distribution: [0.1  0.45 0.05 0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_84_280_96.gif\n",
      "\n",
      "Episode 85: 282_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 3.45, Steps to Find: 11\n",
      "  Tumor Size: 1994 pixels (3.46%)\n",
      "  Action Distribution: [0.05 0.5  0.1  0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_85_282_53.gif\n",
      "\n",
      "Episode 86: 284_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 69.40, Steps to Find: 7\n",
      "  Tumor Size: 4461 pixels (7.74%)\n",
      "  Action Distribution: [0.1  0.45 0.1  0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_86_284_88.gif\n",
      "\n",
      "Episode 87: 287_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 14.15, Steps to Find: 2\n",
      "  Tumor Size: 1807 pixels (3.14%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_87_287_97.gif\n",
      "\n",
      "Episode 88: 289_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 79.65, Steps to Find: 4\n",
      "  Tumor Size: 3435 pixels (5.96%)\n",
      "  Action Distribution: [0.05 0.45 0.05 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_88_289_74.gif\n",
      "\n",
      "Episode 89: 299_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 4.05, Steps to Find: 19\n",
      "  Tumor Size: 2607 pixels (4.53%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_89_299_97.gif\n",
      "\n",
      "Episode 90: 300_107.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 49.50, Steps to Find: 2\n",
      "  Tumor Size: 2216 pixels (3.85%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_90_300_107.gif\n",
      "\n",
      "Episode 91: 308_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 89.90, Steps to Find: 1\n",
      "  Tumor Size: 4910 pixels (8.52%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_91_308_88.gif\n",
      "\n",
      "Episode 92: 314_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 13.85, Steps to Find: 9\n",
      "  Tumor Size: 932 pixels (1.62%)\n",
      "  Action Distribution: [0.   0.45 0.25 0.3  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_92_314_91.gif\n",
      "\n",
      "Episode 93: 326_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 8.50, Steps to Find: 7\n",
      "  Tumor Size: 1227 pixels (2.13%)\n",
      "  Action Distribution: [0.1  0.4  0.05 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_93_326_68.gif\n",
      "\n",
      "Episode 94: 333_91.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 39.40, Steps to Find: 11\n",
      "  Tumor Size: 3974 pixels (6.90%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_94_333_91.gif\n",
      "\n",
      "Episode 95: 350_77.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 8.95, Steps to Find: 8\n",
      "  Tumor Size: 1879 pixels (3.26%)\n",
      "  Action Distribution: [0.   0.45 0.05 0.45 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_95_350_77.gif\n",
      "\n",
      "Episode 96: 356_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.60, Steps to Find: 20\n",
      "  Tumor Size: 532 pixels (0.92%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_96_356_97.gif\n",
      "\n",
      "Episode 97: 360_103.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 59.45, Steps to Find: 2\n",
      "  Tumor Size: 3331 pixels (5.78%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_97_360_103.gif\n",
      "\n",
      "Episode 98: 363_48.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 3.75, Steps to Find: 20\n",
      "  Tumor Size: 872 pixels (1.51%)\n",
      "  Action Distribution: [0.   0.5  0.1  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_98_363_48.gif\n",
      "\n",
      "Episode 99: 365_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.15, Steps to Find: 2\n",
      "  Tumor Size: 3872 pixels (6.72%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -0.2, -0.05]_5actions/episode_99_365_83.gif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_results = testing(\n",
    "    agent=agent,\n",
    "    test_pairs=prepare(mode=\"test\"),\n",
    "    agent_type=\"ppo\",\n",
    "    num_episodes=100,\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    save_gifs=True,\n",
    "    gif_folder=f\"GIFs_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_5actions\"\n",
    ")\n",
    "\n",
    "sucess[f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_5actions\"] = overall_results['success_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c27e7833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO_batch64_rewards[5.0, -1.0, -0.2]_3actions: Success Rate = 43.00%\n",
      "PPO_batch32_rewards[5.0, -1.0, -0.2]_3actions: Success Rate = 46.00%\n",
      "PPO_batch128_rewards[5.0, -1.0, -0.2]_3actions: Success Rate = 54.00%\n",
      "PPO_batch128_rewards[5.0, -0.5, -0.2]_3actions: Success Rate = 28.00%\n",
      "PPO_batch128_rewards[5.0, -0.2, -0.05]_3actions: Success Rate = 44.00%\n",
      "PPO_batch128_rewards[5.0, -0.1, -0.02]_3actions: Success Rate = 37.00%\n",
      "PPO_batch128_rewards[5.0, -0.2, -0.05]_5actions: Success Rate = 37.00%\n"
     ]
    }
   ],
   "source": [
    "for item in sucess:\n",
    "    print(f\"{item}: Success Rate = {sucess[item]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37649936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/martina/codi2/4year/tfg/ppo/wandb/run-20251114_003147-an50jwkc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/an50jwkc' target=\"_blank\">PPO_batch128_rewards[5.0, -1.0, -0.2]_5actions</a></strong> to <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/an50jwkc' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/an50jwkc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Global-Aware PPO training...\n",
      "Episode 0 | Avg Reward: -1.68 | Mean Reward (100): -1.68 | Actor Loss: -0.0093\n",
      "New best model saved!\n",
      "Episode 25 | Avg Reward: 7.71 | Mean Reward (100): 3.02 | Actor Loss: -0.0044\n",
      "New best model saved!\n",
      "Episode 50 | Avg Reward: 6.35 | Mean Reward (100): 4.13 | Actor Loss: -0.0074\n",
      "New best model saved!\n",
      "Episode 75 | Avg Reward: 5.04 | Mean Reward (100): 4.36 | Actor Loss: 0.0045\n",
      "New best model saved!\n",
      "Episode 100 | Avg Reward: 4.32 | Mean Reward (100): 5.86 | Actor Loss: -0.0116\n",
      "New best model saved!\n",
      "Episode 125 | Avg Reward: 12.72 | Mean Reward (100): 7.11 | Actor Loss: 0.0331\n",
      "New best model saved!\n",
      "Episode 150 | Avg Reward: 4.00 | Mean Reward (100): 6.52 | Actor Loss: -0.0013\n",
      "Episode 175 | Avg Reward: 6.72 | Mean Reward (100): 6.94 | Actor Loss: -0.0059\n",
      "Episode 200 | Avg Reward: 9.90 | Mean Reward (100): 8.34 | Actor Loss: 0.0023\n",
      "New best model saved!\n",
      "Episode 225 | Avg Reward: 11.55 | Mean Reward (100): 8.04 | Actor Loss: -0.0128\n",
      "Episode 250 | Avg Reward: 3.46 | Mean Reward (100): 7.91 | Actor Loss: -0.0131\n",
      "Episode 275 | Avg Reward: 8.00 | Mean Reward (100): 8.23 | Actor Loss: -0.0035\n",
      "Episode 300 | Avg Reward: 4.40 | Mean Reward (100): 6.85 | Actor Loss: -0.0050\n",
      "Episode 325 | Avg Reward: 8.08 | Mean Reward (100): 5.98 | Actor Loss: 0.0034\n",
      "Episode 350 | Avg Reward: 8.74 | Mean Reward (100): 7.30 | Actor Loss: -0.0183\n",
      "Episode 375 | Avg Reward: 11.94 | Mean Reward (100): 8.29 | Actor Loss: -0.0071\n",
      "Episode 400 | Avg Reward: 9.06 | Mean Reward (100): 9.45 | Actor Loss: -0.0151\n",
      "New best model saved!\n",
      "Episode 425 | Avg Reward: 1.89 | Mean Reward (100): 7.90 | Actor Loss: -0.0065\n",
      "Episode 450 | Avg Reward: 16.22 | Mean Reward (100): 9.78 | Actor Loss: 0.0406\n",
      "New best model saved!\n",
      "Episode 475 | Avg Reward: 2.45 | Mean Reward (100): 7.40 | Actor Loss: -0.0103\n",
      "Episode 500 | Avg Reward: 13.07 | Mean Reward (100): 8.41 | Actor Loss: -0.0068\n",
      "Episode 525 | Avg Reward: 13.74 | Mean Reward (100): 11.37 | Actor Loss: -0.0056\n",
      "New best model saved!\n",
      "Episode 550 | Avg Reward: 15.04 | Mean Reward (100): 11.08 | Actor Loss: 0.0013\n",
      "Episode 575 | Avg Reward: 15.28 | Mean Reward (100): 14.28 | Actor Loss: -0.0067\n",
      "New best model saved!\n",
      "Episode 600 | Avg Reward: 10.14 | Mean Reward (100): 13.55 | Actor Loss: -0.0111\n",
      "Episode 625 | Avg Reward: 12.62 | Mean Reward (100): 13.27 | Actor Loss: -0.0077\n",
      "Episode 650 | Avg Reward: 15.28 | Mean Reward (100): 13.33 | Actor Loss: 0.0014\n",
      "Episode 675 | Avg Reward: 13.57 | Mean Reward (100): 12.90 | Actor Loss: 0.0134\n",
      "Episode 700 | Avg Reward: 13.89 | Mean Reward (100): 13.84 | Actor Loss: -0.0115\n",
      "Episode 725 | Avg Reward: 16.53 | Mean Reward (100): 14.82 | Actor Loss: -0.0095\n",
      "New best model saved!\n",
      "Episode 750 | Avg Reward: 11.81 | Mean Reward (100): 13.95 | Actor Loss: -0.0044\n",
      "Episode 775 | Avg Reward: 19.82 | Mean Reward (100): 15.51 | Actor Loss: 0.0013\n",
      "New best model saved!\n",
      "Episode 800 | Avg Reward: 26.27 | Mean Reward (100): 18.61 | Actor Loss: -0.0022\n",
      "New best model saved!\n",
      "Episode 825 | Avg Reward: 22.18 | Mean Reward (100): 20.02 | Actor Loss: -0.0054\n",
      "New best model saved!\n",
      "Episode 850 | Avg Reward: 34.77 | Mean Reward (100): 25.76 | Actor Loss: 0.0097\n",
      "New best model saved!\n",
      "Episode 875 | Avg Reward: 7.62 | Mean Reward (100): 22.71 | Actor Loss: 0.0184\n",
      "Episode 900 | Avg Reward: 9.66 | Mean Reward (100): 18.56 | Actor Loss: 0.0180\n",
      "Episode 925 | Avg Reward: 24.61 | Mean Reward (100): 19.16 | Actor Loss: 0.0152\n",
      "Episode 950 | Avg Reward: 15.30 | Mean Reward (100): 14.30 | Actor Loss: -0.0018\n",
      "Episode 975 | Avg Reward: 24.50 | Mean Reward (100): 18.52 | Actor Loss: -0.0014\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▂▃▂▄▂▇▃▂▃▂▂▃▃▄▁▂▁▂█▂▂▃▃▂▂▂▃▅▂▂▃▃▃▃▄▅▅▅▃▃</td></tr><tr><td>avg_episode_reward</td><td>▁▃▃▂▂▄▂▃▃▄▂▃▂▃▃▄▃▂▄▂▄▄▄▄▃▄▄▄▄▄▄▅▆▆█▃▃▆▄▆</td></tr><tr><td>critic_loss</td><td>▁▃▃▂▂▃▂▂▂▃▂▂▁▃▃▃▃▁▄▂▃▃▄▄▃▃▄▄▃▅▅▆▆▅█▄▃▆▅▇</td></tr><tr><td>entropy</td><td>█████▇▇▇▇▇▇▇▇▆▆▆▆▇▅▆▆▅▅▆▆▆▆▆▆▅▅▄▃▃▁▂▅▃▁▁</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>mean_reward_100</td><td>▁▂▂▃▃▃▃▃▄▃▃▄▃▃▃▄▄▃▄▃▄▄▄▅▅▅▅▅▅▅▅▅▆▇█▇▆▆▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>-0.00138</td></tr><tr><td>avg_episode_reward</td><td>24.496</td></tr><tr><td>critic_loss</td><td>108.83502</td></tr><tr><td>entropy</td><td>0.91926</td></tr><tr><td>episode</td><td>975</td></tr><tr><td>mean_reward_100</td><td>18.516</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">PPO_batch128_rewards[5.0, -1.0, -0.2]_5actions</strong> at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/an50jwkc' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO/runs/an50jwkc</a><br> View project at: <a href='https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO' target=\"_blank\">https://wandb.ai/martinacarrettab/TFG_Glioblastoma_PPO</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251114_003147-an50jwkc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -1.0, -0.2], \n",
    "    'action_space': gym.spaces.Discrete(5)\n",
    "}\n",
    "\n",
    "LR = 1e-4\n",
    "MAX_EPISODES = 1000\n",
    "NUM_STEPS = 512  # Start with smaller rollout for testing\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "env = GlobalAwareGlioblastoma(*train_pairs[0], **CURRENT_CONFIG)\n",
    "model = GlobalAwarePPOActorCritic(env, learning_rate=LR, device='cpu')\n",
    "agent = GlobalAwarePPOAgent(\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    model=model,\n",
    "    train_pairs=train_pairs,\n",
    "    env_class=GlobalAwareGlioblastoma,  # Use the new environment class\n",
    "    gamma=0.99,\n",
    "    clip_epsilon=0.2,\n",
    "    ppo_epochs=4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_5actions\"\n",
    ")\n",
    "\n",
    "\n",
    "wandb.init(project=\"TFG_Glioblastoma_PPO\", \n",
    "           name=f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_5actions\",\n",
    "           config={\n",
    "               \"learning_rate\": LR,\n",
    "               \"max_episodes\": MAX_EPISODES,\n",
    "               \"num_steps\": NUM_STEPS,\n",
    "               \"batch_size\": BATCH_SIZE,\n",
    "               \"configuration\": CURRENT_CONFIG\n",
    "           })\n",
    "\n",
    "# Start training\n",
    "agent.train(max_episodes=MAX_EPISODES, num_steps=NUM_STEPS)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf706b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 100 pairs out of 100 listed in CSV.\n",
      "Saved GIF for episode 0 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_0_002_58.gif\n",
      "Saved GIF for episode 10 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_10_013_86.gif\n",
      "Saved GIF for episode 20 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_20_024_49.gif\n",
      "Saved GIF for episode 30 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_30_038_84.gif\n",
      "Saved GIF for episode 40 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_40_052_98.gif\n",
      "Saved GIF for episode 50 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_50_104_74.gif\n",
      "Saved GIF for episode 60 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_60_176_99.gif\n",
      "Saved GIF for episode 70 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_70_204_52.gif\n",
      "Saved GIF for episode 80 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_80_260_62.gif\n",
      "Saved GIF for episode 90 at GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_90_300_107.gif\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS (PPO Agent)\n",
      "============================================================\n",
      "Success Rate: 32.00%\n",
      "Average Episode Reward: 16.24\n",
      "Average Steps to Find Tumor: 9.34\n",
      "Average Tumor Rewards per Episode: 4.27\n",
      "Tumor Size Statistics:\n",
      "  Biggest Tumor: 4910 pixels (8.52%)\n",
      "  Smallest Tumor: 296 pixels (0.51%)\n",
      "  Average Tumor: 1873 pixels (3.25%)\n",
      "Overall Action Distribution: [0.0615 0.405  0.1605 0.333  0.04  ]\n",
      "  Successful Episodes: [0.06875   0.4171875 0.121875  0.3546875 0.0375   ]\n",
      "  Unsuccessful Episodes: [0.05808824 0.39926471 0.17867647 0.32279412 0.04117647]\n",
      "\n",
      "Detailed Results for 100 episodes:\n",
      "--------------------------------------------------------------------------------\n",
      "Episode 0: 002_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 20.40, Steps to Find: 2\n",
      "  Tumor Size: 2049 pixels (3.56%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_0_002_58.gif\n",
      "\n",
      "Episode 1: 004_87.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -5.60, Steps to Find: 20\n",
      "  Tumor Size: 2727 pixels (4.73%)\n",
      "  Action Distribution: [0.05 0.4  0.1  0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_1_004_87.gif\n",
      "\n",
      "Episode 2: 005_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.00, Steps to Find: 20\n",
      "  Tumor Size: 768 pixels (1.33%)\n",
      "  Action Distribution: [0.2  0.35 0.05 0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_2_005_94.gif\n",
      "\n",
      "Episode 3: 006_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -0.40, Steps to Find: 2\n",
      "  Tumor Size: 2834 pixels (4.92%)\n",
      "  Action Distribution: [0.05 0.4  0.2  0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_3_006_83.gif\n",
      "\n",
      "Episode 4: 007_54.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 21.20, Steps to Find: 8\n",
      "  Tumor Size: 1299 pixels (2.26%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_4_007_54.gif\n",
      "\n",
      "Episode 5: 008_41.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -5.60, Steps to Find: 20\n",
      "  Tumor Size: 1243 pixels (2.16%)\n",
      "  Action Distribution: [0.1  0.35 0.2  0.25 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_5_008_41.gif\n",
      "\n",
      "Episode 6: 009_65.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 14.40, Steps to Find: 4\n",
      "  Tumor Size: 4172 pixels (7.24%)\n",
      "  Action Distribution: [0.1  0.35 0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_6_009_65.gif\n",
      "\n",
      "Episode 7: 010_89.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 5.60, Steps to Find: 4\n",
      "  Tumor Size: 1327 pixels (2.30%)\n",
      "  Action Distribution: [0.05 0.4  0.15 0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_7_010_89.gif\n",
      "\n",
      "Episode 8: 011_103.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 16.00, Steps to Find: 16\n",
      "  Tumor Size: 831 pixels (1.44%)\n",
      "  Action Distribution: [0.05 0.35 0.3  0.25 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_8_011_103.gif\n",
      "\n",
      "Episode 9: 012_69.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 16.00, Steps to Find: 14\n",
      "  Tumor Size: 1365 pixels (2.37%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_9_012_69.gif\n",
      "\n",
      "Episode 10: 013_86.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -5.60, Steps to Find: 2\n",
      "  Tumor Size: 1536 pixels (2.67%)\n",
      "  Action Distribution: [0.1  0.4  0.1  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_10_013_86.gif\n",
      "\n",
      "Episode 11: 014_46.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 74.00, Steps to Find: 2\n",
      "  Tumor Size: 2035 pixels (3.53%)\n",
      "  Action Distribution: [0.05 0.4  0.15 0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_11_014_46.gif\n",
      "\n",
      "Episode 12: 015_71.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -6.40, Steps to Find: 20\n",
      "  Tumor Size: 2195 pixels (3.81%)\n",
      "  Action Distribution: [0.1 0.4 0.2 0.3 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_12_015_71.gif\n",
      "\n",
      "Episode 13: 016_95.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -5.60, Steps to Find: 2\n",
      "  Tumor Size: 2999 pixels (5.21%)\n",
      "  Action Distribution: [0.05 0.3  0.2  0.35 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_13_016_95.gif\n",
      "\n",
      "Episode 14: 017_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 24.80, Steps to Find: 6\n",
      "  Tumor Size: 2255 pixels (3.91%)\n",
      "  Action Distribution: [0.05 0.35 0.25 0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_14_017_68.gif\n",
      "\n",
      "Episode 15: 018_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -0.40, Steps to Find: 4\n",
      "  Tumor Size: 1676 pixels (2.91%)\n",
      "  Action Distribution: [0.1  0.4  0.1  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_15_018_84.gif\n",
      "\n",
      "Episode 16: 019_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 21.60, Steps to Find: 5\n",
      "  Tumor Size: 1280 pixels (2.22%)\n",
      "  Action Distribution: [0.15 0.25 0.4  0.2  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_16_019_52.gif\n",
      "\n",
      "Episode 17: 021_96.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -1.20, Steps to Find: 3\n",
      "  Tumor Size: 867 pixels (1.51%)\n",
      "  Action Distribution: [0.1 0.4 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_17_021_96.gif\n",
      "\n",
      "Episode 18: 022_89.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 40.40, Steps to Find: 2\n",
      "  Tumor Size: 1566 pixels (2.72%)\n",
      "  Action Distribution: [0.05 0.35 0.25 0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_18_022_89.gif\n",
      "\n",
      "Episode 19: 023_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 0.40, Steps to Find: 14\n",
      "  Tumor Size: 1119 pixels (1.94%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_19_023_98.gif\n",
      "\n",
      "Episode 20: 024_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.80, Steps to Find: 20\n",
      "  Tumor Size: 1338 pixels (2.32%)\n",
      "  Action Distribution: [0.15 0.45 0.1  0.2  0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_20_024_49.gif\n",
      "\n",
      "Episode 21: 026_43.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 72.40, Steps to Find: 4\n",
      "  Tumor Size: 663 pixels (1.15%)\n",
      "  Action Distribution: [0.1  0.45 0.05 0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_21_026_43.gif\n",
      "\n",
      "Episode 22: 028_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 10.00, Steps to Find: 9\n",
      "  Tumor Size: 799 pixels (1.39%)\n",
      "  Action Distribution: [0.05 0.45 0.2  0.3  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_22_028_56.gif\n",
      "\n",
      "Episode 23: 030_99.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 16.00, Steps to Find: 2\n",
      "  Tumor Size: 1979 pixels (3.44%)\n",
      "  Action Distribution: [0.05 0.4  0.15 0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_23_030_99.gif\n",
      "\n",
      "Episode 24: 030_115.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 8.40, Steps to Find: 6\n",
      "  Tumor Size: 611 pixels (1.06%)\n",
      "  Action Distribution: [0.05 0.35 0.3  0.25 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_24_030_115.gif\n",
      "\n",
      "Episode 25: 032_134.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 12.00, Steps to Find: 9\n",
      "  Tumor Size: 554 pixels (0.96%)\n",
      "  Action Distribution: [0.15 0.3  0.2  0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_25_032_134.gif\n",
      "\n",
      "Episode 26: 033_86.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 25.60, Steps to Find: 2\n",
      "  Tumor Size: 2788 pixels (4.84%)\n",
      "  Action Distribution: [0.05 0.45 0.2  0.3  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_26_033_86.gif\n",
      "\n",
      "Episode 27: 034_113.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.80, Steps to Find: 20\n",
      "  Tumor Size: 2141 pixels (3.72%)\n",
      "  Action Distribution: [0.15 0.35 0.25 0.25 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_27_034_113.gif\n",
      "\n",
      "Episode 28: 035_40.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 74.00, Steps to Find: 1\n",
      "  Tumor Size: 837 pixels (1.45%)\n",
      "  Action Distribution: [0.  0.5 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_28_035_40.gif\n",
      "\n",
      "Episode 29: 036_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 2.40, Steps to Find: 17\n",
      "  Tumor Size: 795 pixels (1.38%)\n",
      "  Action Distribution: [0.15 0.5  0.1  0.25 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_29_036_83.gif\n",
      "\n",
      "Episode 30: 038_84.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -6.40, Steps to Find: 20\n",
      "  Tumor Size: 1720 pixels (2.99%)\n",
      "  Action Distribution: [0.1  0.35 0.1  0.35 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_30_038_84.gif\n",
      "\n",
      "Episode 31: 040_46.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 3375 pixels (5.86%)\n",
      "  Action Distribution: [0.05 0.4  0.1  0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_31_040_46.gif\n",
      "\n",
      "Episode 32: 043_48.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 21.20, Steps to Find: 2\n",
      "  Tumor Size: 1217 pixels (2.11%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_32_043_48.gif\n",
      "\n",
      "Episode 33: 045_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 18.00, Steps to Find: 10\n",
      "  Tumor Size: 473 pixels (0.82%)\n",
      "  Action Distribution: [0.05 0.5  0.1  0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_33_045_57.gif\n",
      "\n",
      "Episode 34: 045_82.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 26.40, Steps to Find: 4\n",
      "  Tumor Size: 2259 pixels (3.92%)\n",
      "  Action Distribution: [0.15 0.3  0.2  0.2  0.15]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_34_045_82.gif\n",
      "\n",
      "Episode 35: 046_44.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -7.20, Steps to Find: 20\n",
      "  Tumor Size: 1147 pixels (1.99%)\n",
      "  Action Distribution: [0.05 0.3  0.2  0.2  0.25]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_35_046_44.gif\n",
      "\n",
      "Episode 36: 048_49.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.00, Steps to Find: 20\n",
      "  Tumor Size: 1308 pixels (2.27%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_36_048_49.gif\n",
      "\n",
      "Episode 37: 049_81.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -5.60, Steps to Find: 4\n",
      "  Tumor Size: 1649 pixels (2.86%)\n",
      "  Action Distribution: [0.05 0.4  0.1  0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_37_049_81.gif\n",
      "\n",
      "Episode 38: 050_60.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 21.20, Steps to Find: 3\n",
      "  Tumor Size: 2312 pixels (4.01%)\n",
      "  Action Distribution: [0.15 0.35 0.2  0.25 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_38_050_60.gif\n",
      "\n",
      "Episode 39: 051_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -9.60, Steps to Find: 20\n",
      "  Tumor Size: 3155 pixels (5.48%)\n",
      "  Action Distribution: [0.05 0.4  0.3  0.2  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_39_051_94.gif\n",
      "\n",
      "Episode 40: 052_98.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 4.00, Steps to Find: 4\n",
      "  Tumor Size: 1228 pixels (2.13%)\n",
      "  Action Distribution: [0.   0.4  0.25 0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_40_052_98.gif\n",
      "\n",
      "Episode 41: 053_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 11.60, Steps to Find: 2\n",
      "  Tumor Size: 2915 pixels (5.06%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_41_053_85.gif\n",
      "\n",
      "Episode 42: 054_61.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 36.80, Steps to Find: 2\n",
      "  Tumor Size: 2098 pixels (3.64%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_42_054_61.gif\n",
      "\n",
      "Episode 43: 055_61.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.00, Steps to Find: 20\n",
      "  Tumor Size: 2578 pixels (4.48%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_43_055_61.gif\n",
      "\n",
      "Episode 44: 057_124.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.00, Steps to Find: 3\n",
      "  Tumor Size: 1433 pixels (2.49%)\n",
      "  Action Distribution: [0.   0.5  0.25 0.2  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_44_057_124.gif\n",
      "\n",
      "Episode 45: 058_84.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 1.20, Steps to Find: 19\n",
      "  Tumor Size: 1231 pixels (2.14%)\n",
      "  Action Distribution: [0.  0.5 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_45_058_84.gif\n",
      "\n",
      "Episode 46: 059_67.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 14.40, Steps to Find: 15\n",
      "  Tumor Size: 730 pixels (1.27%)\n",
      "  Action Distribution: [0.1  0.35 0.2  0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_46_059_67.gif\n",
      "\n",
      "Episode 47: 066_116.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -6.40, Steps to Find: 20\n",
      "  Tumor Size: 674 pixels (1.17%)\n",
      "  Action Distribution: [0.1  0.45 0.1  0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_47_066_116.gif\n",
      "\n",
      "Episode 48: 090_73.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 21.20, Steps to Find: 6\n",
      "  Tumor Size: 1051 pixels (1.82%)\n",
      "  Action Distribution: [0.   0.45 0.05 0.5  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_48_090_73.gif\n",
      "\n",
      "Episode 49: 092_94.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 18.00, Steps to Find: 3\n",
      "  Tumor Size: 1658 pixels (2.88%)\n",
      "  Action Distribution: [0.   0.4  0.35 0.15 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_49_092_94.gif\n",
      "\n",
      "Episode 50: 104_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 42.80, Steps to Find: 1\n",
      "  Tumor Size: 3423 pixels (5.94%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_50_104_74.gif\n",
      "\n",
      "Episode 51: 116_58.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 22.00, Steps to Find: 2\n",
      "  Tumor Size: 1855 pixels (3.22%)\n",
      "  Action Distribution: [0.  0.5 0.1 0.4 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_51_116_58.gif\n",
      "\n",
      "Episode 52: 119_53.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -7.20, Steps to Find: 20\n",
      "  Tumor Size: 1148 pixels (1.99%)\n",
      "  Action Distribution: [0.15 0.45 0.05 0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_52_119_53.gif\n",
      "\n",
      "Episode 53: 130_39.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 10.00, Steps to Find: 6\n",
      "  Tumor Size: 742 pixels (1.29%)\n",
      "  Action Distribution: [0.1  0.45 0.1  0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_53_130_39.gif\n",
      "\n",
      "Episode 54: 147_83.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 29.20, Steps to Find: 5\n",
      "  Tumor Size: 2935 pixels (5.10%)\n",
      "  Action Distribution: [0.15 0.3  0.15 0.3  0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_54_147_83.gif\n",
      "\n",
      "Episode 55: 154_87.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.60, Steps to Find: 2\n",
      "  Tumor Size: 1443 pixels (2.51%)\n",
      "  Action Distribution: [0.05 0.35 0.5  0.1  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_55_154_87.gif\n",
      "\n",
      "Episode 56: 155_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.00, Steps to Find: 20\n",
      "  Tumor Size: 1005 pixels (1.74%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_56_155_48.gif\n",
      "\n",
      "Episode 57: 160_82.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -0.00, Steps to Find: 18\n",
      "  Tumor Size: 2528 pixels (4.39%)\n",
      "  Action Distribution: [0.05 0.35 0.35 0.2  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_57_160_82.gif\n",
      "\n",
      "Episode 58: 163_101.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.40, Steps to Find: 7\n",
      "  Tumor Size: 3132 pixels (5.44%)\n",
      "  Action Distribution: [0.1  0.3  0.35 0.25 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_58_163_101.gif\n",
      "\n",
      "Episode 59: 171_69.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 16.00, Steps to Find: 3\n",
      "  Tumor Size: 1076 pixels (1.87%)\n",
      "  Action Distribution: [0.05 0.4  0.15 0.3  0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_59_171_69.gif\n",
      "\n",
      "Episode 60: 176_99.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 5.60, Steps to Find: 13\n",
      "  Tumor Size: 2223 pixels (3.86%)\n",
      "  Action Distribution: [0.   0.4  0.15 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_60_176_99.gif\n",
      "\n",
      "Episode 61: 177_57.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -6.40, Steps to Find: 20\n",
      "  Tumor Size: 823 pixels (1.43%)\n",
      "  Action Distribution: [0.1  0.35 0.15 0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_61_177_57.gif\n",
      "\n",
      "Episode 62: 178_85.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.20, Steps to Find: 14\n",
      "  Tumor Size: 2286 pixels (3.97%)\n",
      "  Action Distribution: [0.1 0.3 0.2 0.3 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_62_178_85.gif\n",
      "\n",
      "Episode 63: 179_70.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.80, Steps to Find: 20\n",
      "  Tumor Size: 1958 pixels (3.40%)\n",
      "  Action Distribution: [0.05 0.4  0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_63_179_70.gif\n",
      "\n",
      "Episode 64: 180_50.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -6.40, Steps to Find: 20\n",
      "  Tumor Size: 2855 pixels (4.96%)\n",
      "  Action Distribution: [0.1 0.4 0.2 0.3 0. ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_64_180_50.gif\n",
      "\n",
      "Episode 65: 180_72.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 21.20, Steps to Find: 2\n",
      "  Tumor Size: 2771 pixels (4.81%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_65_180_72.gif\n",
      "\n",
      "Episode 66: 184_36.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 36.00, Steps to Find: 2\n",
      "  Tumor Size: 296 pixels (0.51%)\n",
      "  Action Distribution: [0.   0.45 0.25 0.3  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_66_184_36.gif\n",
      "\n",
      "Episode 67: 188_62.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 48.00, Steps to Find: 2\n",
      "  Tumor Size: 1754 pixels (3.05%)\n",
      "  Action Distribution: [0.05 0.5  0.05 0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_67_188_62.gif\n",
      "\n",
      "Episode 68: 190_81.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 77.60, Steps to Find: 5\n",
      "  Tumor Size: 987 pixels (1.71%)\n",
      "  Action Distribution: [0.1  0.45 0.1  0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_68_190_81.gif\n",
      "\n",
      "Episode 69: 200_45.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 77.60, Steps to Find: 5\n",
      "  Tumor Size: 1239 pixels (2.15%)\n",
      "  Action Distribution: [0.1  0.45 0.05 0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_69_200_45.gif\n",
      "\n",
      "Episode 70: 204_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -3.60, Steps to Find: 1\n",
      "  Tumor Size: 893 pixels (1.55%)\n",
      "  Action Distribution: [0.05 0.25 0.45 0.15 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_70_204_52.gif\n",
      "\n",
      "Episode 71: 226_66.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -7.20, Steps to Find: 20\n",
      "  Tumor Size: 2037 pixels (3.54%)\n",
      "  Action Distribution: [0.   0.45 0.2  0.3  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_71_226_66.gif\n",
      "\n",
      "Episode 72: 227_60.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -4.80, Steps to Find: 5\n",
      "  Tumor Size: 1494 pixels (2.59%)\n",
      "  Action Distribution: [0.05 0.5  0.05 0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_72_227_60.gif\n",
      "\n",
      "Episode 73: 231_90.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 16.00, Steps to Find: 3\n",
      "  Tumor Size: 3297 pixels (5.72%)\n",
      "  Action Distribution: [0.   0.4  0.1  0.45 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_73_231_90.gif\n",
      "\n",
      "Episode 74: 236_58.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 16.80, Steps to Find: 12\n",
      "  Tumor Size: 2498 pixels (4.34%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_74_236_58.gif\n",
      "\n",
      "Episode 75: 237_41.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 26.80, Steps to Find: 14\n",
      "  Tumor Size: 840 pixels (1.46%)\n",
      "  Action Distribution: [0.25 0.45 0.1  0.15 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_75_237_41.gif\n",
      "\n",
      "Episode 76: 240_52.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -6.40, Steps to Find: 20\n",
      "  Tumor Size: 2725 pixels (4.73%)\n",
      "  Action Distribution: [0.1  0.45 0.05 0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_76_240_52.gif\n",
      "\n",
      "Episode 77: 245_35.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: -0.40, Steps to Find: 20\n",
      "  Tumor Size: 1257 pixels (2.18%)\n",
      "  Action Distribution: [0.   0.4  0.15 0.35 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_77_245_35.gif\n",
      "\n",
      "Episode 78: 250_45.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 36.00, Steps to Find: 5\n",
      "  Tumor Size: 1616 pixels (2.81%)\n",
      "  Action Distribution: [0.   0.45 0.1  0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_78_250_45.gif\n",
      "\n",
      "Episode 79: 255_56.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.80, Steps to Find: 20\n",
      "  Tumor Size: 3030 pixels (5.26%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_79_255_56.gif\n",
      "\n",
      "Episode 80: 260_62.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 53.20, Steps to Find: 2\n",
      "  Tumor Size: 1653 pixels (2.87%)\n",
      "  Action Distribution: [0.05 0.45 0.1  0.4  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_80_260_62.gif\n",
      "\n",
      "Episode 81: 266_105.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -8.80, Steps to Find: 20\n",
      "  Tumor Size: 1725 pixels (2.99%)\n",
      "  Action Distribution: [0.1  0.35 0.35 0.2  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_81_266_105.gif\n",
      "\n",
      "Episode 82: 274_90.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 68.00, Steps to Find: 3\n",
      "  Tumor Size: 4092 pixels (7.10%)\n",
      "  Action Distribution: [0.   0.45 0.2  0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_82_274_90.gif\n",
      "\n",
      "Episode 83: 276_102.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -1.20, Steps to Find: 2\n",
      "  Tumor Size: 1831 pixels (3.18%)\n",
      "  Action Distribution: [0.05 0.4  0.25 0.3  0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_83_276_102.gif\n",
      "\n",
      "Episode 84: 280_96.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 18.00, Steps to Find: 6\n",
      "  Tumor Size: 905 pixels (1.57%)\n",
      "  Action Distribution: [0.1  0.25 0.35 0.25 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_84_280_96.gif\n",
      "\n",
      "Episode 85: 282_53.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 94.80, Steps to Find: 2\n",
      "  Tumor Size: 1994 pixels (3.46%)\n",
      "  Action Distribution: [0.   0.5  0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_85_282_53.gif\n",
      "\n",
      "Episode 86: 284_88.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 100.00, Steps to Find: 1\n",
      "  Tumor Size: 4461 pixels (7.74%)\n",
      "  Action Distribution: [0.05 0.45 0.05 0.45 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_86_284_88.gif\n",
      "\n",
      "Episode 87: 287_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 15.20, Steps to Find: 3\n",
      "  Tumor Size: 1807 pixels (3.14%)\n",
      "  Action Distribution: [0.1  0.4  0.1  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_87_287_97.gif\n",
      "\n",
      "Episode 88: 289_74.npy\n",
      "  Success: True, Final on Tumor: True\n",
      "  Total Reward: 74.00, Steps to Find: 2\n",
      "  Tumor Size: 3435 pixels (5.96%)\n",
      "  Action Distribution: [0.15 0.45 0.05 0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_88_289_74.gif\n",
      "\n",
      "Episode 89: 299_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.80, Steps to Find: 20\n",
      "  Tumor Size: 2607 pixels (4.53%)\n",
      "  Action Distribution: [0.05 0.4  0.1  0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_89_299_97.gif\n",
      "\n",
      "Episode 90: 300_107.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 24.00, Steps to Find: 14\n",
      "  Tumor Size: 2216 pixels (3.85%)\n",
      "  Action Distribution: [0.15 0.4  0.1  0.25 0.1 ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_90_300_107.gif\n",
      "\n",
      "Episode 91: 308_88.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 56.80, Steps to Find: 1\n",
      "  Tumor Size: 4910 pixels (8.52%)\n",
      "  Action Distribution: [0.05 0.3  0.3  0.2  0.15]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_91_308_88.gif\n",
      "\n",
      "Episode 92: 314_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 2.40, Steps to Find: 17\n",
      "  Tumor Size: 932 pixels (1.62%)\n",
      "  Action Distribution: [0.1  0.3  0.3  0.25 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_92_314_91.gif\n",
      "\n",
      "Episode 93: 326_68.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 0.40, Steps to Find: 6\n",
      "  Tumor Size: 1227 pixels (2.13%)\n",
      "  Action Distribution: [0.05 0.35 0.2  0.35 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_93_326_68.gif\n",
      "\n",
      "Episode 94: 333_91.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -0.40, Steps to Find: 14\n",
      "  Tumor Size: 3974 pixels (6.90%)\n",
      "  Action Distribution: [0.05 0.3  0.2  0.3  0.15]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_94_333_91.gif\n",
      "\n",
      "Episode 95: 350_77.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -7.20, Steps to Find: 20\n",
      "  Tumor Size: 1879 pixels (3.26%)\n",
      "  Action Distribution: [0.   0.35 0.35 0.25 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_95_350_77.gif\n",
      "\n",
      "Episode 96: 356_97.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 10.80, Steps to Find: 15\n",
      "  Tumor Size: 532 pixels (0.92%)\n",
      "  Action Distribution: [0.  0.4 0.1 0.4 0.1]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_96_356_97.gif\n",
      "\n",
      "Episode 97: 360_103.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 35.20, Steps to Find: 3\n",
      "  Tumor Size: 3331 pixels (5.78%)\n",
      "  Action Distribution: [0.   0.35 0.15 0.45 0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_97_360_103.gif\n",
      "\n",
      "Episode 98: 363_48.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: 22.00, Steps to Find: 15\n",
      "  Tumor Size: 872 pixels (1.51%)\n",
      "  Action Distribution: [0.05 0.5  0.1  0.35 0.  ]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_98_363_48.gif\n",
      "\n",
      "Episode 99: 365_83.npy\n",
      "  Success: False, Final on Tumor: False\n",
      "  Total Reward: -4.00, Steps to Find: 2\n",
      "  Tumor Size: 3872 pixels (6.72%)\n",
      "  Action Distribution: [0.   0.4  0.15 0.4  0.05]\n",
      "  GIF saved: GIFs_batch128_rewards[5.0, -1.0, -0.2]_5actions/episode_99_365_83.gif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_results = testing(\n",
    "    agent=agent,\n",
    "    test_pairs=prepare(mode=\"test\"),\n",
    "    agent_type=\"ppo\",\n",
    "    num_episodes=100,\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    save_gifs=True,\n",
    "    gif_folder=f\"GIFs_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_5actions\"\n",
    ")\n",
    "\n",
    "sucess[f\"PPO_batch{BATCH_SIZE}_rewards{CURRENT_CONFIG['rewards']}_5actions\"] = overall_results['success_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1321f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO_batch64_rewards[5.0, -1.0, -0.2]_3actions: Success Rate = 43.00%\n",
      "PPO_batch32_rewards[5.0, -1.0, -0.2]_3actions: Success Rate = 46.00%\n",
      "PPO_batch128_rewards[5.0, -1.0, -0.2]_3actions: Success Rate = 54.00%\n",
      "PPO_batch128_rewards[5.0, -0.5, -0.2]_3actions: Success Rate = 28.00%\n",
      "PPO_batch128_rewards[5.0, -0.2, -0.05]_3actions: Success Rate = 44.00%\n",
      "PPO_batch128_rewards[5.0, -0.1, -0.02]_3actions: Success Rate = 37.00%\n",
      "PPO_batch128_rewards[5.0, -0.2, -0.05]_5actions: Success Rate = 37.00%\n",
      "PPO_batch128_rewards[5.0, -1.0, -0.2]_5actions: Success Rate = 32.00%\n"
     ]
    }
   ],
   "source": [
    "for item in sucess:\n",
    "    print(f\"{item}: Success Rate = {sucess[item]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7478c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
