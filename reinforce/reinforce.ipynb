{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from gymnasium import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/martina/codi2/4year/tfg\")  # add parent folder of general.py\n",
    "\n",
    "from general import prepare, Glioblastoma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cc4d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNPolicy(nn.Module):\n",
    "    def __init__(self, action_dim, channels=1):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(channels, 16, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 5 * 5, 256),   # flatten size for 60x60 input\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, action_dim),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.flatten(1)\n",
    "        return self.fc(x), None\n",
    "\n",
    "    def act(self, state):\n",
    "        # state shape: (60,60) or (1,60,60)\n",
    "        state = torch.tensor(state, dtype=torch.float32)\n",
    "\n",
    "        if state.ndim == 2:\n",
    "            state = state.unsqueeze(0)  # (1,60,60)\n",
    "        if state.ndim == 3:\n",
    "            state = state.unsqueeze(0)  # (1,1,60,60)\n",
    "\n",
    "        probs, _ = self.forward(state)\n",
    "        dist = torch.distributions.Categorical(probs)\n",
    "        action = dist.sample()\n",
    "\n",
    "        return action.item(), dist.log_prob(action)\n",
    "\n",
    "class REINFORCEAgent:\n",
    "    def __init__(self, env_class, train_pairs, env_config,\n",
    "                 gamma=0.99, lr=1e-4):\n",
    "\n",
    "        self.env_class = env_class\n",
    "        self.train_pairs = train_pairs\n",
    "        self.env_config = env_config\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # Create sample env to read obs shape\n",
    "        sample_img, sample_mask = train_pairs[0]\n",
    "\n",
    "        sample_env = env_class(\n",
    "            sample_img,\n",
    "            sample_mask,\n",
    "            grid_size=env_config[\"grid_size\"],\n",
    "            rewards=env_config[\"rewards\"],\n",
    "            action_space=env_config[\"action_space\"]\n",
    "        )\n",
    "\n",
    "        obs, _ = sample_env.reset()\n",
    "\n",
    "        channels = 1 if obs.ndim == 2 else obs.shape[0]\n",
    "\n",
    "        self.action_dim = env_config[\"action_space\"].n\n",
    "        self.policy = CNNPolicy(self.action_dim, channels)\n",
    "        self.model = self.policy\n",
    "        self.optim = optim.Adam(self.policy.parameters(), lr=lr)\n",
    "        self.best_reward = -1e9\n",
    "        self.save_path = \"reinforce_policy.pt\"\n",
    "\n",
    "\n",
    "    def run_episode(self, img_path, mask_path):\n",
    "        env = self.env_class(\n",
    "            img_path,\n",
    "            mask_path,\n",
    "            grid_size=self.env_config[\"grid_size\"],\n",
    "            rewards=self.env_config[\"rewards\"],\n",
    "            action_space=self.env_config[\"action_space\"]\n",
    "        )\n",
    "\n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action, log_prob = self.policy.act(state)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "            log_probs.append(log_prob)\n",
    "            rewards.append(reward)\n",
    "\n",
    "            state = next_state\n",
    "            done = terminated or truncated\n",
    "\n",
    "        return log_probs, rewards\n",
    "\n",
    "\n",
    "    def compute_returns(self, rewards):\n",
    "        G = 0\n",
    "        returns = []\n",
    "        for r in reversed(rewards):\n",
    "            G = r + self.gamma * G\n",
    "            returns.insert(0, G)\n",
    "        returns = torch.tensor(returns, dtype=torch.float32)\n",
    "        return (returns - returns.mean()) / (returns.std() + 1e-8)\n",
    "\n",
    "    def update_policy(self, log_probs, returns):\n",
    "        loss = []\n",
    "        for lp, Gt in zip(log_probs, returns):\n",
    "            loss.append(-lp * Gt)\n",
    "\n",
    "        loss = torch.stack(loss).sum()\n",
    "\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    # Train over ALL train_pairs each epoch\n",
    "    def train(self, epochs=200):\n",
    "        for e in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            epoch_reward = 0\n",
    "\n",
    "            epoch_rewards = []\n",
    "            # Train on ALL image/mask pairs each epoch\n",
    "            for i, (img_path, mask_path) in enumerate(self.train_pairs):\n",
    "                log_probs, rewards = self.run_episode(img_path, mask_path)\n",
    "                returns = self.compute_returns(rewards)\n",
    "                loss = self.update_policy(log_probs, returns)\n",
    "\n",
    "                epoch_loss += loss\n",
    "                epoch_rewards.append(sum(rewards))\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"  episode = {i} | Episode Reward={sum(rewards):.2f} | Loss={loss:.4f}\")\n",
    "            \n",
    "            avg_reward = np.mean(epoch_rewards)\n",
    "            # Save best model so far\n",
    "            if avg_reward > self.best_reward:\n",
    "                self.best_reward = avg_reward\n",
    "                torch.save(self.policy.state_dict(), self.save_path)\n",
    "                print(f\"  -> Saved new best model (Reward {avg_reward:.2f})\")\n",
    "\n",
    "            if e % 10 == 0:\n",
    "                print(f\"[Epoch {e+1}] Avg Reward per Episode={avg_reward:.2f} | Loss={epoch_loss:.4f}\")\n",
    "\n",
    "        torch.save(self.policy.state_dict(), \"reinforce_final.pt\")\n",
    "        print(\"Training finished. Final model saved to reinforce_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "839a510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found 30 pairs out of 30 listed in CSV.\n"
     ]
    }
   ],
   "source": [
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -1.0, -0.2], \n",
    "    'action_space': spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "train_pairs = prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ce38556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  episode = 0 | Episode Reward=-4.00 | Loss=-0.0924\n",
      "  episode = 10 | Episode Reward=7.20 | Loss=-0.0075\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.1712\n",
      "  -> Saved new best model (Reward -8.17)\n",
      "[Epoch 1] Avg Reward per Episode=-8.17 | Loss=-0.1538\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.1591\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=0.0599\n",
      "  episode = 20 | Episode Reward=-4.80 | Loss=-0.3426\n",
      "  episode = 0 | Episode Reward=-10.00 | Loss=0.0475\n",
      "  episode = 10 | Episode Reward=2.00 | Loss=0.4708\n",
      "  episode = 20 | Episode Reward=1.20 | Loss=-0.1603\n",
      "  -> Saved new best model (Reward -7.55)\n",
      "  episode = 0 | Episode Reward=-4.00 | Loss=0.3678\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.0611\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.0530\n",
      "  -> Saved new best model (Reward -3.29)\n",
      "  episode = 0 | Episode Reward=-4.00 | Loss=0.9734\n",
      "  episode = 10 | Episode Reward=7.20 | Loss=-0.3104\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.4595\n",
      "  -> Saved new best model (Reward 0.91)\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-3.5225\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-4.4711\n",
      "  episode = 20 | Episode Reward=-16.80 | Loss=-1.7218\n",
      "  -> Saved new best model (Reward 4.36)\n",
      "  episode = 0 | Episode Reward=82.80 | Loss=5.3989\n",
      "  episode = 10 | Episode Reward=-4.00 | Loss=-5.3803\n",
      "  episode = 20 | Episode Reward=-18.40 | Loss=2.3270\n",
      "  -> Saved new best model (Reward 9.81)\n",
      "  episode = 0 | Episode Reward=82.80 | Loss=4.5500\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=6.4273\n",
      "  episode = 20 | Episode Reward=70.80 | Loss=5.3532\n",
      "  -> Saved new best model (Reward 11.04)\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.3989\n",
      "  episode = 10 | Episode Reward=65.60 | Loss=2.3165\n",
      "  episode = 20 | Episode Reward=11.60 | Loss=5.1875\n",
      "  -> Saved new best model (Reward 17.97)\n",
      "  episode = 0 | Episode Reward=54.40 | Loss=0.5651\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-0.1228\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.3266\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=2.2070\n",
      "  episode = 10 | Episode Reward=77.60 | Loss=1.7476\n",
      "  episode = 20 | Episode Reward=37.20 | Loss=-3.5889\n",
      "  -> Saved new best model (Reward 20.19)\n",
      "[Epoch 11] Avg Reward per Episode=20.19 | Loss=24.4098\n",
      "  episode = 0 | Episode Reward=14.00 | Loss=-2.4412\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=1.2147\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=5.6879\n",
      "  episode = 0 | Episode Reward=-4.00 | Loss=-1.5727\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.1779\n",
      "  episode = 20 | Episode Reward=53.60 | Loss=4.5528\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.1367\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=-0.6629\n",
      "  episode = 20 | Episode Reward=17.60 | Loss=1.5153\n",
      "  episode = 0 | Episode Reward=83.60 | Loss=-1.1692\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=0.1600\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.2313\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=1.1129\n",
      "  episode = 10 | Episode Reward=25.20 | Loss=-1.6393\n",
      "  episode = 20 | Episode Reward=70.80 | Loss=6.2887\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-4.8115\n",
      "  episode = 10 | Episode Reward=8.00 | Loss=-0.3143\n",
      "  episode = 20 | Episode Reward=65.60 | Loss=6.9371\n",
      "  episode = 0 | Episode Reward=0.40 | Loss=-1.3677\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.2703\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.6892\n",
      "  episode = 0 | Episode Reward=-10.80 | Loss=-0.7141\n",
      "  episode = 10 | Episode Reward=13.20 | Loss=0.4402\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.0964\n",
      "  episode = 0 | Episode Reward=0.40 | Loss=-0.9339\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.7943\n",
      "  episode = 20 | Episode Reward=83.60 | Loss=5.1064\n",
      "  episode = 0 | Episode Reward=88.80 | Loss=5.8644\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.7673\n",
      "  episode = 20 | Episode Reward=76.80 | Loss=2.8809\n",
      "  -> Saved new best model (Reward 21.84)\n",
      "[Epoch 21] Avg Reward per Episode=21.84 | Loss=15.8972\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.6128\n",
      "  episode = 10 | Episode Reward=1.20 | Loss=0.2768\n",
      "  episode = 20 | Episode Reward=1.20 | Loss=-4.3103\n",
      "  episode = 0 | Episode Reward=13.20 | Loss=0.3058\n",
      "  episode = 10 | Episode Reward=7.20 | Loss=-0.9048\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=4.1525\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=1.2698\n",
      "  episode = 10 | Episode Reward=26.00 | Loss=-0.9770\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=4.1445\n",
      "  episode = 0 | Episode Reward=37.20 | Loss=-3.9658\n",
      "  episode = 10 | Episode Reward=-5.60 | Loss=0.4016\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.0510\n",
      "  -> Saved new best model (Reward 23.53)\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-6.8513\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=5.6802\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=3.2445\n",
      "  episode = 0 | Episode Reward=88.80 | Loss=6.2895\n",
      "  episode = 10 | Episode Reward=-4.80 | Loss=1.0677\n",
      "  episode = 20 | Episode Reward=-11.60 | Loss=-6.4692\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=5.2872\n",
      "  episode = 10 | Episode Reward=89.60 | Loss=0.2328\n",
      "  episode = 20 | Episode Reward=88.80 | Loss=0.8839\n",
      "  -> Saved new best model (Reward 24.92)\n",
      "  episode = 0 | Episode Reward=6.40 | Loss=-1.0590\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.2148\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.1603\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-6.0830\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=2.9854\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.1297\n",
      "  episode = 0 | Episode Reward=13.20 | Loss=-1.9973\n",
      "  episode = 10 | Episode Reward=82.80 | Loss=6.2314\n",
      "  episode = 20 | Episode Reward=83.60 | Loss=4.9097\n",
      "  -> Saved new best model (Reward 32.09)\n",
      "[Epoch 31] Avg Reward per Episode=32.09 | Loss=5.6035\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.8428\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=-0.3590\n",
      "  episode = 20 | Episode Reward=-5.60 | Loss=-1.5640\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-2.1008\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.1760\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=4.0327\n",
      "  episode = 0 | Episode Reward=84.40 | Loss=-3.8674\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-4.7982\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=4.1698\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-7.5403\n",
      "  episode = 10 | Episode Reward=65.60 | Loss=-2.7489\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.9503\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=3.9753\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-7.2405\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.7168\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-5.7360\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=2.4569\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.1456\n",
      "  episode = 0 | Episode Reward=0.40 | Loss=-0.8993\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=6.5926\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=4.7418\n",
      "  episode = 0 | Episode Reward=83.60 | Loss=5.0782\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.8493\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.5779\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-4.1998\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=5.3746\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.0119\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.1529\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=6.5069\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.8150\n",
      "[Epoch 41] Avg Reward per Episode=13.93 | Loss=-1.0739\n",
      "  episode = 0 | Episode Reward=70.80 | Loss=7.9493\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.0989\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.8711\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.1559\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.1833\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.3704\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-2.8724\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.0075\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.2937\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-8.3576\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=1.9493\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=5.0359\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-5.6610\n",
      "  episode = 10 | Episode Reward=1.20 | Loss=-2.7640\n",
      "  episode = 20 | Episode Reward=12.40 | Loss=3.5933\n",
      "  episode = 0 | Episode Reward=12.40 | Loss=-0.5680\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.6240\n",
      "  episode = 20 | Episode Reward=88.80 | Loss=6.3064\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-4.9832\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-5.3019\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.7326\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.0126\n",
      "  episode = 10 | Episode Reward=-16.00 | Loss=-4.5129\n",
      "  episode = 20 | Episode Reward=-16.00 | Loss=-0.1649\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.7469\n",
      "  episode = 10 | Episode Reward=-16.00 | Loss=0.1464\n",
      "  episode = 20 | Episode Reward=65.60 | Loss=6.4457\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.7384\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=3.7479\n",
      "  episode = 20 | Episode Reward=82.80 | Loss=6.6953\n",
      "[Epoch 51] Avg Reward per Episode=18.25 | Loss=-11.4861\n",
      "  episode = 0 | Episode Reward=82.80 | Loss=7.1306\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-4.3289\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=4.0829\n",
      "  episode = 0 | Episode Reward=82.80 | Loss=7.2659\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.8974\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=3.6657\n",
      "  episode = 0 | Episode Reward=76.80 | Loss=7.9615\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-3.8687\n",
      "  episode = 20 | Episode Reward=77.60 | Loss=5.9686\n",
      "  episode = 0 | Episode Reward=88.80 | Loss=5.4313\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=-0.2906\n",
      "  episode = 20 | Episode Reward=82.80 | Loss=5.6272\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.0566\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=4.5861\n",
      "  episode = 20 | Episode Reward=-5.60 | Loss=0.3653\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-7.2494\n",
      "  episode = 10 | Episode Reward=7.20 | Loss=-0.9014\n",
      "  episode = 20 | Episode Reward=60.40 | Loss=-8.3379\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=3.6855\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=4.6190\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.0493\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.0345\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.4058\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=3.0885\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.6937\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.7639\n",
      "  episode = 20 | Episode Reward=1.20 | Loss=-1.4194\n",
      "  episode = 0 | Episode Reward=-10.00 | Loss=-2.2716\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=-2.2510\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-1.9885\n",
      "[Epoch 61] Avg Reward per Episode=8.49 | Loss=-18.9749\n",
      "  episode = 0 | Episode Reward=0.40 | Loss=0.0263\n",
      "  episode = 10 | Episode Reward=1.20 | Loss=-1.1538\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=4.4202\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=2.3603\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=0.2320\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.8152\n",
      "  episode = 0 | Episode Reward=-4.00 | Loss=-0.8024\n",
      "  episode = 10 | Episode Reward=83.60 | Loss=0.2717\n",
      "  episode = 20 | Episode Reward=88.80 | Loss=8.4392\n",
      "  episode = 0 | Episode Reward=17.60 | Loss=2.0348\n",
      "  episode = 10 | Episode Reward=-4.80 | Loss=-1.6736\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=2.6354\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.6839\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=0.1796\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.1654\n",
      "  episode = 0 | Episode Reward=83.60 | Loss=5.3053\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-1.7144\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.0341\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=-4.7427\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-2.8808\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=2.8327\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=5.3824\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.6484\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=3.9634\n",
      "  episode = 0 | Episode Reward=-4.00 | Loss=-4.1705\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.0102\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.8397\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-4.6268\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-1.7764\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-2.4778\n",
      "[Epoch 71] Avg Reward per Episode=11.12 | Loss=-21.6682\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.7958\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=5.1457\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.0692\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.2562\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.7235\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-2.6785\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.8837\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-5.4983\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=6.0265\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.0257\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=0.6964\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.0285\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.4752\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=-0.2146\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=2.2679\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=-0.7352\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-1.7963\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=5.3203\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.7292\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=5.0855\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.3221\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.6237\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.7054\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.2309\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.8351\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-4.5458\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.6180\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9427\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=3.5886\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0794\n",
      "[Epoch 81] Avg Reward per Episode=21.43 | Loss=-11.3998\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=2.1586\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-5.3597\n",
      "  episode = 20 | Episode Reward=71.60 | Loss=7.3349\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=5.5652\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-7.8707\n",
      "  episode = 20 | Episode Reward=82.80 | Loss=4.8990\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.7319\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=6.2464\n",
      "  episode = 20 | Episode Reward=88.80 | Loss=4.9387\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=1.3433\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=-4.6617\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=4.0439\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=5.0530\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.6602\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=4.0006\n",
      "  episode = 0 | Episode Reward=-11.60 | Loss=-5.4685\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-3.1731\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=6.4517\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.8023\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=6.2615\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.3145\n",
      "  episode = 0 | Episode Reward=-10.00 | Loss=-8.8664\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-0.8041\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.9734\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.4015\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=6.0281\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1326\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.9047\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=5.6663\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.3020\n",
      "[Epoch 91] Avg Reward per Episode=31.00 | Loss=-10.9717\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.1831\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=4.1647\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.7722\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0560\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=6.2952\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.0867\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.9054\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.6790\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=3.8747\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-5.6286\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.3369\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=3.9521\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=6.1751\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-3.1557\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.0748\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.7643\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-3.0792\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.5427\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.2699\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.5291\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.6067\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.6141\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.4484\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1061\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-4.8259\n",
      "  episode = 10 | Episode Reward=-4.80 | Loss=-2.6382\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=2.8093\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-2.5423\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=8.1496\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1202\n",
      "[Epoch 101] Avg Reward per Episode=22.24 | Loss=-9.1949\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.9987\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.3280\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.0153\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=3.0533\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.5519\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=4.6913\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.8248\n",
      "  episode = 10 | Episode Reward=18.40 | Loss=-2.5299\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.0758\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.8858\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.8712\n",
      "  episode = 20 | Episode Reward=82.80 | Loss=7.4170\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-1.3253\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-3.3435\n",
      "  episode = 20 | Episode Reward=88.80 | Loss=5.0004\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=5.9690\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=4.3949\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.1478\n",
      "  episode = 0 | Episode Reward=88.80 | Loss=6.7973\n",
      "  episode = 10 | Episode Reward=-5.60 | Loss=-5.4410\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.0633\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=2.9537\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=6.9879\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.0849\n",
      "  -> Saved new best model (Reward 36.79)\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.1776\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.2481\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.6849\n",
      "  -> Saved new best model (Reward 46.23)\n",
      "  episode = 0 | Episode Reward=77.60 | Loss=-6.8939\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-4.6388\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.9751\n",
      "[Epoch 111] Avg Reward per Episode=14.40 | Loss=-31.6759\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.1090\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-2.1467\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.2389\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-4.1332\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=1.2543\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.5472\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0067\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=-1.7519\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1794\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.9901\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-3.4814\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.9508\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.5913\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.6047\n",
      "  episode = 20 | Episode Reward=88.80 | Loss=5.8599\n",
      "  episode = 0 | Episode Reward=30.40 | Loss=-0.2017\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.6583\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.2031\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.7871\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-1.8832\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.2679\n",
      "  episode = 0 | Episode Reward=77.60 | Loss=7.9487\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.8302\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.2153\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0181\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-4.0233\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.9765\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.7916\n",
      "  episode = 10 | Episode Reward=-4.00 | Loss=-0.4994\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-3.2497\n",
      "[Epoch 121] Avg Reward per Episode=16.52 | Loss=-30.0886\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.1517\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-1.8869\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0450\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.7267\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-3.7809\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.8610\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.4724\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-1.1238\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1036\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-5.4901\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.7070\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1313\n",
      "  episode = 0 | Episode Reward=88.80 | Loss=7.1588\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.0501\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=6.0351\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.8030\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-3.1621\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1824\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.8559\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=2.9868\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.0342\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.8762\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=-3.1642\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1127\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.5801\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.4411\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-2.4730\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=4.1681\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-4.6476\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1280\n",
      "[Epoch 131] Avg Reward per Episode=16.63 | Loss=-30.9811\n",
      "  episode = 0 | Episode Reward=77.60 | Loss=8.0340\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.0596\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.8769\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.6240\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=5.8539\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0992\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.9174\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.3414\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0595\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.9251\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.2567\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.7487\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=-0.6403\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.9907\n",
      "  episode = 20 | Episode Reward=83.60 | Loss=6.9591\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-7.5361\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.9039\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0165\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9388\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.8837\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0134\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-4.6898\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.2013\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0274\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.1460\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.2093\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.4003\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-4.2642\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-3.5884\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0067\n",
      "[Epoch 141] Avg Reward per Episode=15.19 | Loss=-29.0054\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.6106\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-4.1986\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0065\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.7060\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1400\n",
      "  episode = 20 | Episode Reward=77.60 | Loss=10.3282\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.5871\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=5.3397\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0634\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.3375\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1832\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0089\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.4697\n",
      "  episode = 10 | Episode Reward=-10.00 | Loss=-6.2106\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.9135\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.9320\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=5.8947\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=3.3738\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-5.6011\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.3264\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6264\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.4288\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=1.5054\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.9993\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0003\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.9739\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0044\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9044\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.8004\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-3.6267\n",
      "[Epoch 151] Avg Reward per Episode=16.71 | Loss=-26.8326\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9738\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1482\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0234\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.0915\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-8.2152\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0247\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.0328\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.3572\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.0043\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9491\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0713\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9986\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.5484\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.7478\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.8887\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.2640\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0586\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0009\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.5480\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=7.9127\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9938\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=5.4059\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0800\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.8140\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.5796\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0361\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.4015\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.5771\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0391\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6866\n",
      "[Epoch 161] Avg Reward per Episode=30.37 | Loss=-14.6138\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.4004\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.9406\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9830\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.3389\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.1902\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6114\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-2.1632\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.7203\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9831\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-4.1012\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.7057\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9743\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.7750\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.2017\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9792\n",
      "  episode = 0 | Episode Reward=-16.00 | Loss=-6.4270\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0769\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0560\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.2490\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=1.9322\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.5028\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9926\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.1531\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9671\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.5787\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-4.1960\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0041\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.7902\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-5.3009\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.7400\n",
      "[Epoch 171] Avg Reward per Episode=34.21 | Loss=1.4093\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.6668\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.8179\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9671\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.6342\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0366\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.9053\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.5788\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0534\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9704\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0300\n",
      "  episode = 10 | Episode Reward=84.40 | Loss=-5.0512\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=1.8634\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.5709\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-7.3427\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0091\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.8370\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0789\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0288\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=-0.3218\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.6542\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0047\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=5.1449\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0243\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9718\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.7347\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.3670\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9935\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.6562\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-4.2910\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9708\n",
      "[Epoch 181] Avg Reward per Episode=23.88 | Loss=-6.3077\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.2676\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.8069\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.5651\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.8906\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-5.7683\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9713\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9384\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0205\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6494\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.1715\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-6.2496\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.8645\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.1710\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.7025\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0087\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.5674\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.6964\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0041\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=0.5465\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-6.9217\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.8508\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.1573\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=1.9978\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9643\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.3686\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.7311\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9672\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.5760\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0901\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.5603\n",
      "[Epoch 191] Avg Reward per Episode=16.37 | Loss=-17.2227\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-4.8034\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1339\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0695\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.8720\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0602\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.9260\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.2943\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0142\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9857\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.3123\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0010\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9683\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9671\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0219\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9708\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.1290\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-0.9445\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9811\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.4622\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.8411\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6069\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.1446\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1722\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.9303\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.1907\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.2713\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.7767\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=1.8171\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-5.0992\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9836\n",
      "[Epoch 201] Avg Reward per Episode=24.64 | Loss=-22.2011\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.7471\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.8831\n",
      "  episode = 20 | Episode Reward=88.80 | Loss=5.8601\n",
      "  episode = 0 | Episode Reward=77.60 | Loss=5.7764\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-8.2629\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.8648\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.8158\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.4489\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0317\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9918\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1376\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0262\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0308\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0789\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0180\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9873\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.0447\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9815\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.1816\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-0.3343\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9769\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.3639\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0076\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9786\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9207\n",
      "  episode = 10 | Episode Reward=-10.80 | Loss=-6.1407\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9732\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.1094\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.8612\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.7066\n",
      "[Epoch 211] Avg Reward per Episode=23.88 | Loss=-6.2355\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9463\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=0.9133\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.4613\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9685\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0705\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-1.2873\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9981\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.5033\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0499\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=3.1307\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=1.1170\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0677\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.8369\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0368\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9901\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9212\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.7226\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.0091\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9422\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-1.1605\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0070\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-9.5532\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1134\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.3053\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=7.3178\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0584\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0125\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.4439\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0663\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0138\n",
      "[Epoch 221] Avg Reward per Episode=34.33 | Loss=3.9981\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=1.3112\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.7207\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6637\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.8435\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0449\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-1.3824\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.7992\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.9510\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9832\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.7876\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0247\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9884\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.0667\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0264\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9974\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.5896\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0393\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6977\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.5660\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-4.1555\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.7013\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.7003\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.6751\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=7.4005\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=4.5853\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0432\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0053\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.9295\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.6537\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6794\n",
      "[Epoch 231] Avg Reward per Episode=29.56 | Loss=-13.0621\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.5173\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-3.1819\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.5937\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.1434\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.2298\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=1.4010\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.5854\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0516\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.9371\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.8903\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0244\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.0690\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.7935\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-2.6263\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.1636\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.5409\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.6318\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=1.6518\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.8394\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0833\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0585\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.6070\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0887\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.9414\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.7021\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=5.5180\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0454\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.5396\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=4.1930\n",
      "  episode = 20 | Episode Reward=88.80 | Loss=6.3687\n",
      "[Epoch 241] Avg Reward per Episode=38.43 | Loss=4.7867\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.7091\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0745\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0543\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.7624\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-9.7771\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.7775\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.6174\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1357\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=2.4650\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-2.9931\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1735\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1174\n",
      "  episode = 0 | Episode Reward=88.80 | Loss=5.3300\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.3982\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=4.8762\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.8282\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=2.5051\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.5029\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.0373\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.2718\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1750\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=3.5300\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-2.8267\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0814\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-1.4037\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1322\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0663\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.9880\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1228\n",
      "  episode = 20 | Episode Reward=83.60 | Loss=6.5293\n",
      "[Epoch 251] Avg Reward per Episode=20.57 | Loss=-12.3260\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-7.0883\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.6347\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.2362\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-4.2785\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.2076\n",
      "  episode = 20 | Episode Reward=83.60 | Loss=6.2933\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=4.8351\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-3.6461\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1134\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-4.7566\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-2.0011\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6913\n",
      "  episode = 0 | Episode Reward=88.80 | Loss=-2.8775\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1327\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6195\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.8404\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1638\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1167\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.1026\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.2414\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1090\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.7456\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=7.5370\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.0122\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.8673\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-6.6342\n",
      "  episode = 20 | Episode Reward=83.60 | Loss=6.6209\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.8016\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.7437\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1054\n",
      "[Epoch 261] Avg Reward per Episode=15.81 | Loss=-37.1509\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0619\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-5.4836\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.8018\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0800\n",
      "  episode = 10 | Episode Reward=88.80 | Loss=6.4602\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-1.9608\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0827\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-3.1317\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1212\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0817\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-2.2672\n",
      "  episode = 20 | Episode Reward=88.80 | Loss=5.9020\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=2.8022\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=4.1168\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1449\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.1308\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.8869\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1551\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.1056\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.0487\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.3743\n",
      "  episode = 0 | Episode Reward=-17.60 | Loss=-2.2555\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.9383\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.0901\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-5.3309\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-5.7425\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.7180\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0330\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-2.9828\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.0244\n",
      "[Epoch 271] Avg Reward per Episode=26.41 | Loss=-10.9211\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0384\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.5714\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0426\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0367\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.6442\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-5.3149\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0395\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.5266\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.7994\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.5929\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.3156\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0099\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.4262\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-3.7411\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.7105\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=-0.0962\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1574\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9975\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9996\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1319\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9950\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9949\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.1147\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.1120\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0094\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.2289\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0319\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-2.9168\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.3255\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0254\n",
      "[Epoch 281] Avg Reward per Episode=12.47 | Loss=-31.7814\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0134\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-5.1547\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0193\n",
      "  episode = 0 | Episode Reward=-17.60 | Loss=-14.9390\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.6062\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.8431\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9846\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0857\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=-0.0418\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.2662\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-3.0607\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.0197\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9723\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0088\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.7233\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0158\n",
      "  episode = 10 | Episode Reward=-16.80 | Loss=-2.7202\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.8207\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.7863\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=1.9886\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.6683\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9705\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0273\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9760\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=0.3982\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=2.0640\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=2.5935\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0238\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.1734\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0890\n",
      "[Epoch 291] Avg Reward per Episode=19.59 | Loss=-5.7562\n",
      "  episode = 0 | Episode Reward=89.60 | Loss=3.1520\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=3.7751\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.8581\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0478\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=4.1620\n",
      "  episode = 20 | Episode Reward=89.60 | Loss=3.0318\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0205\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.3390\n",
      "  episode = 20 | Episode Reward=-15.20 | Loss=0.0633\n",
      "  episode = 0 | Episode Reward=-16.80 | Loss=-3.8904\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.7098\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.1355\n",
      "  episode = 0 | Episode Reward=-15.20 | Loss=3.7170\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=1.7381\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0958\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=2.0948\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=0.5883\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9881\n",
      "  episode = 0 | Episode Reward=94.80 | Loss=1.9792\n",
      "  episode = 10 | Episode Reward=-15.20 | Loss=-0.0519\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0090\n",
      "  episode = 0 | Episode Reward=-17.60 | Loss=-2.8113\n",
      "  episode = 10 | Episode Reward=-11.60 | Loss=-2.1550\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=2.0022\n",
      "  episode = 0 | Episode Reward=-17.60 | Loss=-2.7221\n",
      "  episode = 10 | Episode Reward=94.80 | Loss=4.1913\n",
      "  episode = 20 | Episode Reward=94.80 | Loss=1.9887\n",
      "Training finished. Final model saved to reinforce_final.pt\n"
     ]
    }
   ],
   "source": [
    "agent = REINFORCEAgent(\n",
    "    env_class=Glioblastoma,\n",
    "    train_pairs=train_pairs,\n",
    "    env_config=CURRENT_CONFIG,\n",
    "    gamma=0.99,\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "agent.train(epochs=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9fbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
