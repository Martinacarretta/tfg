{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb7e8c3",
   "metadata": {},
   "source": [
    "# Notebook to experiment with testing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc7211",
   "metadata": {},
   "source": [
    "## Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a2d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from gymnasium import spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19986577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_environments import prepare, Glioblastoma\n",
    "from training_dqn import DQN\n",
    "from training_agents import DQNAgent\n",
    "from training_buffers import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b21fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found 100 pairs out of 100 listed in CSV.\n"
     ]
    }
   ],
   "source": [
    "test_pairs = prepare(mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461e489",
   "metadata": {},
   "source": [
    "# TESTING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdeda815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent_current(agent, test_pairs, num_episodes=10, print_results=True):\n",
    "    \"\"\"\n",
    "    Test the trained agent using the current environment setup\n",
    "    without any modifications to reward system or early termination\n",
    "    \"\"\"\n",
    "    agent.dnnetwork.eval()  # Set to evaluation mode\n",
    "    \n",
    "    metrics = {\n",
    "        'success_rate': [],\n",
    "        'final_position_accuracy': [],\n",
    "        'average_reward': [],\n",
    "        'steps_to_find_tumor': [],\n",
    "        'tumor_coverage': [],\n",
    "        'total_tumor_reward': []\n",
    "    }\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        img_path, mask_path = test_pairs[i]\n",
    "        env = Glioblastoma(img_path, mask_path, grid_size=4)\n",
    "        \n",
    "        state, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        found_tumor = False\n",
    "        tumor_positions_visited = set()\n",
    "        steps_to_find = env.max_steps  # Default: didn't find\n",
    "        tumor_rewards = 0\n",
    "        \n",
    "        for step in range(env.max_steps):\n",
    "            with torch.no_grad():\n",
    "                action = agent.dnnetwork.get_action(state, epsilon=0.00)\n",
    "            \n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Track tumor-related metrics\n",
    "            current_overlap = env.current_patch_overlap_with_lesion()\n",
    "            if current_overlap > 0:\n",
    "                tumor_positions_visited.add(tuple(env.agent_pos))\n",
    "                if not found_tumor:\n",
    "                    found_tumor = True\n",
    "                    steps_to_find = step + 1\n",
    "                \n",
    "                # Count positive rewards (when on tumor)\n",
    "                if reward > 0:\n",
    "                    tumor_rewards += 1\n",
    "        \n",
    "        # Calculate metrics for this episode\n",
    "        final_overlap = env.current_patch_overlap_with_lesion()\n",
    "        \n",
    "        # Success: ended on tumor region\n",
    "        success = final_overlap > 0\n",
    "        metrics['success_rate'].append(success)\n",
    "        \n",
    "        # Final position accuracy\n",
    "        metrics['final_position_accuracy'].append(final_overlap > 0)\n",
    "        \n",
    "        # Average reward\n",
    "        metrics['average_reward'].append(total_reward)\n",
    "        \n",
    "        # Steps to find tumor\n",
    "        metrics['steps_to_find_tumor'].append(steps_to_find)\n",
    "        \n",
    "        # Tumor coverage (percentage of tumor patches visited)\n",
    "        total_tumor_patches = count_tumor_patches(env)\n",
    "        coverage = len(tumor_positions_visited) / total_tumor_patches if total_tumor_patches > 0 else 0\n",
    "        metrics['tumor_coverage'].append(coverage)\n",
    "        \n",
    "        # Total positive rewards from tumor\n",
    "        metrics['total_tumor_reward'].append(tumor_rewards)\n",
    "    \n",
    "    # Calculate and print final results\n",
    "    if print_results:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TEST RESULTS (Current Model)\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Success Rate: {np.mean(metrics['success_rate'])*100:.2f}%\")\n",
    "        print(f\"Final Position Accuracy: {np.mean(metrics['final_position_accuracy'])*100:.2f}%\")\n",
    "        print(f\"Average Episode Reward: {np.mean(metrics['average_reward']):.2f}\")\n",
    "        print(f\"Average Steps to Find Tumor: {np.mean(metrics['steps_to_find_tumor']):.2f}\")\n",
    "        print(f\"Average Tumor Coverage: {np.mean(metrics['tumor_coverage'])*100:.2f}%\")\n",
    "        print(f\"Average Tumor Rewards per Episode: {np.mean(metrics['total_tumor_reward']):.2f}\")\n",
    "        \n",
    "        # Additional detailed statistics\n",
    "        print(\"\\nDetailed Statistics:\")\n",
    "        print(f\"Best Episode Reward: {np.max(metrics['average_reward']):.2f}\")\n",
    "        print(f\"Worst Episode Reward: {np.min(metrics['average_reward']):.2f}\")\n",
    "        print(f\"Median Steps to Find Tumor: {np.median(metrics['steps_to_find_tumor']):.2f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def count_tumor_patches(env):\n",
    "    \"\"\"Count total number of patches that contain tumor\"\"\"\n",
    "    tumor_patches = 0\n",
    "    original_pos = env.agent_pos.copy()  # Save original position\n",
    "    \n",
    "    for i in range(env.grid_size):\n",
    "        for j in range(env.grid_size):\n",
    "            env.agent_pos = [i, j]\n",
    "            if env.current_patch_overlap_with_lesion() > 0:\n",
    "                tumor_patches += 1\n",
    "    \n",
    "    env.agent_pos = original_pos  # Restore original position\n",
    "    return tumor_patches\n",
    "\n",
    "def visualize_test_episode(agent, img_path, mask_path, episode_num=0):\n",
    "    \"\"\"Visualize a single test episode\"\"\"\n",
    "    env = Glioblastoma(img_path, mask_path, grid_size=4)\n",
    "    state, _ = env.reset()\n",
    "    \n",
    "    positions = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    episode_reward = 0\n",
    "    tumor_found = False\n",
    "    \n",
    "    print(f\"\\nVisualizing Test Episode {episode_num}\")\n",
    "    print(\"Image:\", os.path.basename(img_path))\n",
    "    \n",
    "    for step in range(env.max_steps):\n",
    "        with torch.no_grad():\n",
    "            action = agent.dnnetwork.get_action(state, epsilon=0.01)\n",
    "        \n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        \n",
    "        positions.append(env.agent_pos.copy())\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        # Check tumor status\n",
    "        current_overlap = env.current_patch_overlap_with_lesion()\n",
    "        if current_overlap > 0 and not tumor_found:\n",
    "            tumor_found = True\n",
    "            print(f\"  Step {step+1}: Found tumor at position {env.agent_pos}\")\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        # Render every step or at important moments\n",
    "        if step == 0 or tumor_found or step == env.max_steps - 1:\n",
    "            env.render()\n",
    "    \n",
    "    final_overlap = env.current_patch_overlap_with_lesion()\n",
    "    print(f\"Final position: {env.agent_pos}, On tumor: {final_overlap > 0}\")\n",
    "    print(f\"Total reward: {sum(rewards):.2f}\")\n",
    "    \n",
    "    print(\"\\nStep-by-step rewards:\")\n",
    "    for idx, (pos, act, rew) in enumerate(zip(positions, actions, rewards)):\n",
    "        print(f\"  Step {idx+1}: Position {pos}, Action {act}, Reward {rew}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6597962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model to test:\n",
    "LR = 1e-4 #From paper\n",
    "CONFIG1 = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [10.0, -2.0, -0.5],\n",
    "    'action_space': spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "CONFIG2 = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [10.0, -2.0, -0.5], # [10.0, -2.0, -0.5],\n",
    "    'action_space': spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "env = Glioblastoma(*test_pairs[0], **CONFIG1)\n",
    "env2 = Glioblastoma(*test_pairs[0], **CONFIG2)\n",
    "\n",
    "model = DQN(env, learning_rate=LR, device='cpu')\n",
    "model.load_state_dict(torch.load(\"Glioblastoma020_56.dat\"))\n",
    "\n",
    "model2 = DQN(env2, learning_rate=LR, device='cpu')\n",
    "model2.load_state_dict(torch.load(\"Trial009.dat\"))\n",
    "# model2.load_state_dict(torch.load(\"Glioblastoma.dat\"))\n",
    "\n",
    "agent = DQNAgent(env_config=CONFIG1, dnnetwork=model, buffer_class=ReplayBuffer, train_pairs=test_pairs,\n",
    "                 env_class=Glioblastoma,\n",
    "                 epsilon=0.00)  # very low epsilon for testing\n",
    "\n",
    "agent2 = DQNAgent(env_config=CONFIG2, dnnetwork=model2, buffer_class=ReplayBuffer, train_pairs=test_pairs,\n",
    "                  env_class=Glioblastoma,\n",
    "                  epsilon=0.00)  # very low epsilon for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "882c27e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of layer fc.0.weight:\n",
      "tensor([[ 0.0457, -0.0255, -0.0067,  ..., -0.0145, -0.0194,  0.0553],\n",
      "        [-0.0144,  0.0111, -0.0237,  ...,  0.0092,  0.0182,  0.0530],\n",
      "        [ 0.0291, -0.0288, -0.0541,  ..., -0.0471, -0.0503, -0.0414],\n",
      "        ...,\n",
      "        [ 0.0490,  0.0193, -0.0301,  ..., -0.0445,  0.0345, -0.0869],\n",
      "        [-0.0245, -0.0035, -0.0140,  ..., -0.0262,  0.0071, -0.0459],\n",
      "        [-0.0112,  0.0424, -0.0333,  ..., -0.0602,  0.0015, -0.0723]])\n",
      "Weights of layer fc.0.weight:\n",
      "tensor([[ 0.0311, -0.0320,  0.0300,  ...,  0.0296,  0.0037,  0.0281],\n",
      "        [-0.0145, -0.0473, -0.0158,  ..., -0.0107,  0.0320, -0.0575],\n",
      "        [ 0.0157, -0.0318, -0.0100,  ..., -0.0154,  0.0036,  0.0527],\n",
      "        ...,\n",
      "        [-0.0248,  0.0158, -0.0228,  ..., -0.0108, -0.0287, -0.0621],\n",
      "        [ 0.0176,  0.0514,  0.0318,  ..., -0.0024, -0.0001, -0.0003],\n",
      "        [ 0.0014,  0.0527,  0.0293,  ...,  0.0138, -0.0045, -0.0708]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'fc' in name and 'weight' in name:\n",
    "        print(f\"Weights of layer {name}:\")\n",
    "        print(param.data)\n",
    "        break  # print only the first fc layer weights\n",
    "\n",
    "for name, param in model2.named_parameters():\n",
    "    if 'fc' in name and 'weight' in name:\n",
    "        print(f\"Weights of layer {name}:\")\n",
    "        print(param.data)\n",
    "        break  # print only the first fc layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "698e9f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TEST RESULTS (Current Model)\n",
      "==================================================\n",
      "Success Rate: 54.00%\n",
      "Final Position Accuracy: 54.00%\n",
      "Average Episode Reward: -10.03\n",
      "Average Steps to Find Tumor: 10.53\n",
      "Average Tumor Coverage: 26.21%\n",
      "Average Tumor Rewards per Episode: 8.82\n",
      "\n",
      "Detailed Statistics:\n",
      "Best Episode Reward: 20.00\n",
      "Worst Episode Reward: -35.50\n",
      "Median Steps to Find Tumor: 3.00\n",
      "\n",
      "==================================================\n",
      "TEST RESULTS (Current Model)\n",
      "==================================================\n",
      "Success Rate: 36.00%\n",
      "Final Position Accuracy: 36.00%\n",
      "Average Episode Reward: -23.73\n",
      "Average Steps to Find Tumor: 13.48\n",
      "Average Tumor Coverage: 11.10%\n",
      "Average Tumor Rewards per Episode: 4.41\n",
      "\n",
      "Detailed Statistics:\n",
      "Best Episode Reward: 20.00\n",
      "Worst Episode Reward: -38.50\n",
      "Median Steps to Find Tumor: 20.00\n"
     ]
    }
   ],
   "source": [
    "metrics1 = test_agent_current(agent, test_pairs, num_episodes=len(test_pairs))\n",
    "\n",
    "metrics2 = test_agent_current(agent2, test_pairs, num_episodes=len(test_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d21522",
   "metadata": {},
   "source": [
    "- Trial003: accuracy = 51.00%\n",
    "- 004 - 27%\n",
    "- 005 - 52%\n",
    "- 006 - 14%\n",
    "- 007 - 07%\n",
    "- 008 - 36%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ada14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test each one of the models in the folder \"other_models\"\n",
    "# env = Glioblastoma(*test_pairs[0], grid_size=4)\n",
    "# model = DQN(env, learning_rate=LR, device='cpu')\n",
    "\n",
    "# max_success_rate = 0  # initialize to zero\n",
    "# for model_file in os.listdir(\"other_models\"):\n",
    "#     if model_file.endswith(\".dat\"):\n",
    "#         # print(f\"\\nTesting model: {model_file}\")\n",
    "#         model.load_state_dict(torch.load(os.path.join(\"other_models\", model_file)))\n",
    "        \n",
    "#         agent = DQNAgent(env=env, dnnetwork=model, buffer_class=ReplayBuffer, train_pairs=test_pairs,\n",
    "#                          epsilon=0.00)  # very low epsilon for testing\n",
    "        \n",
    "#         metrics = test_agent_current(agent, test_pairs, num_episodes=len(test_pairs), print_results=False)\n",
    "#         if np.mean(metrics['success_rate']) > max_success_rate:\n",
    "#             max_success_rate = np.mean(metrics['success_rate'])\n",
    "#             best_model_file = model_file\n",
    "#             print(f\"New best model found: {best_model_file} with success rate {max_success_rate*100:.2f}%\")\n",
    "            \n",
    "# print(f\"\\nBest model overall: {best_model_file} with success rate {max_success_rate*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f84e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):  # visualize 3 test episodes\n",
    "#     visualize_test_episode(agent2, test_pairs[i][0], test_pairs[i][1], episode_num=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
