{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb7e8c3",
   "metadata": {},
   "source": [
    "# Notebook to experiment with testing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc7211",
   "metadata": {},
   "source": [
    "## Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from gymnasium import spaces\n",
    "\n",
    "SEED = 42\n",
    "# Python RNG\n",
    "random.seed(SEED)\n",
    "\n",
    "# NumPy RNG\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# PyTorch RNG (CPU + GPU)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19986577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_environments import prepare, Glioblastoma, Glioblastoma2\n",
    "from training_dqn import DQN, DQN2, DQN3, DQN4\n",
    "from training_agents import DQNAgent, DQNAgent2\n",
    "from training_buffers import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b21fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = prepare(mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461e489",
   "metadata": {},
   "source": [
    "# TESTING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeda815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent_current(agent, test_pairs, num_episodes=10, print_results=True, env_config=None):\n",
    "    \"\"\"\n",
    "    Test the trained agent using the current environment setup\n",
    "    without any modifications to reward system or early termination\n",
    "    \"\"\"\n",
    "    agent.dnnetwork.eval()  # Set to evaluation mode\n",
    "    \n",
    "    metrics = {\n",
    "        'success_rate': [],\n",
    "        'final_position_accuracy': [],\n",
    "        'average_reward': [],\n",
    "        'steps_to_find_tumor': [],\n",
    "        'tumor_coverage': [],\n",
    "        'total_tumor_reward': []\n",
    "    }\n",
    "    \n",
    "    grid_size, rewards, action_space = env_config['grid_size'], env_config['rewards'], env_config['action_space']\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        img_path, mask_path = test_pairs[i]\n",
    "        env = Glioblastoma2(img_path, mask_path, grid_size=grid_size, rewards=rewards, action_space=action_space)\n",
    "        \n",
    "        state, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        found_tumor = False\n",
    "        tumor_positions_visited = set()\n",
    "        steps_to_find = env.max_steps  # Default: didn't find\n",
    "        tumor_rewards = 0\n",
    "        \n",
    "        for step in range(env.max_steps):\n",
    "            with torch.no_grad():\n",
    "                action = agent.dnnetwork.get_action(state, epsilon=0.00)\n",
    "            \n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Track tumor-related metrics\n",
    "            current_overlap = env.current_patch_overlap_with_lesion()\n",
    "            if current_overlap > 0:\n",
    "                tumor_positions_visited.add(tuple(env.agent_pos))\n",
    "                if not found_tumor:\n",
    "                    found_tumor = True\n",
    "                    steps_to_find = step + 1\n",
    "                \n",
    "                # Count positive rewards (when on tumor)\n",
    "                if reward > 0:\n",
    "                    tumor_rewards += 1\n",
    "        \n",
    "        # Calculate metrics for this episode\n",
    "        final_overlap = env.current_patch_overlap_with_lesion()\n",
    "        \n",
    "        # Success: ended on tumor region\n",
    "        success = final_overlap > 0\n",
    "        metrics['success_rate'].append(success)\n",
    "        \n",
    "        # Final position accuracy\n",
    "        metrics['final_position_accuracy'].append(final_overlap > 0)\n",
    "        \n",
    "        # Average reward\n",
    "        metrics['average_reward'].append(total_reward)\n",
    "        \n",
    "        # Steps to find tumor\n",
    "        metrics['steps_to_find_tumor'].append(steps_to_find)\n",
    "        \n",
    "        # Tumor coverage (percentage of tumor patches visited)\n",
    "        total_tumor_patches = count_tumor_patches(env)\n",
    "        coverage = len(tumor_positions_visited) / total_tumor_patches if total_tumor_patches > 0 else 0\n",
    "        metrics['tumor_coverage'].append(coverage)\n",
    "        \n",
    "        # Total positive rewards from tumor\n",
    "        metrics['total_tumor_reward'].append(tumor_rewards)\n",
    "    \n",
    "    # Calculate and print final results\n",
    "    if print_results:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TEST RESULTS (Current Model)\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Success Rate: {np.mean(metrics['success_rate'])*100:.2f}%\")\n",
    "        print(f\"Final Position Accuracy: {np.mean(metrics['final_position_accuracy'])*100:.2f}%\")\n",
    "        print(f\"Average Episode Reward: {np.mean(metrics['average_reward']):.2f}\")\n",
    "        print(f\"Average Steps to Find Tumor: {np.mean(metrics['steps_to_find_tumor']):.2f}\")\n",
    "        print(f\"Average Tumor Coverage: {np.mean(metrics['tumor_coverage'])*100:.2f}%\")\n",
    "        print(f\"Average Tumor Rewards per Episode: {np.mean(metrics['total_tumor_reward']):.2f}\")\n",
    "        \n",
    "        # Additional detailed statistics\n",
    "        print(\"\\nDetailed Statistics:\")\n",
    "        print(f\"Best Episode Reward: {np.max(metrics['average_reward']):.2f}\")\n",
    "        print(f\"Worst Episode Reward: {np.min(metrics['average_reward']):.2f}\")\n",
    "        print(f\"Median Steps to Find Tumor: {np.median(metrics['steps_to_find_tumor']):.2f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def count_tumor_patches(env):\n",
    "    \"\"\"Count total number of patches that contain tumor\"\"\"\n",
    "    tumor_patches = 0\n",
    "    original_pos = env.agent_pos.copy()  # Save original position\n",
    "    \n",
    "    for i in range(env.grid_size):\n",
    "        for j in range(env.grid_size):\n",
    "            env.agent_pos = [i, j]\n",
    "            if env.current_patch_overlap_with_lesion() > 0:\n",
    "                tumor_patches += 1\n",
    "    \n",
    "    env.agent_pos = original_pos  # Restore original position\n",
    "    return tumor_patches\n",
    "\n",
    "def visualize_test_episode(agent, img_path, mask_path, episode_num=0):\n",
    "    \"\"\"Visualize a single test episode\"\"\"\n",
    "    env = Glioblastoma2(img_path, mask_path, grid_size=4)\n",
    "    state, _ = env.reset()\n",
    "    \n",
    "    positions = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    episode_reward = 0\n",
    "    tumor_found = False\n",
    "    \n",
    "    print(f\"\\nVisualizing Test Episode {episode_num}\")\n",
    "    print(\"Image:\", os.path.basename(img_path))\n",
    "    \n",
    "    for step in range(env.max_steps):\n",
    "        with torch.no_grad():\n",
    "            action = agent.dnnetwork.get_action(state, epsilon=0.01)\n",
    "        \n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        \n",
    "        positions.append(env.agent_pos.copy())\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        # Check tumor status\n",
    "        current_overlap = env.current_patch_overlap_with_lesion()\n",
    "        if current_overlap > 0 and not tumor_found:\n",
    "            tumor_found = True\n",
    "            print(f\"  Step {step+1}: Found tumor at position {env.agent_pos}\")\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        # Render every step or at important moments\n",
    "        if step == 0 or tumor_found or step == env.max_steps - 1:\n",
    "            env.render()\n",
    "    \n",
    "    final_overlap = env.current_patch_overlap_with_lesion()\n",
    "    print(f\"Final position: {env.agent_pos}, On tumor: {final_overlap > 0}\")\n",
    "    print(f\"Total reward: {sum(rewards):.2f}\")\n",
    "    \n",
    "    print(\"\\nStep-by-step rewards:\")\n",
    "    for idx, (pos, act, rew) in enumerate(zip(positions, actions, rewards)):\n",
    "        print(f\"  Step {idx+1}: Position {pos}, Action {act}, Reward {rew}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6597962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model to test:\n",
    "LR = 1e-4 #From paper\n",
    "CURRENT_CONFIG = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [3.0, -1.5, -0.5], \n",
    "    'action_space': spaces.Discrete(5)\n",
    "}\n",
    "\n",
    "env = Glioblastoma2(*test_pairs[0], **CURRENT_CONFIG)\n",
    "\n",
    "model = DQN4(env, learning_rate=LR, device='cpu')\n",
    "model.load_state_dict(torch.load(\"Extension008.dat\"))\n",
    "\n",
    "agent = DQNAgent2(env_config=CURRENT_CONFIG, dnnetwork=model, buffer_class=ReplayBuffer, train_pairs=test_pairs,\n",
    "                 env_class=Glioblastoma2,\n",
    "                 epsilon=0.00)  # very low epsilon for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if 'fc' in name and 'weight' in name:\n",
    "#         print(f\"Weights of layer {name}:\")\n",
    "#         print(param.data)\n",
    "#         break  # print only the first fc layer weights\n",
    "\n",
    "# for name, param in model2.named_parameters():\n",
    "#     if 'fc' in name and 'weight' in name:\n",
    "#         print(f\"Weights of layer {name}:\")\n",
    "#         print(param.data)\n",
    "#         break  # print only the first fc layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics1 = test_agent_current(agent, test_pairs, num_episodes=len(test_pairs), env_config=CURRENT_CONFIG)\n",
    "\n",
    "# metrics2 = test_agent_current(agent2, test_pairs, num_episodes=len(test_pairs), env_config=CONFIG2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d21522",
   "metadata": {},
   "source": [
    "- Trial003: accuracy = 51.00%\n",
    "- 004 - 27%\n",
    "- 005 - 52%\n",
    "- 006 - 14%\n",
    "- 007 - 07%\n",
    "- 008 - 36%\n",
    "- 012 - 54%\n",
    "- 013 - 25%\n",
    "- 014 - 36%\n",
    "- 014 - 53%\n",
    "- 016 - 47%\n",
    "- 017 - 22%\n",
    "- 018 - 52%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4 #From paper\n",
    "\n",
    "# test each one of the models in the folder \"other_models\"\n",
    "CONFIG1 = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [10.0, -2.0, -0.5],\n",
    "    'action_space': spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "CONFIG2 = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [5.0, -1.0, -0.2],\n",
    "    'action_space': spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "CONFIG3 = {\n",
    "    'grid_size': 4,\n",
    "    'rewards': [8.0, -1.5, -0.3],\n",
    "    'action_space': spaces.Discrete(3)\n",
    "}\n",
    "\n",
    "\n",
    "env1 = Glioblastoma(*test_pairs[0], **CONFIG1)\n",
    "model = DQN(env1, learning_rate=LR, device='cpu')\n",
    "agent1 = DQNAgent(env_config=CONFIG1, dnnetwork=model, buffer_class=ReplayBuffer, train_pairs=test_pairs,\n",
    "                 env_class=Glioblastoma,\n",
    "                 epsilon=0.00)  # very low epsilon for testing\n",
    "\n",
    "\n",
    "env2 = Glioblastoma(*test_pairs[0], **CONFIG2)\n",
    "model2 = DQN(env2, learning_rate=LR, device='cpu')\n",
    "agent2 = DQNAgent(env_config=CONFIG2, dnnetwork=model2, buffer_class=ReplayBuffer, train_pairs=test_pairs,\n",
    "                 env_class=Glioblastoma,\n",
    "                 epsilon=0.00)  # very low epsilon for testing\n",
    "\n",
    "env3 = Glioblastoma(*test_pairs[0], **CONFIG3)\n",
    "model3 = DQN(env3, learning_rate=LR, device='cpu')\n",
    "agent3 = DQNAgent(env_config=CONFIG3, dnnetwork=model3, buffer_class=ReplayBuffer, train_pairs=test_pairs,\n",
    "                 env_class=Glioblastoma,\n",
    "                 epsilon=0.00)  # very low epsilon for testing\n",
    "\n",
    "\n",
    "\n",
    "max_success_rate = 0  # initialize to zero\n",
    "for model_file in os.listdir(\"grid_search\"):\n",
    "    if model_file.endswith(\".dat\"):\n",
    "        # print(f\"\\nTesting model: {model_file}\")\n",
    "        trial_num = int(model_file.split(\"Trial\")[-1].split(\".\")[0])\n",
    "\n",
    "        if 19 <= trial_num <= 114:\n",
    "            print(\"Using CONFIG1\")\n",
    "            env, agent, model, model_cfg = env1, agent1, model, CONFIG1\n",
    "            model.load_state_dict(torch.load(os.path.join(\"grid_search\", model_file)))\n",
    "        elif 115 <= trial_num <= 210:\n",
    "            print(\"Using CONFIG2\")\n",
    "            env, agent, model, model_cfg = env2, agent2, model2, CONFIG2\n",
    "            model2.load_state_dict(torch.load(os.path.join(\"grid_search\", model_file)))\n",
    "        elif 211 <= trial_num <= 306:\n",
    "            print(\"Using CONFIG3\")\n",
    "            env, agent, model, model_cfg = env3, agent3, model3, CONFIG3\n",
    "            model3.load_state_dict(torch.load(os.path.join(\"grid_search\", model_file)))\n",
    "                        \n",
    "        metrics = test_agent_current(agent, test_pairs, num_episodes=len(test_pairs), print_results=False)\n",
    "        if np.mean(metrics['success_rate']) > max_success_rate:\n",
    "            max_success_rate = np.mean(metrics['success_rate'])\n",
    "            best_model_file = model_file\n",
    "            print(f\"New best model found: {best_model_file} with success rate {max_success_rate*100:.2f}%\")\n",
    "            \n",
    "print(f\"\\nBest model overall: {best_model_file} with success rate {max_success_rate*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f84e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):  # visualize 3 test episodes\n",
    "#     visualize_test_episode(agent2, test_pairs[i][0], test_pairs[i][1], episode_num=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
