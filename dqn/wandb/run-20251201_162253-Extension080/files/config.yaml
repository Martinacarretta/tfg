_wandb:
    value:
        cli_version: 0.22.2
        e:
            ulth54uzjjqdqq3jis5k6d2y9rk2p3dv:
                codePath: dqn/training.ipynb
                codePathLocal: training.ipynb
                cpu_count: 4
                cpu_count_logical: 8
                disk:
                    /:
                        total: "269427478528"
                        used: "42845908992"
                email: martinacarrettab@gmail.com
                executable: /usr/bin/python3
                git:
                    commit: 048222afc5f9f612f5150af9df102a6830fa1086
                    remote: https://github.com/Martinacarretta/tfg
                host: LAPTOP-INQT65B2
                memory:
                    total: "3991105536"
                os: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.35
                program: /home/martina/codi2/4year/tfg/dqn/training.ipynb
                python: CPython 3.10.12
                root: /home/martina/codi2/4year/tfg/dqn
                startedAt: "2025-12-01T15:22:53.829978Z"
                writerId: ulth54uzjjqdqq3jis5k6d2y9rk2p3dv
        m: []
        python_version: 3.10.12
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 2
                - 13
                - 14
                - 16
                - 61
            "4": 3.10.12
            "5": 0.22.2
            "8":
                - 1
                - 2
            "12": 0.22.2
            "13": linux-x86_64
BATCH_SIZE:
    value: 128
BURN_IN:
    value: 500
DNN_SYNC:
    value: 200
DNN_UPD:
    value: 4
Decay type:
    value: exponential
EPSILON:
    value: 1
EPSILON_DECAY:
    value: 0.995
EPSILON_MIN:
    value: 0.3
GAMMA:
    value: 0.99
MAX_EPISODES:
    value: 1000
MEMORY_SIZE:
    value: 15000
agent:
    value: training_agents.DQNAgent
buffer:
    value: training_buffers.ReplayBuffer
configuration:
    value:
        action_space: Discrete(5)
        grid_size: 6
        max_steps: 20
        rewards:
            - 10
            - -3
            - 1.5
            - -0.1
environment:
    value: general.GlioblastomaPositionalEncoding
lr:
    value: 5e-05
model:
    value: training_dqn.DQNPositionalEncoding
notes:
    value: Normalization, random shift, increase tumor threshold, oscilation penalty, randomize start position, distance shaping
